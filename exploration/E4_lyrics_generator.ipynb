{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "alternative-architect",
   "metadata": {},
   "source": [
    "# AI 작사가 만들기 👩‍🎨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consistent-mailing",
   "metadata": {},
   "source": [
    "## 1. 데이터 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "packed-denial",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "published-going",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기: 187088\n",
      "Examples:\n",
      " ['At first I was afraid', 'I was petrified', 'I kept thinking I could never live without you', 'By my side But then I spent so many nights', \"Just thinking how you've done me wrong\", 'I grew strong', \"I learned how to get along And so you're back\", 'From outer space', 'I just walked in to find you', 'Here without that look upon your face I should have changed that fucking lock', 'I would have made you leave your key', 'If I had known for just one second', \"You'd be back to bother me Well now go,\", 'Walk out the door', 'Just turn around', \"Now, you're not welcome anymore Weren't you the one\", 'Who tried to break me with desire?', \"Did you think I'd crumble?\", \"Did you think I'd lay down and die? Oh not I,\", 'I will survive']\n"
     ]
    }
   ],
   "source": [
    "txt_file_path = os.getenv('HOME') + '/aiffel/lyricist/data/lyrics/*'\n",
    "\n",
    "txt_list = glob.glob(txt_file_path)\n",
    "\n",
    "raw_corpus = []\n",
    "\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        raw = f.read().splitlines()\n",
    "        raw_corpus.extend(raw)\n",
    "\n",
    "print(\"데이터 크기:\", len(raw_corpus))\n",
    "print(\"Examples:\\n\", raw_corpus[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprising-flight",
   "metadata": {},
   "source": [
    "## 2. 데이터 정제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "partial-leisure",
   "metadata": {},
   "source": [
    "### 2.1 정규표현식으로 문장 정제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "moral-ready",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> at first i was afraid <end>\n"
     ]
    }
   ],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip() # 소문자로 변경 후 양쪽 공백 제거\n",
    "    sentence = re.sub(\"\\[.*\\]*\", \" \", sentence) # 노래 구조 삭제 ex. [Outro]\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence) # 특수문자 양옆에 공백 추가\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 다수의 공백은 하나의 공백으로 처리 \n",
    "    sentence = re.sub(r\"[^a-z?.!,¿]+\", \" \", sentence) # 영어와 지정한 특수문자 제외 공백 처리 \n",
    "    sentence = sentence.strip() # 양쪽 공백 삭제\n",
    "    sentence = '<start> ' + sentence + ' <end>' # 문장 시작에는 <start>, 끝에는 <end>를 추가\n",
    "    return sentence\n",
    "\n",
    "print(preprocess_sentence(raw_corpus[0]))# 정제 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "available-bronze",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168590\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<start> i was petrified <end>',\n",
       " '<start> i kept thinking i could never live without you <end>',\n",
       " '<start> by my side but then i spent so many nights <end>',\n",
       " '<start> just thinking how you ve done me wrong <end>',\n",
       " '<start> i grew strong <end>',\n",
       " '<start> i learned how to get along and so you re back <end>',\n",
       " '<start> from outer space <end>',\n",
       " '<start> i just walked in to find you <end>',\n",
       " '<start> here without that look upon your face i should have changed that fucking lock <end>',\n",
       " '<start> i would have made you leave your key <end>',\n",
       " '<start> if i had known for just one second <end>',\n",
       " '<start> you d be back to bother me well now go , <end>',\n",
       " '<start> walk out the door <end>',\n",
       " '<start> just turn around <end>',\n",
       " '<start> now , you re not welcome anymore weren t you the one <end>',\n",
       " '<start> who tried to break me with desire ? <end>',\n",
       " '<start> did you think i d crumble ? <end>',\n",
       " '<start> did you think i d lay down and die ? oh not i , <end>',\n",
       " '<start> i will survive <end>']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [] # 정제된 말뭉치를 저장\n",
    "\n",
    "for sentence in raw_corpus:\n",
    "    # 원치않는 문장 건너뛰기\n",
    "    if len(sentence) == 0 or len(sentence.split()) > 15: continue # 길이가 0이거나 토큰이 15개가 넘는 문장은 건너뛰기\n",
    "#     if sentence[-1] == \":\": continue # 가사가 ':'으로 마치는 경우 존재하므로 건너뛰지 않는다\n",
    "    \n",
    "    preprocessed_sentence = preprocess_sentence(sentence)\n",
    "    corpus.append(preprocessed_sentence)\n",
    "        \n",
    "# 정제된 결과 확인\n",
    "print(len(corpus))\n",
    "corpus[1:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-sleeping",
   "metadata": {},
   "source": [
    "### 2.2 Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "composite-mother",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2   71  250 ...    0    0    0]\n",
      " [   2    5   57 ...    0    0    0]\n",
      " [   2    5 1103 ...    0    0    0]\n",
      " ...\n",
      " [   2   47   16 ...    0    0    0]\n",
      " [  24    9 2887 ...  261   19    3]\n",
      " [   2    6  176 ...    0    0    0]] <keras_preprocessing.text.Tokenizer object at 0x7f079aad4c90>\n"
     ]
    }
   ],
   "source": [
    "def tokenize(corpus):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words=12000, # 단어장의 크기(전체 단어의 개수) \n",
    "        filters=' ',\n",
    "        oov_token=\"<unk>\" # 사전에 없는 단어 <unk>으로 대체\n",
    "    )\n",
    "    # corpus를 이용해 tokenizer 내부의 단어장을 완성\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    # 준비한 tokenizer를 이용해 corpus를 Tensor로 변환\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)   \n",
    "    # 입력 데이터의 시퀀스 길이를 일정하게\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post', maxlen=15)\n",
    "    \n",
    "    print(tensor,tokenizer)\n",
    "    return tensor, tokenizer\n",
    "\n",
    "tensor, tokenizer = tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "modular-therapist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2   71  250    5   57  644    3    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [   2    5   57 6670    3    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [   2    5 1103  510    5  104   79  202  257    7    3    0    0    0\n",
      "     0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(168590, 15)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tensor[:3, :15]) # 생성된 텐서 데이터 3번째 행 부터 15번째 열까지 출력\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "forward-hours",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : <unk>\n",
      "2 : <start>\n",
      "3 : <end>\n",
      "4 : ,\n",
      "5 : i\n",
      "6 : the\n",
      "7 : you\n",
      "8 : and\n",
      "9 : a\n",
      "10 : to\n"
     ]
    }
   ],
   "source": [
    "# 단어사전 확인\n",
    "len(tokenizer.index_word)\n",
    "for idx in tokenizer.index_word:\n",
    "    print(idx, \":\", tokenizer.index_word[idx])\n",
    "\n",
    "    if idx >= 10: break #단어장의 10번째 단어까지 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honey-lewis",
   "metadata": {},
   "source": [
    "## 3. 평가 데이터셋 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "experienced-description",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2  71 250   5  57 644   3   0   0   0   0   0   0   0]\n",
      "[ 71 250   5  57 644   3   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "src_input = tensor[:, :-1] # 마지막 토큰을 잘라, 소스 문장 생성\n",
    "tgt_input = tensor[:, 1:] # <start>를 잘라, 타겟 문장 생성\n",
    "print(src_input[0])\n",
    "print(tgt_input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adolescent-archives",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Train: (134872, 14)\n",
      "Target Train: (134872, 14)\n",
      "Source Val: (33718, 14)\n",
      "Target Val: (33718, 14)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input, tgt_input, test_size=0.2, random_state=42)\n",
    "print(\"Source Train:\", enc_train.shape)\n",
    "print(\"Target Train:\", dec_train.shape)\n",
    "print(\"Source Val:\", enc_val.shape)\n",
    "print(\"Target Val:\", dec_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hourly-latvia",
   "metadata": {},
   "source": [
    "## 4. 모델 설계 및 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-checkout",
   "metadata": {},
   "source": [
    "__조건__: 10 Epoch 안에 val_loss 값을 2.2 수준으로 줄일 수 있는 모델을 설계하라"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clinical-claim",
   "metadata": {},
   "source": [
    "### 4.1 1차 모델 설계 (하이퍼파라미터 조정)\n",
    "\n",
    "__데이터__\n",
    "- Source Train: (134872, 14)\n",
    "- Target Train: (134872, 14)\n",
    "- Source Validation: (33718, 14)\n",
    "- Target Validation: (33718, 14)\n",
    "\n",
    "\n",
    "__모델설계__\n",
    "\n",
    "[Model1]\n",
    "- RNN 레이어 2개\n",
    "- embedding_size = 256\n",
    "- hidden_size = 1024\n",
    "- n_train_epoch = 10\n",
    "\n",
    "[Model2]\n",
    "- RNN 레이어 2개\n",
    "- embedding_size = 512\n",
    "- hidden_size = 1024\n",
    "- n_train_epoch = 10  \n",
    "\n",
    "[Model3]\n",
    "- RNN 레이어 2개\n",
    "- embedding_size = 1024\n",
    "- hidden_size = 1024\n",
    "- n_train_epoch = 10  \n",
    "\n",
    "\n",
    "__실행방법__\n",
    "\n",
    "훈련셋을 train,validation으로 분리한다. __하이퍼파라미터__를 조정하며 train으로 훈련하고 validation으로 loss를 평가한다.최종 평가는 생성하는 문장을 확인한다.\n",
    "\n",
    "__결과__\n",
    "\n",
    "Train과 validation의 loss 결과<br>\n",
    "참고용으로 확인한 loss \n",
    "\n",
    "[Model1] \n",
    "loss: 2.2189 - val_loss: 2.5852\n",
    "\n",
    "[Model2]\n",
    "loss: 2.0250 - val_loss: 2.4940\n",
    "\n",
    "[Model3]\n",
    "loss: 2.0079 - val_loss: 2.4921"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eastern-organization",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpreted-newark",
   "metadata": {},
   "source": [
    "> __return_sequences=True__<br>\n",
    "    return_sequences=True for all LSTM layers except the last one.    \n",
    "    Setting this flag to True lets Keras know that LSTM output should contain all historical generated outputs along with time stamps (3D). So, next LSTM layer can work further on the data.\n",
    "    If this flag is false, then LSTM only returns last output (2D). Such output is not good enough for another LSTM layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "innocent-dallas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 1\n",
    "vocab_size = tokenizer.num_words + 1 # 총 단어 개수 + pad:0\n",
    "embedding_size = 256 # 단어가 추상적으로 표현되는 크기\n",
    "hidden_size = 1024 # 모델에 둘 일꾼의 수(많으면 배가 산으로)\n",
    "model = TextGenerator(vocab_size, embedding_size , hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "operational-trade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 14, 12001), dtype=float32, numpy=\n",
       "array([[[ 1.09650093e-04,  7.55700967e-05,  4.64430668e-05, ...,\n",
       "         -6.37245976e-05, -8.88853610e-05,  3.32817173e-04],\n",
       "        [ 4.25293256e-05, -1.16485593e-04,  4.01814235e-04, ...,\n",
       "         -1.28365733e-04, -5.76188722e-05,  1.76828747e-04],\n",
       "        [ 1.28811153e-04, -2.26286182e-04,  6.32244628e-04, ...,\n",
       "         -1.32657384e-04, -2.24731411e-04,  2.32255203e-04],\n",
       "        ...,\n",
       "        [ 7.03075202e-04,  9.25957051e-04, -6.55797194e-05, ...,\n",
       "         -5.83082801e-05, -5.87891089e-04,  3.84218409e-04],\n",
       "        [ 7.44950143e-04,  6.10340387e-04, -1.56804560e-06, ...,\n",
       "         -1.56189097e-04, -7.44727382e-04,  5.23206021e-04],\n",
       "        [ 6.44089538e-04,  4.97802917e-04,  1.64057987e-04, ...,\n",
       "         -4.77595953e-04, -9.87384701e-04,  4.48294682e-04]],\n",
       "\n",
       "       [[ 2.31161204e-04, -6.61938902e-05, -8.36381150e-05, ...,\n",
       "         -8.25635434e-05, -5.12118895e-05,  1.52420078e-04],\n",
       "        [ 6.37488192e-05, -3.13662749e-04,  2.26172597e-05, ...,\n",
       "          1.98562760e-04,  6.59125944e-05,  3.14758567e-04],\n",
       "        [-2.18755213e-06, -3.34781216e-04,  2.92531531e-05, ...,\n",
       "          4.56534763e-04,  1.95362896e-04,  4.87570680e-04],\n",
       "        ...,\n",
       "        [-1.48252281e-03,  4.85102879e-04,  6.64263149e-04, ...,\n",
       "         -2.05927427e-04,  3.55229713e-05, -9.85605875e-05],\n",
       "        [-1.07315322e-03,  3.85415857e-04,  7.50174921e-04, ...,\n",
       "         -4.90572420e-04,  2.16400775e-04,  1.07256135e-04],\n",
       "        [-4.91084182e-04,  9.61219048e-05,  8.07148754e-04, ...,\n",
       "         -3.73265211e-04,  1.60788200e-04,  1.21234712e-04]],\n",
       "\n",
       "       [[ 2.31161204e-04, -6.61938902e-05, -8.36381150e-05, ...,\n",
       "         -8.25635434e-05, -5.12118895e-05,  1.52420078e-04],\n",
       "        [ 2.42220762e-04, -4.09000859e-05, -1.50658845e-04, ...,\n",
       "          1.81192809e-05,  8.13911538e-05,  2.26024451e-04],\n",
       "        [ 6.32722877e-05,  1.22565723e-06, -2.40244597e-04, ...,\n",
       "          9.53422204e-05,  3.71996372e-04,  3.12426273e-04],\n",
       "        ...,\n",
       "        [-7.55545509e-04,  2.61132984e-04, -5.27684926e-04, ...,\n",
       "          8.69280950e-04, -3.88560293e-04,  4.33312642e-04],\n",
       "        [-5.21959329e-04,  3.37863195e-04, -1.01772544e-03, ...,\n",
       "          7.80198548e-04, -6.14556135e-04,  2.58614484e-04],\n",
       "        [-1.90692794e-04,  3.05159250e-04, -1.16376090e-03, ...,\n",
       "          5.25292184e-04, -6.81782665e-04,  1.63081379e-04]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-3.41034211e-05,  1.52407447e-04, -3.27992806e-04, ...,\n",
       "          1.03724095e-04, -3.72163224e-04, -1.07859290e-04],\n",
       "        [-2.76226725e-04,  1.50626322e-04, -4.18818672e-04, ...,\n",
       "          9.89086839e-05, -7.66739657e-04, -3.66226159e-05],\n",
       "        [-3.98421369e-04,  3.00134590e-04, -7.55065004e-04, ...,\n",
       "          2.17905588e-04, -1.32004346e-03, -1.02336329e-04],\n",
       "        ...,\n",
       "        [-1.26166909e-03,  8.04702402e-04, -1.51766930e-03, ...,\n",
       "          6.48809713e-04, -4.57940530e-03,  2.51850724e-04],\n",
       "        [-1.20612583e-03,  9.34977201e-04, -1.67997438e-03, ...,\n",
       "          7.39961397e-04, -4.81382152e-03,  2.00193972e-04],\n",
       "        [-1.28148752e-03,  9.09298949e-04, -1.58120110e-03, ...,\n",
       "          7.10188120e-04, -4.91308980e-03,  3.00585380e-04]],\n",
       "\n",
       "       [[ 2.31161204e-04, -6.61938902e-05, -8.36381150e-05, ...,\n",
       "         -8.25635434e-05, -5.12118895e-05,  1.52420078e-04],\n",
       "        [ 5.01219241e-04, -2.28545832e-06, -2.80610635e-04, ...,\n",
       "         -9.69479370e-05, -6.87345673e-05,  1.10022498e-04],\n",
       "        [ 4.20267897e-04,  1.61999924e-04, -1.05759769e-04, ...,\n",
       "         -1.78596310e-04, -1.51190645e-04,  3.42635263e-04],\n",
       "        ...,\n",
       "        [ 5.04284108e-04, -1.18002034e-04,  6.06704038e-04, ...,\n",
       "         -3.03760462e-04,  1.04514777e-03,  1.52864304e-04],\n",
       "        [ 7.84616219e-04, -4.50695719e-04,  5.72652381e-04, ...,\n",
       "          6.52932504e-05,  7.08011154e-04, -1.16709292e-04],\n",
       "        [ 1.10836572e-03, -8.35275743e-04,  5.52949845e-04, ...,\n",
       "          4.63655917e-04,  2.76890292e-04, -4.03026526e-04]],\n",
       "\n",
       "       [[ 2.31161204e-04, -6.61938902e-05, -8.36381150e-05, ...,\n",
       "         -8.25635434e-05, -5.12118895e-05,  1.52420078e-04],\n",
       "        [ 4.08654305e-04, -1.09438588e-05, -1.01651121e-05, ...,\n",
       "          1.75909245e-05, -1.90789760e-05,  1.96999608e-04],\n",
       "        [ 2.26848919e-04,  7.16381546e-05, -1.05268460e-04, ...,\n",
       "          1.97046378e-04, -2.96392041e-04,  3.41442821e-04],\n",
       "        ...,\n",
       "        [ 9.25326080e-04, -8.39144748e-04,  1.66686455e-04, ...,\n",
       "          9.37498582e-04, -1.05038495e-03, -4.63956385e-04],\n",
       "        [ 1.41193520e-03, -1.29475957e-03,  3.42534739e-04, ...,\n",
       "          1.21204834e-03, -1.34588371e-03, -6.60305261e-04],\n",
       "        [ 1.86275668e-03, -1.71465904e-03,  4.96714667e-04, ...,\n",
       "          1.40935194e-03, -1.63031521e-03, -8.33923696e-04]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# corpus 텐서를 tf.data.Dataset객체로 변환\n",
    "dataset = tf.data.Dataset.from_tensor_slices((src_input, tgt_input))\n",
    "dataset = dataset.shuffle(len(src_input))\n",
    "dataset = dataset.batch(256, drop_remainder=True)\n",
    "\n",
    "# model에 작은 데이터셋으로 input shape를 결정\n",
    "for src_sample, tgt_sample in dataset.take(1): break\n",
    "\n",
    "# 한 배치만 불러온 데이터를 모델에 넣어봅니다\n",
    "model(src_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "harmful-provincial",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  3072256   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  multiple                  5246976   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                multiple                  8392704   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  12301025  \n",
      "=================================================================\n",
      "Total params: 29,012,961\n",
      "Trainable params: 29,012,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "spare-netherlands",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "527/527 [==============================] - 202s 378ms/step - loss: 4.1540 - val_loss: 3.2652\n",
      "Epoch 2/10\n",
      "527/527 [==============================] - 199s 377ms/step - loss: 3.1814 - val_loss: 3.0784\n",
      "Epoch 3/10\n",
      "527/527 [==============================] - 200s 379ms/step - loss: 2.9866 - val_loss: 2.9583\n",
      "Epoch 4/10\n",
      "527/527 [==============================] - 200s 380ms/step - loss: 2.8402 - val_loss: 2.8646\n",
      "Epoch 5/10\n",
      "527/527 [==============================] - 198s 376ms/step - loss: 2.7143 - val_loss: 2.7934\n",
      "Epoch 6/10\n",
      "527/527 [==============================] - 200s 380ms/step - loss: 2.6009 - val_loss: 2.7345\n",
      "Epoch 7/10\n",
      "527/527 [==============================] - 199s 377ms/step - loss: 2.4979 - val_loss: 2.6946\n",
      "Epoch 8/10\n",
      "527/527 [==============================] - 199s 377ms/step - loss: 2.4026 - val_loss: 2.6488\n",
      "Epoch 9/10\n",
      "527/527 [==============================] - 200s 379ms/step - loss: 2.2992 - val_loss: 2.6155\n",
      "Epoch 10/10\n",
      "527/527 [==============================] - 199s 378ms/step - loss: 2.2189 - val_loss: 2.5852\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    ".\n",
    "model.compile(loss=loss, optimizer=optimizer)\n",
    "\n",
    "hist = model.fit(enc_train, \n",
    "          dec_train, \n",
    "          epochs=10,\n",
    "          batch_size=256,\n",
    "          validation_data=(enc_val, dec_val),\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "unusual-reputation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAvmElEQVR4nO3dd3hUdfbH8fcJIAFBQUBEigER6SQQEEWKHVRsgFgQZUXWn1gQGyr2Lqy9YEMRsC2CDRVRQ1MRQq8WmjSlKAiLtOT8/jgTCTGBJOTmTjLn9Tx5SGZu7pxk13zm20VVcc45F7viwi7AOedcuDwInHMuxnkQOOdcjPMgcM65GOdB4JxzMa5k2AXkVeXKlTUhISHsMpxzrkiZMWPGBlWtkt1zRS4IEhISSE1NDbsM55wrUkRkRU7PedeQc87FOA8C55yLcR4EzjkX44rcGIFzrvjatWsXq1atYvv27WGXUmTFx8dTo0YNSpUqlevv8SBwzkWNVatWUb58eRISEhCRsMspclSVjRs3smrVKmrXrp3r7/OuIedc1Ni+fTuVKlXyEMgnEaFSpUp5blF5EDjnooqHwIHJz+8vZoLg55+hXz/YtSvsSpxzLroEFgQiEi8i00RkjogsEJH7crjuQhFZGLnmraDq+eEHePppGDEiqFdwzhV1mzZt4oUXXsjX95555pls2rQp19ffe++9DB48OF+vVdCCbBHsAE5W1WZAItBRRFpnvkBEjgFuB9qoaiOgX1DFnHkmJCfDgw96q8A5l719BcHu3bv3+b2ffvopFSpUCKCq4AUWBGq2Rr4sFfnIehzaVcDzqvpH5HvWBVWPCNx9NyxdCiNHBvUqzrmibMCAASxZsoTExERuueUWJkyYQNu2bTnnnHNo2LAhAOeddx4tWrSgUaNGvPzyy39/b0JCAhs2bGD58uU0aNCAq666ikaNGnH66afz119/7fN1Z8+eTevWrWnatCnnn38+f/zxBwDPPPMMDRs2pGnTplx00UUATJw4kcTERBITE0lKSmLLli0H/HMHOn1UREoAM4C62B/877NcUi9y3TdACeBeVf08m/v0AfoA1KpVK9/1nH02NG9urYIePaCkT551Lmr16wezZxfsPRMT4amncn7+0UcfZf78+cyOvPCECROYOXMm8+fP/3s65tChQznssMP466+/aNmyJV26dKFSpUp73eenn37i7bff5pVXXuHCCy/k/fffp0ePHjm+bs+ePXn22Wdp3749d999N/fddx9PPfUUjz76KMuWLaN06dJ/dzsNHjyY559/njZt2rB161bi4+MP4DdiAh0sVtU0VU0EagCtRKRxlktKAscAHYCLgVdEpEI293lZVZNVNblKlWw3z8sVEbjnHliyxFsFzrncadWq1V5z8p955hmaNWtG69atWblyJT/99NM/vqd27dokJiYC0KJFC5YvX57j/Tdv3symTZto3749AJdffjmTJk0CoGnTplx66aWMGDGCkpF3rm3atKF///4888wzbNq06e/HD0ShvCdW1U0ikgJ0BOZnemoV8L2q7gKWiciPWDBMD6qWzp0hKclaBZde6q0C56LVvt65F6aDDz74788nTJjAl19+yXfffUfZsmXp0KFDtnP2S5cu/ffnJUqU2G/XUE7Gjh3LpEmT+Pjjj3nooYeYN28eAwYM4KyzzuLTTz+lTZs2jBs3jvr16+fr/hmCnDVUJePdvYiUAU4DFme57AOsNYCIVMa6ipYGVZO9jrUKfv4Z3gpsjpJzrigqX778PvvcN2/eTMWKFSlbtiyLFy9m6tSpB/yahx56KBUrVmTy5MkADB8+nPbt25Oens7KlSs56aSTeOyxx9i8eTNbt25lyZIlNGnShNtuu42WLVuyeHHWP6t5F+T74WrAsMg4QRzwnqp+IiL3A6mq+hEwDjhdRBYCacAtqroxwJoAOOcc6yt88EG45BJvFTjnTKVKlWjTpg2NGzemU6dOnHXWWXs937FjR4YMGUKDBg049thjad26dQ53ypthw4Zx9dVXs23bNurUqcPrr79OWloaPXr0YPPmzagq119/PRUqVOCuu+4iJSWFuLg4GjVqRKdOnQ749UU160Se6JacnKwFcTDNmDFwwQUwfLgNHDvnwrdo0SIaNGgQdhlFXna/RxGZoarJ2V0fMyuLszr3XGjWDB54ANLSwq7GOefCE7NBEBdn6wp+/BHeeSfsapxzLjwxGwQA550HTZp4q8A5F9tiOgji4mwG0Q8/wLvvhl2Nc86FI6aDAOD886FxY28VOOdiV8wHQcZYweLF8N//hl2Nc84VvpgPAoAuXaBRI7j/fm8VOOfyply5cnl6PBp5ELCnVbBoEYwaFXY1zjlXuDwIIrp2hYYNrVWQnh52Nc65MAwYMIDnn3/+768zDo/ZunUrp5xyCs2bN6dJkyZ8+OGHub6nqnLLLbfQuHFjmjRpwruRmSlr166lXbt2JCYm0rhxYyZPnkxaWhpXXHHF39c++eSTBf4zZsc3V4jIaBVcdJG1Ci68MOyKnItxIexD3b17d/r160ffvn0BeO+99xg3bhzx8fGMGTOGQw45hA0bNtC6dWvOOeecXJ0PPHr0aGbPns2cOXPYsGEDLVu2pF27drz11lucccYZ3HnnnaSlpbFt2zZmz57N6tWrmT/f9ubMy4lnB8JbBJl07QoNGnirwLlYlZSUxLp161izZg1z5syhYsWK1KxZE1XljjvuoGnTppx66qmsXr2a3377LVf3nDJlChdffDElSpSgatWqtG/fnunTp9OyZUtef/117r33XubNm0f58uWpU6cOS5cu5brrruPzzz/nkEMOCfgnNt4iyKRECWsVXHwxjB5tweCcC0lI+1B369aNUaNG8euvv9K9e3cARo4cyfr165kxYwalSpUiISEh2+2n86Jdu3ZMmjSJsWPHcsUVV9C/f3969uzJnDlzGDduHEOGDOG9995j6NChBfFj7ZO3CLLo1g3q14f77vNWgXOxqHv37rzzzjuMGjWKbt26Abb99OGHH06pUqVISUlhxYoVub5f27Zteffdd0lLS2P9+vVMmjSJVq1asWLFCqpWrcpVV11F7969mTlzJhs2bCA9PZ0uXbrw4IMPMnPmzKB+zL14iyCLEiXgrrvs0JoxY2xqqXMudjRq1IgtW7ZQvXp1qlWrBsCll15K586dadKkCcnJyXk6COb888/nu+++o1mzZogIjz/+OEcccQTDhg1j0KBBlCpVinLlyvHmm2+yevVqevXqRXrkXegjjzwSyM+YVcxuQ70vaWm2rqB0aZg1ywaSnXPB822oC4ZvQ10AMloFc+fCBx+EXY1zzgXLgyAHF10E9er5DCLnXPHnQZCDjFbBnDnw0UdhV+Nc7Chq3dXRJj+/Pw+CfbjoIjjmGJtB5P/fdC548fHxbNy40cMgn1SVjRs3Eh8fn6fvC2zWkIjEA5OA0pHXGaWq9+RwbRdgFNBSVYMdCc6DkiVh4EC4/HJrFZx7btgVOVe81ahRg1WrVrF+/fqwSymy4uPjqVGjRp6+J7BZQ2Jrrw9W1a0iUgqYAtygqlOzXFceGAscBFy7vyAojFlDme3ebauNy5eHGTMgFyvKnXMu6oQya0jN1siXpSIf2aXOA8BjwIEt0wtIRqtg1iz4+OOwq3HOuYIX6BiBiJQQkdnAOmC8qn6f5fnmQE1VHbuf+/QRkVQRSQ2jyXjppXD00T5W4JwrngINAlVNU9VEoAbQSkQaZzwnInHAE8BNubjPy6qarKrJVapUCazenGS0CmbOhLH7jCznnCt6CmXWkKpuAlKAjpkeLg80BiaIyHKgNfCRiGTbhxW2Hj2gTh24915vFTjnipfAgkBEqohIhcjnZYDTgMUZz6vqZlWtrKoJqpoATAXOiaZZQ5mVLAl33mkDxp9+GnY1zjlXcIJsEVQDUkRkLjAdGyP4RETuF5FzAnzdwFx2GdSu7a0C51zxEtg6AlWdCyRl8/jdOVzfIahaCkqpUtYq6N0bPvsMzjwz7Iqcc+7A+criPOrZExISfAaRc6748CDIo4xWwbRp8PnnYVfjnHMHzoMgH3r2hKOO8laBc6548CDIh4MOgjvugO+/hy++CLsa55w7MB4E+XTFFVCrls8gcs4VfR4E+ZTRKpg6FcaPD7sa55zLPw+CA9CrF9Ss6WMFzrmizYPgAGS0Cr79Fr78MuxqnHMufzwIDlCvXlCjhrcKnHNFlwfBASpdGm6/Hb75Br7+OuxqnHMu7zwICsCVV0L16j6DyDlXNHkQFICMVsGUKZCSEnY1zjmXN7ETBBs2wA03wP/+F8jtr7wSjjzSxwqcc0VP7ATBV1/Bc89B69bw008Ffvv4eGsVTJoEEyYU+O2dcy4wsRME3bvbLnFr10JyMnz4YYG/RO/ee1oFzjlXVMROEACcdpodMVavHpx3nm0jmpZWYLePj4fbboOJE71V4JwrOmIrCMC2DZ082d6+P/ywnS6zcWOB3f6qq6BaNW8VOOeKjtgLArC37q+8Yh8TJkCLFtZSKABlylirYMIEGy9wzrloF5tBkKF3b5vzqQpt2sBrrxXIbfv0gSOO8FaBc65oCCwIRCReRKaJyBwRWSAi//izKCL9RWShiMwVka9E5Kig6slRy5bWGmjb1oKhTx/YseOAbpnRKvj6a+uFcs65aBZki2AHcLKqNgMSgY4i0jrLNbOAZFVtCowCHg+wnpxVrmwzim6/3bqL2raFX345oFv++99Qtaq3Cpxz0S+wIFCzNfJlqciHZrkmRVW3Rb6cCtQIqp79KlHCBo9Hj4bFi23c4Kuv8n27MmXg1lvtFlOmFGCdzjlXwAIdIxCREiIyG1gHjFfV7/dx+ZXAZzncp4+IpIpI6vr16wOoNJPzz4fUVDj8cDj9dHj00XwvFb76aruNtwqcc9Es0CBQ1TRVTcTe6bcSkcbZXSciPYBkYFAO93lZVZNVNblKlSqB1fu3evXsQOJu3ay7qEsX+PPPPN+mbFlrFXz5pZ1Z4Jxz0ahQZg2p6iYgBeiY9TkRORW4EzhHVQ9slLYglSsHb78NTzwBH31kg8oLF+b5NldfDVWqeKvAORe9gpw1VEVEKkQ+LwOcBizOck0S8BIWAuuCqiXfRODGG62jf9MmaNUK3nsvT7c4+GBrFXzxBXz3XTBlOufcgQiyRVANSBGRucB0bIzgExG5X0TOiVwzCCgH/FdEZovIRwHWk3/t28PMmdC0qe1ZdNNNsHt3rr/9//7PWwXOueglWsT2TE5OTtbU1NRwXnznTguB556zcHj3XZsjmguPP25rC777zjZAdc65wiQiM1Q1ObvnYntlcV4ddBA8+ywMHw7TpkHz5rnu77nmGluu4K0C51y08SDIjx49LADi461l8MIL+51iWq4c3HyzrVubNq2Q6nTOuVzwIMivZs1svcHpp0PfvnD55bBt2z6/pW9fqFQJBg7M0xCDc84FyoPgQFSsaFNL77sPRoyAE06ApUtzvLxcObj7bhg/Hk45BVavLsRanXMuBx4EByouzv66jx0LK1bY1hSffprj5ddfD2++afvcNWtm3+acc2HyICgonTrZX/eEBDj7bLj3XkhPz/bSyy6zS6tXt0tvvtkmJDnnXBg8CApSnTrwzTf2l/6++6BzZ/j992wvPfZY28XimmvgP/+xDU+XLSvkep1zDg+Cgle2LLzxhs0kGj8ekpNh9uxsL42Ph+efh1Gj4IcfICnJPnfOucLkQRAEEVtOPGmS9fkcf7ytPchBly4waxbUr2/73F1zDWzfXoj1OudimgdBkFq3tsGA1q2hZ0+bP5rDYEDt2naa2S23wIsvwnHH2bEIzjkXNA+CoFWtal1EN99s3UXt2+c4b7RUKduK4tNPYc0a61V6881Crtc5F3M8CApDyZIwaBD8978wfz40aQKPPAJbtmR7eadONqyQnGzr1C6/HLZuzfZS55w7YB4EhalrV5g+3cYM7rjD+oMeeyzbv/LVq9vu1/fcY8MLyckwd24INTvnij0PgsJWv76tIps61Q67GTDAAmHQIPjf//a6tEQJW47w1Vd2QFqrVjBkSL5PznTOuWx5EITluOPgs8/sDMvmze30mjp1bFFBlj2LTjrJuopOOskmI114oZ2T45xzBcGDIGzHHw/jxtlCtKZNbVC5Th148kn466+/Lzv8cGtIPP44fPCBrTnwXUydcwXBgyBanHCCzS6aPBkaNYL+/S0Qnn7670CIi7PppZMnW/dQmzbWgMhhJwvnnMsVD4Joc+KJNigwcaKNJ/TrB0cfbQfiRFaZtW5tC9A6d7YGxDnnwIYN4ZbtnCu6PAiiVbt2kJJiH8ccY9uW1q1re1Ls2EHFivD++3Zq5vjxkJhoC5mdcy6vPAiiXYcOMGGCtRJq14Zrr7VAePFFZOcO+va1CUhly9pg8gMPQFpa2EU754qSwIJAROJFZJqIzBGRBSLyj9N6RaS0iLwrIj+LyPcikhBUPUWaCJx8sr3lHz8eatWyDYmOOQZeeomkRjuZMQMuvtiORjj9dFi7NuyinXNFRZAtgh3AyaraDEgEOopI6yzXXAn8oap1gSeBxwKsp+gTgVNPhSlTbKZR9epw9dVQrx7l33mF4UN3MXSotRCaNbNLnHNufwILAjUZS2ZLRT6yLoU6FxgW+XwUcIqISFA1FRsi9rb/229tLULVqtCnD3JsPXqlv8b0b3dRtSp07Ai33w67doVdsHMumgU6RiAiJURkNrAOGK+q32e5pDqwEkBVdwObgUrZ3KePiKSKSOr69euDLLloEbG/9lOn2iKDypWhd28aXlCfGde+ztW9d/Poo7bP3YoVYRfrnItWgQaBqqapaiJQA2glIo3zeZ+XVTVZVZOrVKlSoDUWCyJw5pm2wuzjj6FCBQ66+l+8mFKfqf83jEXzdpOYaAvRnHMuq0KZNaSqm4AUoGOWp1YDNQFEpCRwKLCxMGoqlkTsEOTUVPjwQzjkEI578Qp+q9yQ6yoMp8v5aVx/PezYEXahzrloEuSsoSoiUiHyeRngNCDrUSsfAZdHPu8KfK3qW6odMBFbZTZjBowZw0GHluX+5T1ZW7EhG58dyYnHp/HTT2EX6ZyLFkG2CKoBKSIyF5iOjRF8IiL3i8g5kWteAyqJyM9Af2BAgPXEHhE47zyYORPef5/Da5RmJD0YOacxDzd5m2FD03wnU+cckps34CJyA/A6sAV4FUgCBqjqF8GW90/Jycmamppa2C9bPKSnw+jR7LrzXkr9uICfqMv4Wr05/qUrSOpYNezqnHMBEpEZqpqc3XO5bRH8S1X/BE4HKgKXAY8WUH2usMTFQdeulFo0l/R33qN8vWpc88sAGneqwYyjLuD3kZ/5smTnYlBugyBjbv+ZwHBVXZDpMVfUxMUR170bR/wwia3TF/Ftq37U+mUyh/U4k82VarN74L3wyy9hV+mcKyS5DYIZIvIFFgTjRKQ84JsfFwPlkuvT/vtBbF6wmseT32Pq5gbEPXQ/mpCAduoEo0f7ijTnirncBsGV2EBuS1Xdhq0S7hVYVa7Q1W14ELdO70aJ8ePoeMxSHtCBbEiZB126QI0acNtt+FQj54qn3AbB8cAPqrpJRHoAA7FVwK6YOfVU+HRhApWeu5+GZZbTWT5hzsHHo//5D9SrZ7uhjhy51+lpzrmiLbdB8CKwTUSaATcBS4A3A6vKhapkSejbFxb/XJKEvmfR4pcPaFTuF749+2F05Uro0cM2vLv+epg3L+xynXMHKLdBsDuy0Otc4DlVfR4oH1xZLhpUqmQHo82eDdVbHkmbT26nSemfSH3sKzjjDHjpJTtn+bjj4NVXYcuWsEt2zuVDboNgi4jcjk0bHSsicdg4gYsBjRvDF1/YrhXbd8bR8raTOXfb2yydsgaefBK2boWrroIjj7R/p03DV6o5V3TkNgi6Y+cL/EtVf8U2kRsUWFUu6mTsWrFgATz2GHz9NdRvU4nb1vbjz2/n25bY3brBW29ZC6FZM2tO/P572KU75/YjV0EQ+eM/EjhURM4GtquqjxHEoNKl4dZbbQJRjx4waBDUO1YYuuh40l8dakejDRliF15/vbUSevSAiRO9leBclMpVEIjIhcA0oBtwIfC9iHQNsjAX3Y44AoYOtV6go4+GK6+EVq3gm3mHwL//DdOnw6xZ0Ls3fPKJzTY69lh4/HH47bewy3fOZZLbrqE7sTUEl6tqT6AVcFdwZbmiIjnZTs586y37+37iiXDJJbByJZCYCM89B2vWwLBhlh633WbrErp0gc8/9y0tnIsCuQ2COFVdl+nrjXn4XlfMicDFF8PixXD33TBmjL35v+8+2LYNKFsWevaESZNg0SLo188+79QJ6tSxcJgyxUPBuZDkdvfRQUBT4O3IQ92Buap6W4C1Zct3H41+K1bYOMJ770HNmjaOcOGFFhh/27kTPvrIpp1+9RXs3g2HHWYnrXXubNNTDz00tJ/BueJmX7uP5ioIIjfpArSJfDlZVccUUH154kFQdEyeDDfcYEMFJ54ITz8NzZtnc+HmzTY/9eOP4dNPYeNGW9XWrp2duNa5M9StW+j1O1ecFEgQRAsPgqIlLQ1efx3uuAM2bLBB5QcfhKo5HX+QlgZTp9oA88cf23xVsL6mzp0tGNq0saBwzuVavoNARLYA2V0ggKrqIQVTYu55EBRNmzfDAw/AM89AmTJw1102u/Sgg/bzjcuWwdixFgoTJliXUoUKNr7QuTN07AgVKxbCT+Bc0eYtAhc1fvwRbrrJ3vAfcww88QScdVaW8YOcbNkC48fbN48dC+vWQYkS1kLIaC0ce2wub+ZcbCmIE8qcKxD16tmb+88+s7/hnTvDKafYerP9Kl8eLrjAFjCsXWtdSAMGWHPjllugQQN7gRtvtKXPfo6Cc7kSWBCISE0RSRGRhSKyIHLucdZrDhWRj0VkTuQaP+MgRnTsCHPnWlfRokW23qxDB0hJyeUC5Lg428riwQdtV7wVK+CFF6yZ8eKLli6VK0P37jB8uA1AO+eyFVjXkIhUA6qp6szIiWYzgPNUdWGma+4ADlXV20SkCvADcISq7szpvt41VPz89Re88go8+qi90W/bFu65B04+OZ+9PP/7H3z5pXUhffIJ/PqrBccJJ1j30dlnQ8OG3oXkYkooXUOqulZVZ0Y+3wIsAqpnvQwoLyIClAN+B3YHVZOLTmXK2MDx0qW2T93SpXZATtu2NiSQ5/cqBx8M555r6bJ6tW13cdddtrptwADbTvXoo+1Fx4+HHTsC+bmcKyoKZbBYRBKASUBjVf0z0+PlgY+A+tj5Bt1VdWw2398H6ANQq1atFitWrAi8Zhee7dttGOCRR2DVKjj+eLj3XjjttAJ4E7969Z5ZSF9+aS9WrpwtYDv1VGjfHurX99aCK3ZCnTUkIuWAicBDqjo6y3NdsUVq/YGjgfFAs8xhkZV3DcWOHTtsDcLDD9veRa1bW5fRGWcU0N/pbdtsUDljFtKqVfb44YdbILRvbwMX3o3kioHQgkBESgGfAONU9Ylsnh8LPKqqkyNffw0MUNVpOd3TgyD27NwJb7xhgbBihe1yes89tpSgwP4+q8KSJTZ9aeJEW7OwcqU9V7myrXLu0MHCoXFjG3NwrggJJQgi/f7DgN9VtV8O17wI/Kaq94pIVWAm1iLYkNN9PQhi186d8Oab8NBDsHy57Xx6zz15WIeQF6r2IhMm7AmH5cvtucMOswGMjGBo2tTmwjoXxcIKghOBycA8ID3y8B1ALQBVHSIiRwJvANWw1cqPquqIfd3Xg8Dt2rUnEJYtgxYtbNfTzp0D7sFZsWJPKEycaC0IsM3x2rXb052UmOhbYLio4yuLXbG0axeMGGGBsGQJJCVZIJx7biF16a9atacbaeJEO7YN4JBDbJe9jGBo0cKDwYXOg8AVa7t3w8iRtrbs55/tuOS774bzzivkrvw1a/ZuMSxebI+XK2fbYGQMPicnQ6lShViYcx4ELkbs3g1vv22B8OOP0KSJBcIFF4Q0tvvrr3YAT0arYWFkLWXZsra4LWOMoWVLO+PZuQB5ELiYkpYG77xju53+8INN8rnrLujaNeTJPuvXWzBkdCXNm2ePx8fbYokOHWysoVkz31HVFTgPAheT0tLslLQHHrD9jBo2tEDo1i1KJvls2GCn92R0Jc2Zs2cZdbVq0KjRno+GDe3fChVCLdkVXR4ELqalpcGoUXD//dY706ABDBxo+9FFRSBk+OMP+O47mD/fDuRZsMASbNu2PdcceWT2AeHHerr98CBwDkhPh/fft0CYP9+OLhg4EC66KIon9aSn27TVjGDIHBB//bXnuurV/xkQDRt6QLi/eRA4l0l6OowZY4Ewd67tXD1wIFxySRQHQlbp6bbALXM4LFz4z4CoUSP7gDik0A8XdCHzIHAuG+np8OGHFgizZ8NRR8ENN0Dv3nYGTpGUlpZzQGzfvue6mjX3DohGjazPrMj+4G5/PAic2wdV23du8GCb1HPoodCnj+1SXaNG2NUVkLQ0W4adORwyupgyb8Ndq5aFQuPGtkK6eXNrMkXVYIrLDw8C53Jp2jT4z39scDkuDi6+2M5YbtYs7MoCkpZmB0BkFxA7I+dDlS1rv4CkJPto3tzCwtc+FCkeBM7l0bJl8PTT8OqrduDZqadaIBTYFtjRbtcuC4NZs2DmTPt39mzYssWeL1nSwiAjGJKSLCy8aylqeRA4l09//AEvv2xnK69ZYz0mN91kLYWYe0Ocnm6th8zhMGsWrFtnz4tA3bp7h0NSElSpEm7dDvAgcO6A7dxpq5UHD7YFwUccYWMI//637Uods1TtoOnMwTBr1p4tu8GmtmYOhqQkG4uIiaZV9PAgcK6AqNoJl4MHwxdfWPf5lVdCv35Qp07Y1UWR33+3rqTM4bB4sbUqwNIzczAkJUG9ej4oHSAPAucCMHcuPPEEvPWWjblecAHcfDMcd1zYlUWpbdvsl5Y5HObOzXlQOinJxiHi48Otu5jwIHAuQGvWwLPPwpAhsGmT7Th98812UI6/wd2PzIPSGWMPmQelRWzNQ926ez6OPnrPvwcfHGr5RYkHgXOFYOtWGDoUnnzSusjr1oX+/eHyy+3NrsulzIPSCxbYqUM//2wfG7KcYnvEEdmHRN26vkFfFh4EzhWi3bttC4tBg2D6dKhUCa65Bvr2hapVw66uiNu8ee9gyPz5mjV7X3vYYTmHRJUqMTdY7UHgXAhUYcoUW6D20Udw0EFw2WXWSmjQIOzqiqFt26wlkV1I/PLLnoFqsFPjcgqJI48M+eCKYIR1eH1N4E2gKqDAy6r6dDbXdQCeAkoBG1S1/b7u60HgiqIff7QuozfesC1/zjrLxhHat4+5N6bh2LnT+uuyBsSSJRYeu3btuTY+3qaAZQ6JOnWgdm3bkKqIDl6HFQTVgGqqOlNEygMzgPNUdWGmayoA3wIdVfUXETlcVdft674eBK4oW78eXngBnn/ePm/Rwhaode3qxxiHJi0NVq7MPiR+/nnv3VzBDg2qXRsSEvb+t3ZtG9iO0v8ho6JrSEQ+BJ5T1fGZHrsGOFJVB+b2Ph4Erjj46y8YPtymn/7wg62vytj51HeIjiIZC+aWLrUWxbJle//7yy8WJBni4mynwqwhkfFv9eqhTSULPQhEJAGYBDRW1T8zPf4U1iXUCCgPPK2qb+7rXh4ErjhJT4exY20cYeJEC4FevWxg+Zhjwq7O7dfu3bBqVfYhsWwZrF695/hRsD2aatXKPiQSEmwWVEDjE6EGgYiUAyYCD6nq6CzPPQckA6cAZYDvgLNU9ccs1/UB+gDUqlWrxYoVKwKt2bkwTJ9u4wijRlmXdceOcN119m8xHLuMDTt2WLdTdiGxbBn89tve15cubYGQU4uicuV8DyqFFgQiUgr4BBinqk9k8/wAoIyq3hP5+jXgc1X9b0739BaBK+7WroVXXrEFamvX2lhl377WUvCp8cXMtm12FGnmcMgcGBs37n19//7WfMyHsAaLBRgG/K6q/XK4pgHwHHAGcBAwDbhIVefndF8PAhcrdu609QjPPgvffGOL0i67zEKhSZOwq3OF4s8/LSgyQiIx0aaa5UNYQXAiMBmYB2RM4L0DqAWgqkMi190C9Ipc86qqPrWv+3oQuFg0axY895zta7R9O3ToANdeC+eeW4TOWXahCn2wuCB5ELhYtnEjvPaaTUFdscImqPzf/9lso8MPD7s6F832FQQ+BOVcEVKpEtx6q01x/+ADqF8f7rzTpq9ffrkNODuXVx4EzhVBJUpYt9D48XbM8FVXwejR0KoVtG4NI0bsfSa9c/viQeBcEdeggY0frF5tR2r+8YcNKteqBXfdZdPcndsXDwLniolDDrF1B4sW2elpxx0HDz1kU9AvvBAmTdp7bZNzGTwInCtm4uLgtNNsx9MlS+DGG+14zfbtbfbhK6/Y9HXnMngQOFeM1a5t5yKsWmUBANCnj215c/PNtoWOcx4EzsWAsmVtiuns2dZFdPrp8NRTtsty584wbtze2/W72OJB4FwMEYG2beHdd20dwsCBMG2a7WfUoIENNv/55/7v44oXDwLnYlT16nD//baT8ogRdrLjDTfY49dcA3Pnhl2hKyweBM7FuNKl4dJL4bvvbEFaly4wdCg0awbHHw+vv+6Dy8WdB4Fz7m/JyXac5urVtiX2pk3wr3/ZMb7XXgvz5oVdoQuCB4Fz7h8qVYJ+/WzV8qRJcPbZ8Oqr0LSptRLeeMNbCcWJB4FzLkcZg8sjRlgr4YknrJXQq5e1Eq67zlsJxYEHgXMuVypVssVpCxfasZpnn21rE5o2hRNO8FZCUeZB4JzLExFo127vVsLvv+/dSpif49FSLhp5EDjn8i2jlbBokbUSzjoLXn7ZTlBr0waGDfNWQlHgQeCcO2AZrYSRI2HNGjtWd+NGuOIKW5dw/fXeSohmHgTOuQJVqZKdsb5oEUyYAGeeCS+9tHcr4a+/wq7SZeZB4JwLhIjteDpypI0lZG4lHHmktRIWLAi7SgceBM65QlC58t6thE6drJXQuLG1Et5801sJYQosCESkpoikiMhCEVkgIjfs49qWIrJbRLoGVY9zLnwZrYS33rJWwuDBsGGDnbd85JG215G3EgpfkC2C3cBNqtoQaA30FZGGWS8SkRLAY8AXAdbinIsylSvDTTfB4sV7WglDhlgr4cQTvZVQmAILAlVdq6ozI59vARYB1bO59DrgfWBdULU456JXdq2E9eutlVCtmu2Emprqx2wGqVDGCEQkAUgCvs/yeHXgfODF/Xx/HxFJFZHU9evXB1ancy5cmVsJKSl2aM7rr0PLlrYb6lNPWUi4ghV4EIhIOewdfz9VzXrkxVPAbaq6z7ORVPVlVU1W1eQqVaoEVKlzLlqIQIcOMHw4rF1rXUZlytjiterVbavssWNh9+6wKy0eRANsb4lIKeATYJyqPpHN88sAiXxZGdgG9FHVD3K6Z3JysqampgZQrXMu2s2fby2E4cOtZVCtmnUh9eoF9eqFXV10E5EZqpqc3XNBzhoS4DVgUXYhAKCqtVU1QVUTgFHANfsKAedcbGvc2NYjrFoFY8bY+QmDBsGxx9ouqUOHwpYtYVdZ9ATZNdQGuAw4WURmRz7OFJGrReTqAF/XOVfMHXQQnHcefPQRrFwJjz1mLYQrr7RWwr/+BVOm+ABzbgXaNRQE7xpyzmVHFaZOtVbBO+/A1q1wzDHWbdSzp40txLJQuoacc64widjpaa+8Ar/+aucjVKsGd9wBtWrZzqjvvw87d4ZdafTxIHDOFTsHH2yDyBMnwk8/we23w5w50LWrtQxuvBHmzg27yujhQeCcK9bq1oUHH4QVK+Czz+Ckk+D5521dQnIyvPAC/PFH2FWGy4PAORcTSpSAjh3hvffszISnn7Z1CH37WhfSJZfA+PGQvs9VTcWTB4FzLuZUrmzbYM+eDTNnwlVXweefw+mnQ+3acM89sGxZ2FUWHg8C51xMS0qCZ5+1VsI770D9+vDAA1CnDpxyip3NXNyP2/QgcM45ID4euneHceNg+XILg+XL4bLL4IgjbG1CSkrx7DryIHDOuSxq1YKBA23GUUqKzTYaNQpOPhkSEmwW0sKFYVdZcDwInHMuB3Fxtvnd0KG2NuHtt+3s5UGDoFEjaNHCdkT97bewKz0wHgTOOZcLZcvCRRfZrqerV8OTT9rjGTuinnmmBUVRHE/wIHDOuTyqWhX69YMZM+xozVtusZ1RL7nExhN69YKvvy464wkeBM45dwAaNoRHHrGB5a+/tvGE99+3GUdHHVU0xhM8CJxzrgDExdmq5czjCU2bFo3xBA8C55wrYFnHE556yjbFi9bxBA8C55wLUNWqcMMNkJoaveMJHgTOOVdI9jeeMGCAhUVh8yBwzrlCltN4wuDBdhxn8+Y2PfXXXwupnsJ5Geecc9nJbjwhLg7694caNQpnPMGDwDnnokTm8YSFC+HWW/ceT3jiiWBeN7AgEJGaIpIiIgtFZIGI3JDNNZeKyFwRmSci34pIs6Dqcc65oqRBA3j4YRtPSEmBbt2gZs1gXqtkMLcFYDdwk6rOFJHywAwRGa+qmZdWLAPaq+ofItIJeBk4LsCanHOuSMnY76hDh+BeI7AgUNW1wNrI51tEZBFQHViY6ZpvM33LVKBGUPU455zLXqGMEYhIApAEfL+Py64EPsvh+/uISKqIpK5fvz6ACp1zLnYFHgQiUg54H+inqn/mcM1JWBDclt3zqvqyqiaranKVKlWCK9Y552JQkGMEiEgpLARGquroHK5pCrwKdFLVjUHW45xz7p+CnDUkwGvAIlXNdtKTiNQCRgOXqeqPQdXinHMuZ0G2CNoAlwHzRGR25LE7gFoAqjoEuBuoBLxgucFuVU0OsCbnnHNZBDlraAog+7mmN9A7qBqcc87tn68sds65GCeqGnYNeSIi64EV+fz2ysCGAiynqPPfx97897GH/y72Vhx+H0eparbTLotcEBwIEUn1MYg9/PexN/997OG/i70V99+Hdw0551yM8yBwzrkYF2tB8HLYBUQZ/33szX8fe/jvYm/F+vcRU2MEzjnn/inWWgTOOeey8CBwzrkYFzNBICIdReQHEflZRAaEXU+YcnN6XKwRkRIiMktEPgm7lrCJSAURGSUii0VkkYgcH3ZNYRGRGyP/jcwXkbdFJD7smoIQE0EgIiWA54FOQEPgYhFpGG5Voco4Pa4h0BroG+O/D4AbgEVhFxElngY+V9X6QDNi9PciItWB64FkVW0MlAAuCreqYMREEACtgJ9Vdamq7gTeAc4NuabQqOpaVZ0Z+XwL9h969XCrCo+I1ADOwrZDj2kicijQDts5GFXdqaqbQi0qXCWBMiJSEigLrAm5nkDEShBUB1Zm+noVMfyHL7Ncnh5X3D0F3Aqkh1xHNKgNrAdej3SVvSoiB4ddVBhUdTUwGPgFO3Z3s6p+EW5VwYiVIHDZyM3pccWdiJwNrFPVGWHXEiVKAs2BF1U1CfgfEJNjaiJSEes5qA0cCRwsIj3CrSoYsRIEq4Gamb6uEXksZuXm9LgY0QY4R0SWY12GJ4vIiHBLCtUqYJWqZrQQR2HBEItOBZap6npV3YUdonVCyDUFIlaCYDpwjIjUFpGDsAGfj0KuKTS5OT0uVqjq7apaQ1UTsP9ffK2qxfJdX26o6q/AShE5NvLQKcDCEEsK0y9AaxEpG/lv5hSK6cB5oGcWRwtV3S0i1wLjsJH/oaq6IOSywpTt6XGq+ml4Jbkoch0wMvKmaSnQK+R6QqGq34vIKGAmNtNuFsV0qwnfYsI552JcrHQNOeecy4EHgXPOxTgPAueci3EeBM45F+M8CJxzLsZ5EDhXiESkg+9w6qKNB4FzzsU4DwLnsiEiPURkmojMFpGXIucVbBWRJyP7038lIlUi1yaKyFQRmSsiYyJ71CAidUXkSxGZIyIzReToyO3LZdrvf2Rk1apzofEgcC4LEWkAdAfaqGoikAZcChwMpKpqI2AicE/kW94EblPVpsC8TI+PBJ5X1WbYHjVrI48nAf2wszHqYCu9nQtNTGwx4VwenQK0AKZH3qyXAdZh21S/G7lmBDA6sn9/BVWdGHl8GPBfESkPVFfVMQCquh0gcr9pqroq8vVsIAGYEvhP5VwOPAic+ycBhqnq7Xs9KHJXluvyuz/Ljkyfp+H/HbqQedeQc//0FdBVRA4HEJHDROQo7L+XrpFrLgGmqOpm4A8RaRt5/DJgYuTkt1Uicl7kHqVFpGxh/hDO5Za/E3EuC1VdKCIDgS9EJA7YBfTFDmlpFXluHTaOAHA5MCTyhz7zbp2XAS+JyP2Re3QrxB/DuVzz3UedyyUR2aqq5cKuw7mC5l1DzjkX47xF4JxzMc5bBM45F+M8CJxzLsZ5EDjnXIzzIHDOuRjnQeCcczHu/wFdH+F7BT//pgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습 그래프 그리기\n",
    "def loss_graph(history):\n",
    "    %matplotlib inline\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fig, loss_ax = plt.subplots()\n",
    "\n",
    "    loss_ax.plot(history.history['loss'], 'b', label='train loss')\n",
    "    loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "    loss_ax.set_xlabel('epoch')\n",
    "    loss_ax.set_ylabel('loss')\n",
    "\n",
    "    loss_ax.legend(loc='upper right')\n",
    "\n",
    "    plt.show()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "improving-revolution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      multiple                  6144512   \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                multiple                  6295552   \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                multiple                  8392704   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  12301025  \n",
      "=================================================================\n",
      "Total params: 33,133,793\n",
      "Trainable params: 33,133,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "527/527 [==============================] - 210s 392ms/step - loss: 4.0869 - val_loss: 3.2006\n",
      "Epoch 2/10\n",
      "527/527 [==============================] - 209s 396ms/step - loss: 3.1079 - val_loss: 2.9859\n",
      "Epoch 3/10\n",
      "527/527 [==============================] - 209s 396ms/step - loss: 2.8816 - val_loss: 2.8645\n",
      "Epoch 4/10\n",
      "527/527 [==============================] - 209s 396ms/step - loss: 2.7287 - val_loss: 2.7721\n",
      "Epoch 5/10\n",
      "527/527 [==============================] - 208s 395ms/step - loss: 2.5879 - val_loss: 2.7016\n",
      "Epoch 6/10\n",
      "527/527 [==============================] - 208s 395ms/step - loss: 2.4583 - val_loss: 2.6426\n",
      "Epoch 7/10\n",
      "527/527 [==============================] - 208s 395ms/step - loss: 2.3457 - val_loss: 2.5960\n",
      "Epoch 8/10\n",
      "527/527 [==============================] - 208s 394ms/step - loss: 2.2316 - val_loss: 2.5572\n",
      "Epoch 9/10\n",
      "527/527 [==============================] - 208s 394ms/step - loss: 2.1244 - val_loss: 2.5214\n",
      "Epoch 10/10\n",
      "527/527 [==============================] - 207s 393ms/step - loss: 2.0250 - val_loss: 2.4940\n"
     ]
    }
   ],
   "source": [
    "# model 2\n",
    "embedding_size = 512\n",
    "hidden_size = 1024\n",
    "model2 = TextGenerator(vocab_size, embedding_size , hidden_size)\n",
    "model2(src_sample)\n",
    "model2.summary()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "model2.compile(loss=loss, optimizer=optimizer)\n",
    "\n",
    "hist = model2.fit(enc_train, dec_train, \n",
    "          epochs=10,\n",
    "          batch_size=256,\n",
    "          validation_data=(enc_val, dec_val),\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "veterinary-disclaimer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      multiple                  12289024  \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                multiple                  8392704   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                multiple                  8392704   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  12301025  \n",
      "=================================================================\n",
      "Total params: 41,375,457\n",
      "Trainable params: 41,375,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "527/527 [==============================] - 217s 407ms/step - loss: 4.0040 - val_loss: 3.1382\n",
      "Epoch 2/10\n",
      "527/527 [==============================] - 217s 412ms/step - loss: 3.0434 - val_loss: 2.9465\n",
      "Epoch 3/10\n",
      "527/527 [==============================] - 217s 412ms/step - loss: 2.8345 - val_loss: 2.8249\n",
      "Epoch 4/10\n",
      "527/527 [==============================] - 217s 412ms/step - loss: 2.6730 - val_loss: 2.7290\n",
      "Epoch 5/10\n",
      "527/527 [==============================] - 217s 412ms/step - loss: 2.5207 - val_loss: 2.6539\n",
      "Epoch 6/10\n",
      "527/527 [==============================] - 217s 411ms/step - loss: 2.3773 - val_loss: 2.5938\n",
      "Epoch 7/10\n",
      "527/527 [==============================] - 217s 411ms/step - loss: 2.2482 - val_loss: 2.5392\n",
      "Epoch 8/10\n",
      "527/527 [==============================] - 217s 412ms/step - loss: 2.1171 - val_loss: 2.4982\n",
      "Epoch 9/10\n",
      "527/527 [==============================] - 216s 410ms/step - loss: 1.9902 - val_loss: 2.4635\n",
      "Epoch 10/10\n",
      "527/527 [==============================] - 216s 410ms/step - loss: 1.8659 - val_loss: 2.4391\n"
     ]
    }
   ],
   "source": [
    "# model 3\n",
    "embedding_size = 1024\n",
    "hidden_size = 1024\n",
    "model3 = TextGenerator(vocab_size, embedding_size , hidden_size)\n",
    "model3(src_sample)\n",
    "model3.summary()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "model3.compile(loss=loss, optimizer=optimizer)\n",
    "\n",
    "hist = model3.fit(enc_train, dec_train, \n",
    "          epochs=10,\n",
    "          batch_size=256,\n",
    "          validation_data=(enc_val, dec_val),\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessible-uncertainty",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean-entity",
   "metadata": {},
   "source": [
    "### 4.2 2차 모델 설계 (레이어 추가)\n",
    "\n",
    "__데이터__\n",
    "- Source Train: (134872, 14)\n",
    "- Target Train: (134872, 14)\n",
    "- Source Validation: (33718, 14)\n",
    "- Target Validation: (33718, 14)\n",
    "\n",
    "\n",
    "__모델설계__\n",
    "\n",
    "[Model4]\n",
    "- RNN 레이어 3개\n",
    "- embedding_size = 256\n",
    "- hidden_size = 1024\n",
    "- n_train_epoch = 10\n",
    "\n",
    "[Model5]\n",
    "- RNN 레이어 3개\n",
    "- embedding_size = 512\n",
    "- hidden_size = 1024\n",
    "- n_train_epoch = 10  \n",
    "\n",
    "[Model6]\n",
    "- RNN 레이어 3개\n",
    "- embedding_size = 1024\n",
    "- hidden_size = 1024\n",
    "- n_train_epoch = 10  \n",
    "\n",
    "\n",
    "__실행방법__\n",
    "\n",
    "훈련셋을 train,validation으로 분리한다. 설계된 모델은 기존보다 RNN레이어를 한 층 더 추가하였다,  __하이퍼파라미터__를 조정하며 train으로 훈련하고 validation으로 loss를 평가한다.최종 평가는 생성하는 문장을 확인한다.\n",
    "\n",
    "__결과__\n",
    "\n",
    "Train과 validation의 loss 결과<br>\n",
    "참고용으로 확인한 loss \n",
    "\n",
    "[Model4] \n",
    "loss: 2.5717  - val_loss: 2.7989\n",
    "\n",
    "[Model5]\n",
    "loss: 2.5000  - val_loss: 2.7536\n",
    "\n",
    "[Model6]\n",
    "loss: 2.4000  - val_loss: 2.7019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "meaning-greenhouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 설계\n",
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_3 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.rnn_3(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "criminal-doubt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련 및 검증 함수\n",
    "def train_val_model(embedding_size, hidden_size):\n",
    "    model = TextGenerator(vocab_size, embedding_size , hidden_size)\n",
    "#     model(src_sample)\n",
    "#     model.summary()\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')\n",
    "\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "\n",
    "    hist = model.fit(enc_train, dec_train, \n",
    "              epochs=10,\n",
    "              batch_size=256,\n",
    "              validation_data=(enc_val, dec_val),\n",
    "              verbose=1)\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "physical-heavy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "527/527 [==============================] - 243s 448ms/step - loss: 4.1457 - val_loss: 3.3113\n",
      "Epoch 2/10\n",
      "527/527 [==============================] - 237s 450ms/step - loss: 3.2490 - val_loss: 3.1979\n",
      "Epoch 3/10\n",
      "527/527 [==============================] - 238s 451ms/step - loss: 3.1376 - val_loss: 3.1055\n",
      "Epoch 4/10\n",
      "527/527 [==============================] - 239s 453ms/step - loss: 3.0137 - val_loss: 3.0254\n",
      "Epoch 5/10\n",
      "527/527 [==============================] - 240s 455ms/step - loss: 2.9204 - val_loss: 2.9699\n",
      "Epoch 6/10\n",
      "527/527 [==============================] - 239s 454ms/step - loss: 2.8305 - val_loss: 2.9189\n",
      "Epoch 7/10\n",
      "527/527 [==============================] - 239s 453ms/step - loss: 2.7533 - val_loss: 2.8791\n",
      "Epoch 8/10\n",
      "527/527 [==============================] - 239s 453ms/step - loss: 2.6873 - val_loss: 2.8488\n",
      "Epoch 9/10\n",
      "527/527 [==============================] - 239s 453ms/step - loss: 2.6303 - val_loss: 2.8248\n",
      "Epoch 10/10\n",
      "527/527 [==============================] - 238s 452ms/step - loss: 2.5717 - val_loss: 2.7989\n"
     ]
    }
   ],
   "source": [
    "# model 4\n",
    "hist4 = train_val_model(256, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "capable-confusion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "527/527 [==============================] - 256s 472ms/step - loss: 4.1406 - val_loss: 3.2830\n",
      "Epoch 2/10\n",
      "527/527 [==============================] - 248s 470ms/step - loss: 3.2036 - val_loss: 3.1203\n",
      "Epoch 3/10\n",
      "527/527 [==============================] - 248s 471ms/step - loss: 3.0388 - val_loss: 3.0244\n",
      "Epoch 4/10\n",
      "527/527 [==============================] - 248s 471ms/step - loss: 2.9252 - val_loss: 2.9543\n",
      "Epoch 5/10\n",
      "527/527 [==============================] - 248s 470ms/step - loss: 2.8418 - val_loss: 2.9119\n",
      "Epoch 6/10\n",
      "527/527 [==============================] - 247s 470ms/step - loss: 2.7584 - val_loss: 2.8656\n",
      "Epoch 7/10\n",
      "527/527 [==============================] - 247s 469ms/step - loss: 2.6851 - val_loss: 2.8319\n",
      "Epoch 8/10\n",
      "527/527 [==============================] - 247s 469ms/step - loss: 2.6203 - val_loss: 2.7995\n",
      "Epoch 9/10\n",
      "527/527 [==============================] - 246s 467ms/step - loss: 2.5559 - val_loss: 2.7807\n",
      "Epoch 10/10\n",
      "527/527 [==============================] - 247s 468ms/step - loss: 2.5000 - val_loss: 2.7536\n"
     ]
    }
   ],
   "source": [
    "# model 5\n",
    "hist5 = train_val_model(512, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "neither-insert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "527/527 [==============================] - 282s 523ms/step - loss: 4.0708 - val_loss: 3.2527\n",
      "Epoch 2/10\n",
      "527/527 [==============================] - 274s 521ms/step - loss: 3.1687 - val_loss: 3.0913\n",
      "Epoch 3/10\n",
      "527/527 [==============================] - 275s 521ms/step - loss: 3.0061 - val_loss: 2.9902\n",
      "Epoch 4/10\n",
      "527/527 [==============================] - 275s 521ms/step - loss: 2.8790 - val_loss: 2.9224\n",
      "Epoch 5/10\n",
      "527/527 [==============================] - 274s 521ms/step - loss: 2.7750 - val_loss: 2.8653\n",
      "Epoch 6/10\n",
      "527/527 [==============================] - 274s 520ms/step - loss: 2.7001 - val_loss: 2.8212\n",
      "Epoch 7/10\n",
      "527/527 [==============================] - 274s 520ms/step - loss: 2.6154 - val_loss: 2.7842\n",
      "Epoch 8/10\n",
      "527/527 [==============================] - 274s 520ms/step - loss: 2.5389 - val_loss: 2.7500\n",
      "Epoch 9/10\n",
      "527/527 [==============================] - 274s 520ms/step - loss: 2.4685 - val_loss: 2.7238\n",
      "Epoch 10/10\n",
      "527/527 [==============================] - 273s 518ms/step - loss: 2.4000 - val_loss: 2.7019\n"
     ]
    }
   ],
   "source": [
    "# model 6\n",
    "hist6 = train_val_model(1024, 1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lovely-lexington",
   "metadata": {},
   "source": [
    "LSTM 레이어를 더 추가했지만 정확도는 기존 심층 LSTM에 비해 떨어지는 것을 볼 수 있다.😥<br>\n",
    "레이어 추가 외에 RNN을 개선하는 방법에는 양방향 RNN이 있다고 한다..!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guilty-business",
   "metadata": {},
   "source": [
    "> ### 양방향 RNN (Bidirectional RNN)\n",
    "    - 기존의 RNN은 한 방향(forwad)으로 학습이 진행되지만, 양방향 RNN은 역방향으로의 순서도 고려하여 학습하는 모델이다.\n",
    "    - 두 개의 RNN모델(순방향, 역방향)을 만들어 학습 결과를 합치는 모델에 가깝다.\n",
    "![bidirectional_RNN](http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/09/bidirectional-rnn.png)\n",
    "[참고](https://buomsoo-kim.github.io/keras/2019/07/29/Easy-deep-learning-with-Keras-20.md/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-absolute",
   "metadata": {},
   "source": [
    "### 4.3 3차 모델 설계 (양방향 RNN)\n",
    "\n",
    "__데이터__\n",
    "- Source Train: (134872, 14)\n",
    "- Target Train: (134872, 14)\n",
    "- Source Validation: (33718, 14)\n",
    "- Target Validation: (33718, 14)\n",
    "\n",
    "\n",
    "__모델설계__\n",
    "\n",
    "[Model7]\n",
    "- 양방향 RNN 레이어 2개\n",
    "- embedding_size = 256\n",
    "- hidden_size = 1024\n",
    "- n_train_epoch = 10\n",
    "\n",
    "[Model8]\n",
    "- \\<start>, \\<end>를 제거한 데이터셋\n",
    "- 양방향 RNN 레이어 2개\n",
    "- embedding_size = 256\n",
    "- hidden_size = 1024\n",
    "- n_train_epoch = 10\n",
    "\n",
    "[Model9]\n",
    "- \\<start>, \\<end>를 제거한 데이터셋\n",
    "- 양방향 RNN 레이어 2개\n",
    "- Dropout 레이어 1개\n",
    "- embedding_size = 256\n",
    "- hidden_size = 1024\n",
    "- n_train_epoch = 10\n",
    "\n",
    "\n",
    "__실행방법__\n",
    "\n",
    "훈련셋을 train,validation으로 분리한다. 양방향 LSTM 레이어를 쌓아 train으로 훈련하고 validation으로 loss를 평가한다.필요한 경우 과적합을 방지하기 위해 dropout 레이어를 추가하여 모델을 설계하고 훈련시켰다. 최종 평가는 생성하는 문장을 확인한다.\n",
    "\n",
    "__결과__\n",
    "\n",
    "Train과 validation의 loss 결과<br>\n",
    "참고용으로 확인한 loss \n",
    "\n",
    "[Model7] \n",
    "loss: 2.5892e-04 - val_loss: 0.0669 # over fitting\n",
    "\n",
    "[Model8] \n",
    "loss: 6.4103e-04 - val_loss: 0.0902\n",
    "\n",
    "[Model9] 시간관계상 모델을 돌려보지 못했다 추후 시도해볼 예정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cardiac-christmas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 설계\n",
    "from keras.layers import Bidirectional\n",
    "\n",
    "class TextGenerator_Bidirectional(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(hidden_size, return_sequences=True))\n",
    "        self.rnn_2 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(hidden_size, return_sequences=True))\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acknowledged-grill",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련 및 검증 함수\n",
    "vocab_size =tokenizer.num_words + 1\n",
    "def train_val_model(embedding_size, hidden_size):\n",
    "    model = TextGenerator_Bidirectional(vocab_size, embedding_size , hidden_size)\n",
    "#     model(src_sample)\n",
    "#     model.summary()\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')\n",
    "\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "\n",
    "    hist = model.fit(enc_train, dec_train, \n",
    "              epochs=10,\n",
    "              batch_size=256,\n",
    "              validation_data=(enc_val, dec_val),\n",
    "              verbose=1)\n",
    "    return model, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "middle-belly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "527/527 [==============================] - 437s 813ms/step - loss: 3.0920 - val_loss: 0.4181\n",
      "Epoch 2/10\n",
      "527/527 [==============================] - 428s 812ms/step - loss: 0.2566 - val_loss: 0.1365\n",
      "Epoch 3/10\n",
      "527/527 [==============================] - 430s 815ms/step - loss: 0.0500 - val_loss: 0.0909\n",
      "Epoch 4/10\n",
      "527/527 [==============================] - 431s 819ms/step - loss: 0.0101 - val_loss: 0.0747\n",
      "Epoch 5/10\n",
      "527/527 [==============================] - 429s 814ms/step - loss: 0.0028 - val_loss: 0.0676\n",
      "Epoch 6/10\n",
      "527/527 [==============================] - 427s 810ms/step - loss: 0.0012 - val_loss: 0.0643\n",
      "Epoch 7/10\n",
      "527/527 [==============================] - 426s 809ms/step - loss: 0.0103 - val_loss: 0.1200\n",
      "Epoch 8/10\n",
      "527/527 [==============================] - 431s 818ms/step - loss: 0.0182 - val_loss: 0.0775\n",
      "Epoch 9/10\n",
      "527/527 [==============================] - 432s 820ms/step - loss: 0.0013 - val_loss: 0.0686\n",
      "Epoch 10/10\n",
      "527/527 [==============================] - 431s 818ms/step - loss: 2.5892e-04 - val_loss: 0.0669\n"
     ]
    }
   ],
   "source": [
    "# model 7\n",
    "model, hist7 = train_val_model(256, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "saving-farmer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAoE0lEQVR4nO3de3iU5Z3/8feXJAQDQU6pBwKCihbCaWKg9IeCrYdqtR5WLVCtp6rbXa3r2rXSo9baXVq9tl1bW0sVT7UqRV1tZYu6arFbtaKGg1IUI8hBSwRBaLCE8P39cc/AJEzCJJknTyb5vK5rrpl5DjPfDCGfuZ/7fu7H3B0REZGmesRdgIiIdE4KCBERyUgBISIiGSkgREQkIwWEiIhkVBh3Abk0aNAgHzZsWNxliIjkjZdffvl9dy/LtK5LBcSwYcNYtGhR3GWIiOQNM1vd3DodYhIRkYwUECIikpECQkREMupSfRAi0nXV19ezdu1aPvroo7hLyUu9evWivLycoqKirPdRQIhIXli7di2lpaUMGzYMM4u7nLzi7mzcuJG1a9cyfPjwrPfTISYRyQsfffQRAwcOVDi0gZkxcODAVre+FBAikjcUDm3Xls+u2wdEfT3MmgVPPhl3JSIinUtkAWFmc8xsg5kta2b9NWZWnbwtM7MGMxuQXLfKzJYm10V65lthIdx0E8ydG+W7iEg+27x5Mz/72c/atO9nP/tZNm/enPX2119/PTfffHOb3ivXomxB3AWc1NxKd7/J3ce7+3jg68Af3H1T2iafSq6virBGzCCRgFdfjfJdRCSftRQQO3fubHHf+fPn069fvwiqil5kAeHuC4FN+9wwmAHcH1Ut+5JIwNKl4XCTiEhTM2fO5K233mL8+PFcc801PPvssxxzzDGcdtppjBo1CoAzzjiDo446ioqKCmbPnr1732HDhvH++++zatUqRo4cyaWXXkpFRQUnnngi27dvb/F9q6urmTRpEmPHjuXMM8/kgw8+AOCWW25h1KhRjB07lunTpwPwhz/8gfHjxzN+/HgSiQRbt25t988d+zBXMyshtDSuSFvswBNm5sAv3H12xp3D/pcBlwEMHTq0TTVUVsKOHbB8OYwd26aXEJEOdNVVUF2d29ccPx5+/OPM62bNmsWyZcuoTr7ps88+yyuvvMKyZct2DxudM2cOAwYMYPv27UyYMIGzzjqLgQMHNnqdN998k/vvv59f/vKXfP7zn+ehhx7ivPPOa7am888/n5/85CdMnTqV73znO3z3u9/lxz/+MbNmzeLtt9+muLh49+Grm2++mVtvvZXJkyezbds2evXq1c5PpHN0Un8O+L8mh5eOdvdK4GTgcjOb0tzO7j7b3avcvaqsLOOEhPuUSIT7V15p0+4i0g1NnDix0TkFt9xyC+PGjWPSpEmsWbOGN998c699hg8fzvjx4wE46qijWLVqVbOvv2XLFjZv3szUqVMBuOCCC1i4cCEAY8eO5dxzz+VXv/oVhYXhe/7kyZO5+uqrueWWW9i8efPu5e0RewsCmE6Tw0vuvi55v8HMHgEmAgujKmDECCgpCf0QF14Y1buISK40902/I/Xu3Xv342effZannnqK559/npKSEo499tiM5xwUFxfvflxQULDPQ0zNefzxx1m4cCG//e1v+f73v8/SpUuZOXMmp5xyCvPnz2fy5MksWLCAj3/84216/ZRYWxBmtj8wFXg0bVlvMytNPQZOBDKOhMqVggIYN04d1SKSWWlpaYvH9Lds2UL//v0pKSnhL3/5Cy+88EK733P//fenf//+PPfccwDce++9TJ06lV27drFmzRo+9alP8YMf/IAtW7awbds23nrrLcaMGcO1117LhAkT+Mtf/tLuGiJrQZjZ/cCxwCAzWwtcBxQBuPttyc3OBJ5w97+l7XoA8EjypI5C4Nfu/vuo6kyprIR77oFdu6BHZzjwJiKdxsCBA5k8eTKjR4/m5JNP5pRTTmm0/qSTTuK2225j5MiRHHnkkUyaNCkn73v33Xfz5S9/mbq6Og499FDuvPNOGhoaOO+889iyZQvuzpVXXkm/fv349re/zTPPPEOPHj2oqKjg5JNPbvf7m7vn4MfoHKqqqrytFwy64w645BJ48004/PAcFyYi7bZ8+XJGjhwZdxl5LdNnaGYvN3c6gb4rJ6mjWkSkMQVEUkVFOKta/RAiIoECIqm4GEaPVkCIiKQoINIkEuEQUxfqlhERaTMFRJpEAmprYf36uCsREYmfAiJNqqNah5lERBQQjYwbF2Z3VUCISHv16dOnVcs7IwVEmtLSMO2GAkJERAGxl1RHtYhIysyZM7n11lt3P09d1Gfbtm0cd9xxVFZWMmbMGB599NEWXqUxd+eaa65h9OjRjBkzhgcffBCAd999lylTpjB+/HhGjx7Nc889R0NDAxdeeOHubX/0ox/l/GfMpDNM1tepJBLw4IOwaRMMGBB3NSKSUQfP9z1t2jSuuuoqLr/8cgDmzp3LggUL6NWrF4888gh9+/bl/fffZ9KkSZx22mlZXf/54Ycfprq6msWLF/P+++8zYcIEpkyZwq9//Ws+85nP8M1vfpOGhgbq6uqorq5m3bp1LFsWpqVrzRXq2kMtiCZSHdW5/t0TkfyVSCTYsGED69evZ/HixfTv358hQ4bg7nzjG99g7NixHH/88axbt46//vWvWb3mH//4R2bMmEFBQQEHHHAAU6dO5aWXXmLChAnceeedXH/99SxdupTS0lIOPfRQampq+MpXvsLvf/97+vbtG/FPHKgF0UT6SKZPfzreWkSkGTHM933OOecwb9483nvvPaZNmwbAfffdR21tLS+//DJFRUUMGzYs4zTfrTFlyhQWLlzI448/zoUXXsjVV1/N+eefz+LFi1mwYAG33XYbc+fOZc6cObn4sVqkFkQTZWVQXq6OahFpbNq0aTzwwAPMmzePc845BwjTfH/sYx+jqKiIZ555htWrV2f9escccwwPPvggDQ0N1NbWsnDhQiZOnMjq1as54IADuPTSS7nkkkt45ZVXeP/999m1axdnnXUWN954I690UEepWhAZqKNaRJqqqKhg69atDB48mIMOOgiAc889l8997nOMGTOGqqqqVl2g58wzz+T5559n3LhxmBk//OEPOfDAA7n77ru56aabKCoqok+fPtxzzz2sW7eOiy66iF27dgHwH//xH5H8jE1puu8MrrsObrwRtm4NV5oTkfhpuu/203TfOVBZGS4ctGRJ3JWIiMRHAZGBptwQEVFAZDRkSDgHQv0QIp1LVzok3tHa8tkpIDIwC60ItSBEOo9evXqxceNGhUQbuDsbN26kV69erdovslFMZjYHOBXY4O6jM6w/FngUeDu56GF3vyG57iTgv4AC4HZ3nxVVnc1JJOCWW6C+HoqKOvrdRaSp8vJy1q5dS21tbdyl5KVevXpRXl7eqn2iHOZ6F/BT4J4WtnnO3U9NX2BmBcCtwAnAWuAlM3vM3V+PqtBMKithxw5YvhzGju3IdxaRTIqKihg+fHjcZXQrkR1icveFwKY27DoRWOnuNe6+A3gAOD2nxWUh1VGtfggR6a7i7oP4pJktNrP/MbOK5LLBwJq0bdYml2VkZpeZ2SIzW5TLpueIEeEcCPVDiEh3FWdAvAIc4u7jgJ8A/92WF3H32e5e5e5VZWVlOSuuoCBcQEgBISLdVWwB4e4fuvu25OP5QJGZDQLWAUPSNi1PLutwlZVhVtfk2e0iIt1KbAFhZgdactJ0M5uYrGUj8BIwwsyGm1lPYDrwWBw1JhJhuo2amjjeXUQkXlEOc70fOBYYZGZrgeuAIgB3vw04G/gnM9sJbAemexjgvNPMrgAWEIa5znH316KqsyXpHdWHHx5HBSIi8YksINx9xj7W/5QwDDbTuvnA/Cjqao2KCigsDP0Qn/983NWIiHSsuEcxdWrFxSEk1FEtIt2RAmIfKivDISad3S8i3Y0CYh8SCaithfXr465ERKRjKSD2QVN/i0h3pYDYh3HjwuyuCggR6W4UEPtQWhqm3VBAiEh3o4DIQiKhSftEpPtRQGQhkYDVq2FTW+amFRHJUwqILKQ6qqurYy1DRKRDKSCyoJFMItIdKSCyUFYG5eUKCBHpXhQQWVJHtYh0NwqILCUSsGIF1NXFXYmISMdQQGQpkQgXDlqyJO5KREQ6hgIiS5WV4V79ECLSXSggsjRkCAwYoH4IEek+FBBZMguHmdSCEJHuQgHRCokELF0K9fVxVyIiEj0FRCtUVsKOHbB8edyViIhEL7KAMLM5ZrbBzJY1s/5cM1tiZkvN7E9mNi5t3ark8mozWxRVja2VOqNa/RAi0h1E2YK4CziphfVvA1PdfQzwPWB2k/Wfcvfx7l4VUX2tNmIElJSoH0JEuofCqF7Y3Rea2bAW1v8p7ekLQHlUteRKQUG4gJACQkS6g87SB/El4H/SnjvwhJm9bGaXtbSjmV1mZovMbFFtbW2kRULoh6iuDifNiYh0ZbEHhJl9ihAQ16YtPtrdK4GTgcvNbEpz+7v7bHevcveqsrKyiKsN/RBbt0JNTeRvJSISq1gDwszGArcDp7v7xtRyd1+XvN8APAJMjKfCvamjWkS6i9gCwsyGAg8DX3T3N9KW9zaz0tRj4EQg40ioOFRUQGGh+iFEpOuLrJPazO4HjgUGmdla4DqgCMDdbwO+AwwEfmZmADuTI5YOAB5JLisEfu3uv4+qztYqLg4hoYAQka4uylFMM/ax/hLgkgzLa4Bxe+/ReVRWwu9+B+5hCg4Rka4o9k7qfJRIQG0trF8fdyUiItFRQLSBrlEtIt2BAqINxo0Lh5YUECLSlSkg2qC0NEy7oYAQka5MAdFGiYTOhRCRrk0B0UaJBKxeDZs2xV2JiEg0FBBtlOqorq6OtQwRkcgoINpII5lEpKtTQLRRWRmUlysgRKTrUkC0gzqqRaQrU0C0QyIBK1ZAXV3clYiI5J4Coh0SiXDhoCVL4q5ERCT3FBDtUFkZ7tUPISJdkQKiHYYMgQED1A8hIl2TAqIdzMJhJrUgRKQrUkC0UyIBS5dCfX3clYiI5JYCop0qK2HHDli+PO5KRERySwHRTqkzqtUPISJdTaQBYWZzzGyDmS1rZr2Z2S1mttLMlphZZdq6C8zszeTtgijrbI8RI6CkRP0QItL1RN2CuAs4qYX1JwMjkrfLgJ8DmNkA4DrgE8BE4Doz6x9ppW1UUBAuIKSAEJGuJtKAcPeFQEsTYp8O3OPBC0A/MzsI+AzwpLtvcvcPgCdpOWhilUiEWV137Yq7EhGR3Im7D2IwsCbt+drksuaWd0qVlbB1K9TUxF2JiEjuxB0Q7WZml5nZIjNbVFtbG0sN6qgWka4o7oBYBwxJe16eXNbc8r24+2x3r3L3qrKyssgKbUlFBRQWqh9CRLqWuAPiMeD85GimScAWd38XWACcaGb9k53TJyaXdUrFxSEkFBAi0pUURvniZnY/cCwwyMzWEkYmFQG4+23AfOCzwEqgDrgouW6TmX0PeCn5Uje4e6e++nNlJfzud+AepuAQEcl3kQaEu8/Yx3oHLm9m3RxgThR1RSGRgDvvhPXrYXCn7U4XEcle3IeYugxdo1pEupqsAsLM/sXM+ib7Cu4ws1fM7MSoi8sn48aFQ0sKCBHpKrJtQVzs7h8SOov7A18EZkVWVR4qLQ3TbiggRKSryDYgUt2unwXudffX0pZJkq4NISJdSbYB8bKZPUEIiAVmVgpoYokmEglYtQo2derxViIi2ck2IL4EzAQmuHsdYajqRZFVladSHdXV1bGWISKSE9kGxCeBFe6+2czOA74FbImurPykkUwi0pVkGxA/B+rMbBzwVeAt4J7IqspTZWVQXq6AEJGuIduA2Jk8qe104KfufitQGl1Z+SuR0KR9ItI1ZBsQW83s64ThrY+bWQ+SU2ZIY4kErFgBdXVxVyIi0j7ZBsQ04O+E8yHeI8yuelNkVeWxRCJcOGjJkrgrERFpn6wCIhkK9wH7m9mpwEfurj6IDCqTV9VWP4SI5Ltsp9r4PPBn4Bzg88CLZnZ2lIXlqyFDYMAA9UOISP7LdjbXbxLOgdgAYGZlwFPAvKgKy1dmOqNaRLqGbPsgeqTCIWljK/btdhIJWLoU6uvjrkREpO2ybUH83swWAPcnn08jXOxHMkgkYMcOWL4cxo6NuxoRkbbJtpP6GmA2MDZ5m+3u10ZZWD5TR7WIdAVZX1HO3R8CHoqwli5jxAgoKQkd1RdcEHc1IiJt02JAmNlWwDOtIlwxtG8kVeW5goJwASG1IEQkn7V4iMndS929b4ZbaTbhYGYnmdkKM1tpZjMzrP+RmVUnb2+Y2ea0dQ1p6x5r008Xo0QizOq6S5Oii0ieimwkkpkVALcCJwOjgBlmNip9G3f/V3cf7+7jgZ8AD6et3p5a5+6nRVVnVCorYetWqKmJuxIRkbaJcqjqRGClu9e4+w7gAcJkf82ZwZ5RUnkvNfW3TpgTkXwVZUAMBtakPV+bXLYXMzsEGA48nba4l5ktMrMXzOyM5t7EzC5LbreotrY2B2XnRkUFFBaqH0JE8ldnOdltOjDP3RvSlh3i7lXAF4Afm9lhmXZ099nuXuXuVWVlZR1Ra1aKi0NIKCBEJF9FGRDrgCFpz8uTyzKZTpPDS+6+LnlfAzwLJHJfYrQqK8MhJs80DkxEpJOLMiBeAkaY2XAz60kIgb1GI5nZx4H+wPNpy/qbWXHy8SBgMvB6hLVGIpGA2lpYvz7uSkREWi+ygHD3ncAVwAJgOTDX3V8zsxvMLH1U0nTggeQV61JGAovMbDHwDDDL3fMyIECHmUQkP2V9JnVbuPt8mszZ5O7fafL8+gz7/QkYE2VtHWHcuDC766uvwqmnxl2NiEjrdJZO6i6ptBQOP1wtCBHJTwqIiFVWKiBEJD8pICKWSMCqVbBpU9yViIi0jgIiYqmO6urqWMsQEWk1BUTENJJJRPKVAiJiZWVQXq6AEJH8o4DoAImEJu0TkfyjgOgAiQSsWAF1dXFXIiKSPQVEB0gkwoWDliyJuxIRkewpIDqAOqpFJB8pIDrA0KEwYID6IUQkvyggOoBZaEWoBSEi+UQB0UESCVi6FOrr465ERCQ7CogOkkjAjh2wfHnclYiIZEcB0UEqK8O9DjOJSL5QQHSQESOgpEQd1SKSPxQQHaSgIFxASC0IEckXCogOlEiEWV137Yq7EhGRfVNAdKDKSti6FWpq4q5ERGTfIg0IMzvJzFaY2Uozm5lh/YVmVmtm1cnbJWnrLjCzN5O3C6Kss6OkzqhWP4SI5IPIAsLMCoBbgZOBUcAMMxuVYdMH3X188nZ7ct8BwHXAJ4CJwHVm1j+qWjtKRQUUFqofQkTyQ5QtiInASnevcfcdwAPA6Vnu+xngSXff5O4fAE8CJ0VUZ4cpLg4hoYAQkXwQZUAMBtakPV+bXNbUWWa2xMzmmdmQVu6LmV1mZovMbFFtbW0u6o5U6toQ7nFXIiLSsrg7qX8LDHP3sYRWwt2tfQF3n+3uVe5eVVZWlvMCc62yEmprYf36uCsREWlZlAGxDhiS9rw8uWw3d9/o7n9PPr0dOCrbffOVpv4WkXwRZUC8BIwws+Fm1hOYDjyWvoGZHZT29DQgNVPRAuBEM+uf7Jw+Mbks740bF2Z3VUCISGdXGNULu/tOM7uC8Ie9AJjj7q+Z2Q3AInd/DLjSzE4DdgKbgAuT+24ys+8RQgbgBnffFFWtHam0FA4/XAEhIp2feRfqLa2qqvJFixbFXcY+TZ8OL74Ib78ddyUi0t2Z2cvuXpVpXdyd1N1SIgGrVsGmLtEmEpGuSgERg1RHdXV1rGWIiLRIAQFw113hK30H0UgmEckHCoiNG+Hqq+Hoo+H11zvkLcvKoLxcASEinZsCYuBAePZZ2LkTpkyBl17a5y65kDqjWkSks1JAAIwdC//3f9C3L3z60/D005G/ZSIBK1ZAXV3kbyUi0iYKiJTDDoM//hEOOQROPhn++78jfbtEIlw4aMmSSN9GRKTNFBDpDj4YFi4MEyaddRbceWdkb6WOahHp7BQQTQ0YAE8+CccdBxdfDP/5n5G8zdCh4a3UDyEinZUCIpM+feC3v4Wzz4avfhW+9a2cz89tFloRakGISGelgGhOcTE88ABccgl8//vwz/8MDQ05fYtEApYuhfr6nL6siEhORDZZX5dQUACzZ4ehsD/4AXzwAdxzD/TsmZOXTyRgxw5YvjwMpBIR6UwUEPtiBrNmhQ6Da6+FLVvgoYegpKTdL11ZGe5ffVUBISKdjw4xZetrX4Nf/hKeeAJOOCG0JtppxIiQM+qoFpHOSAHRGpdcAg8+GM62PvZYeO+9dr1cQUG4gJA6qkWkM1JAtNbZZ8Pjj8Nbb4X5m9p5UYdEIszqumtXbsoTEckVBURbnHACPPVUuKDD5MmwbFmbXyqRgK1boaYmh/WJiOSAAqKtJk0KZ11DmOTvhRfa9DKpjmr1Q4hIZ6OAaI/Ro8MkfwMGwPHHhzOwW6miAgoL1Q8hIp1PpAFhZieZ2QozW2lmMzOsv9rMXjezJWb2v2Z2SNq6BjOrTt4ei7LOdhk+PEzyd9hhcMopMG9eq3YvLg4hoYAQkc4msoAwswLgVuBkYBQww8xGNdnsVaDK3ccC84Afpq3b7u7jk7fToqozJw48MFxTYsIEmDYNbr+9Vbunrg2R49k8RETaJcoWxERgpbvXuPsO4AHg9PQN3P0Zd09dEeEFoDzCeqLVv384R+LEE+HSS+GHP9z3PkmVlVBbC+vXR1ifiEgrRRkQg4E1ac/XJpc150vA/6Q972Vmi8zsBTM7o7mdzOyy5HaLamtr21Vwu/XuDY8+GloR114LM2dm1SzQ1N8i0hl1iqk2zOw8oAqYmrb4EHdfZ2aHAk+b2VJ3f6vpvu4+G5gNUFVVFf9Bmp494b77QoviBz8IQ2F//vNwVlwzxo0LM3q8+iqcemoH1ioi0oIoA2IdMCTteXlyWSNmdjzwTWCqu/89tdzd1yXva8zsWSAB7BUQnVJBAfzsZ2F007//O2zeDPfeG3qkMygthcMPVwtCRDqXKA8xvQSMMLPhZtYTmA40Go1kZgngF8Bp7r4hbXl/MytOPh4ETAZej7DW3DML04TffDP85jdw2mnwt781u3llpQJCRDqXyALC3XcCVwALgOXAXHd/zcxuMLPUqKSbgD7Ab5oMZx0JLDKzxcAzwCx3z6+ASPnqV+GOO8KZ1yecEA45ZZBIwKpVza4WEelwkfZBuPt8YH6TZd9Je3x8M/v9CRgTZW0d6uKLoV8/mDEDpk4No50OOqjRJqmO6t/8Bi67LDRARETipDOpO8o//APMnx8m95s8OUz2l+aTn4Qjj4QvfzmcTvHoozovQkTipYDoSMcdB08/HS46dPTR4XqjSaWl4ekdd4RLTZxxRmhVPPSQZnoVkXgoIDraxInw3HNhpNOUKfCnP+1eVVQUjkatWAF33w11dWF28bFjw+Wxc3xJbBGRFikg4jBqVJi/adCg0HG9YEGj1YWFcP754VrV990XWhAzZoQ5m371K9i5M6a6RaRbUUDEZdiwEBJHHAGf+xzMnbvXJgUF8IUvhMtNzJ0bzsH74hdh5Ei46y6or+/wqkWkG1FAxOmAA+CZZ+ATn4Dp02H27Iyb9egB55wTrjz38MOhv+Kii0Kn9u23w44dHVu2iHQP5l1oqExVVZUvWrQo7jJar64uJMD8+WH465FHhpZF+v2wYaGTgjC66fHH4bvfhUWLYOjQMO3TxRc3e7K2iEhGZvayu1dlXKeA6CTq68OcTa++Gnqp33gDNm7cs76wMFxz4ogjdoeGjziCZ9YfyTdvOYAXXjQGDw5zBF5yCey3X3w/inRRDQ1hmHa/fjBwoE7W6SIUEPlq48YQFKnASD1+8034++5pq/C+ffnwwCP48wdH8FztkWzY/wiOvvgIzrz2CHof0CfGH0Dy1ubNsGQJLF6857ZsGXz0UVjft2+YQCzT7cADFR55RAHR1ezaBe+8kzE8/J13sLR/0619D2a/8UdSODLDIavCTjGZr8Rp1y6oqWkcBIsXw+rVe7YZNChMOTxuXBhK9+GH4UTPlSvD7e23G4/BLilpHBiHHbbncXl56FSTTkMB0Z1s3w4rV7L80Td44e4V2Mo3qChcweiiFey3/YM92xUV7XXIavf9xz6mb4Bd0bZtoVWQ3jJYujQsh/CH+8gj94RB6nbQQS3/PtTXhy8sqcBYuXJPgLz1VuNRFMXFcOihmVseQ4fqS0sMFBDd2Isvwve+Fzq1h/fdyLfOWcH0yjcoWbNiTwtk5cpGh6zo3Ttcz6Jv3zBkqm/fxo8zLcv0uFcvBU0c3EMLoGmrIH16l/333zsIKipy33nV0ADr1jUOj/QQqavbs21hYWjZZgqP4cPDOG/JOQWE8PLLISgefTT8/b7ySrjqqtDXSEMDrFmz53BVTU2YDmTr1nA44cMP936czfwfhYXZBUpz63v3Dt84e/ZsfCsoUPCkbN8e+gbSg2DJkvDvB+FzOuywvcNg6ND4P0N3eO+9zOGxcmX4XUvp0SPUnB4YffqELyHFxeGWeryv++JiHeZKo4CQ3aqr4cYbwxxPffrAFVfA1VdDWVkrXsQ9fPPLFBytfZw6vNEaZnuHRpS3wsIQSqlbjx6Nn2e7rK37mYXPfP36vVsFb7yxJ6x79w7zsqQHwZgx4R8637iHQRrNhUf6CL+2KCpqXag0F0Q9e4Z/L7O977Ndlovte/UKU/e0gQJC9rJsWQiKuXPDUYV/+if4t38LA1A6VENDCIlMIbJtWzi+vWNH9LfOflp6QUHjjuBhwxoHwdix4dh+d/lmvG1b+JLy0Ufh8Gi2963Zdl/3nelv5wEHhNZYGyggpFnLl4erov761+HL0D/+I3zta3DwwXFX1sHcmw+j+vrwxzl127Wr8fPWLGvP/gcfvCcM9t8/7k+se0v/fXEP/1aZ7rNd1t7tCwvDjAxtoICQfXrzzRAU994bft8OPjh8ST3kkHCffhs6VGdsdyebNoVuqbfeCn3fJSVhYFP6rVevuKuUtlJASNZqasIMsjU14RKoq1aF/uumU42nAiTTTQGSX3buDP/GNTV7giD9fvPmfb9Gv357h0b67cADw33fvvH3jUtjCghpl507Q/9oKjCa3tas2XsK8oMOajlA9I2zY23dmvmPf6pVkP7vV1QU/p0OOyx0a6TuDz00LK+rC4e733235Vv6yOmU/fZrOUhSt4EDu093StxiCwgzOwn4L6AAuN3dZzVZXwzcAxwFbASmufuq5LqvA18CGoAr3b3xRRMyUEDEIxUgq1dnDpB33mk+QJo7hKW5pFpn167wb9BcK6C2tvH2Awbs/cc/9bi8PPSJt4d7aHmkwqKlQEkfzZpSWLin1dG0FZJ63KdPONxVUhJ+X0pK2l93dxRLQJhZAfAGcAKwFngJmOHur6dt88/AWHf/splNB85092lmNgq4H5gIHAw8BRzh7i1eU00B0Tk1NOzdAkkPk3fe2XsQUeqPQXFx+Ebbs2fu7lu7T2qkafrowvbc2mr79jCrRaZWwNtvN/7G3qNHCN+mf/xT9/36tb2OXKur2zs0MgVK05DLpGfPPWGRHhyZnrfncc+eXedQWUsBEeV57ROBle5ekyziAeB04PW0bU4Hrk8+ngf81MwsufwBd/878LaZrUy+3vMR1isRKSiAIUPC7Zhj9l7f0BD+ADRtebz33p5BRNu3h2+aqect3efDpVn3FSKZwqjpN+0+fcIf/FGj4NRTG4fA0KG7Z4fv9EpKQs2HHdbydvX18Ne/ht+Vv/4V/va38HtRVxduzT1OPd+wIfO6tvy+mIW6U5MFpMIi/T6bx7natqwMFi5s/c+xL1EGxGBgTdrztUDTcVi7t3H3nWa2BRiYXP5Ck30HZ3oTM7sMuAxg6NChOSlcOlZBQTisUV4ORx/d/tfbtSv8MdlXkGR739Cw98jCjrqlv+egQY1bAYMGdZ1vsdkoKtrze5JL9fXZBUymxx99tOd0iPT7bB7nctuoRj3n/cxY7j4bmA3hEFPM5Ugn0KPHnpNeRfalqCj8gdWpJXuLcpzAOmBI2vPy5LKM25hZIbA/obM6m31FRCRCUQbES8AIMxtuZj2B6cBjTbZ5DLgg+fhs4GkPveaPAdPNrNjMhgMjgD9HWKuIiDQR2SGmZJ/CFcACwjDXOe7+mpndACxy98eAO4B7k53QmwghQnK7uYQO7Z3A5fsawSQiIrmlE+VERLqxloa56lxFERHJSAEhIiIZKSBERCQjBYSIiGTUpTqpzawWWN3G3QcB7+ewnHymz6IxfR6N6fPYoyt8Foe4e8aLDnepgGgPM1vUXE9+d6PPojF9Ho3p89ijq38WOsQkIiIZKSBERCQjBcQes+MuoBPRZ9GYPo/G9Hns0aU/C/VBiIhIRmpBiIhIRgoIERHJqNsHhJmdZGYrzGylmc2Mu544mdkQM3vGzF43s9fM7F/iriluZlZgZq+a2e/iriVuZtbPzOaZ2V/MbLmZfTLumuJkZv+a/H+yzMzuN7NecdeUa906IMysALgVOBkYBcwws1HxVhWrncBX3X0UMAm4vJt/HgD/AiyPu4hO4r+A37v7x4FxdOPPxcwGA1cCVe4+mnBJg+nxVpV73ToggInASnevcfcdwAPA6THXFBt3f9fdX0k+3kr4A5DxWuDdgZmVA6cAt8ddS9zMbH9gCuEaLrj7DnffHGtR8SsE9kteDbMEWB9zPTnX3QNiMLAm7flauvEfxHRmNgxIAC/GXEqcfgx8DdgVcx2dwXCgFrgzecjtdjPrHXdRcXH3dcDNwDvAu8AWd38i3qpyr7sHhGRgZn2Ah4Cr3P3DuOuJg5mdCmxw95fjrqWTKAQqgZ+7ewL4G9Bt++zMrD/haMNw4GCgt5mdF29VudfdA2IdMCTteXlyWbdlZkWEcLjP3R+Ou54YTQZOM7NVhEOPnzazX8VbUqzWAmvdPdWinEcIjO7qeOBtd69193rgYeD/xVxTznX3gHgJGGFmw82sJ6GT6bGYa4qNmRnhGPNyd//PuOuJk7t/3d3L3X0Y4ffiaXfvct8Qs+Xu7wFrzOzI5KLjCNeM767eASaZWUny/81xdMFO+8K4C4iTu+80syuABYRRCHPc/bWYy4rTZOCLwFIzq04u+4a7z4+vJOlEvgLcl/wyVQNcFHM9sXH3F81sHvAKYfTfq3TBaTc01YaIiGTU3Q8xiYhIMxQQIiKSkQJCREQyUkCIiEhGCggREclIASHSCZjZsZoxVjobBYSIiGSkgBBpBTM7z8z+bGbVZvaL5PUitpnZj5LXBvhfMytLbjvezF4wsyVm9khy/h7M7HAze8rMFpvZK2Z2WPLl+6Rdb+G+5Bm6IrFRQIhkycxGAtOAye4+HmgAzgV6A4vcvQL4A3Bdcpd7gGvdfSywNG35fcCt7j6OMH/Pu8nlCeAqwrVJDiWc2S4Sm2491YZIKx0HHAW8lPxyvx+wgTAd+IPJbX4FPJy8fkI/d/9DcvndwG/MrBQY7O6PALj7RwDJ1/uzu69NPq8GhgF/jPynEmmGAkIkewbc7e5fb7TQ7NtNtmvr/DV/T3vcgP5/Ssx0iEkke/8LnG1mHwMwswFmdgjh/9HZyW2+APzR3bcAH5jZMcnlXwT+kLxS31ozOyP5GsVmVtKRP4RItvQNRSRL7v66mX0LeMLMegD1wOWEi+dMTK7bQOinALgAuC0ZAOmzn34R+IWZ3ZB8jXM68McQyZpmcxVpJzPb5u594q5DJNd0iElERDJSC0JERDJSC0JERDJSQIiISEYKCBERyUgBISIiGSkgREQko/8PasSmEapy8ZMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_graph(hist7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wireless-bulletin",
   "metadata": {},
   "source": [
    "corpus에서 \\<start>와 \\<end>를 제거하고 학습시켜보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "third-ballet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  69  248    3 ...    0    0    0]\n",
      " [   3   55 6668 ...    0    0    0]\n",
      " [   3 1101  508 ...    0    0    0]\n",
      " ...\n",
      " [  45   14   95 ...    0    0    0]\n",
      " [  20   22    7 ...   43  259   17]\n",
      " [   4  174   15 ...    0    0    0]] <keras_preprocessing.text.Tokenizer object at 0x7ff1d738c590>\n",
      "Source Train: (134872, 14)\n",
      "Target Train: (134872, 14)\n",
      "Source Val: (33718, 14)\n",
      "Target Val: (33718, 14)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 준비\n",
    "new_corpus = [] # 새로운 말뭉치 준비\n",
    "for line in corpus:\n",
    "    new_line = re.sub(\"(\\<[a-z]+\\>)\", \" \", line) # <start>, <end> 삭제\n",
    "    new_line = new_line.strip() # 양쪽 공백 삭제\n",
    "    new_corpus.append(new_line)\n",
    "    \n",
    "    \n",
    "# Tokenization\n",
    "tensor, tokenizer = tokenize(new_corpus) \n",
    "\n",
    "# 평가 데이터셋 분리\n",
    "src_input = tensor[:, :-1] # 마지막 토큰을 잘라, 소스 문장 생성\n",
    "tgt_input = tensor[:, 1:] # 첫 토큰을 잘라, 타겟 문장 생성\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input, tgt_input, test_size=0.2, random_state=42)\n",
    "print(\"Source Train:\", enc_train.shape)\n",
    "print(\"Target Train:\", dec_train.shape)\n",
    "print(\"Source Val:\", enc_val.shape)\n",
    "print(\"Target Val:\", dec_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "understood-origin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "527/527 [==============================] - 403s 745ms/step - loss: 2.8369 - val_loss: 0.4508\n",
      "Epoch 2/10\n",
      "527/527 [==============================] - 399s 756ms/step - loss: 0.3203 - val_loss: 0.1979\n",
      "Epoch 3/10\n",
      "527/527 [==============================] - 402s 763ms/step - loss: 0.0932 - val_loss: 0.1271\n",
      "Epoch 4/10\n",
      "527/527 [==============================] - 401s 762ms/step - loss: 0.0282 - val_loss: 0.1063\n",
      "Epoch 5/10\n",
      "527/527 [==============================] - 403s 764ms/step - loss: 0.0121 - val_loss: 0.0957\n",
      "Epoch 6/10\n",
      "527/527 [==============================] - 403s 765ms/step - loss: 0.0062 - val_loss: 0.0920\n",
      "Epoch 7/10\n",
      "527/527 [==============================] - 404s 767ms/step - loss: 0.0255 - val_loss: 0.1158\n",
      "Epoch 8/10\n",
      "527/527 [==============================] - 406s 770ms/step - loss: 0.0083 - val_loss: 0.0983\n",
      "Epoch 9/10\n",
      "527/527 [==============================] - 405s 768ms/step - loss: 0.0018 - val_loss: 0.0915\n",
      "Epoch 10/10\n",
      "527/527 [==============================] - 405s 769ms/step - loss: 6.4103e-04 - val_loss: 0.0902\n"
     ]
    }
   ],
   "source": [
    "# 모델 훈련 \n",
    "# model 8\n",
    "model8, hist8 = train_val_model(256, 1024) # 마지막으로 설계된 모델 그대로 사용(TextGenerator_Bidirectional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "contemporary-norway",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEHCAYAAAC0pdErAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAnb0lEQVR4nO3deZhcZZn38e/dS9JkI6HTxJiFJBAl+9InIRpJUBbZFwUTBhR4VQaHRWRkiPoqiM6I4rwgGoWMRkFZDTCgIEEcQmAMmoWEhDUBoumwpLMnJhDSfb9/PNV0dVPdXb2cPlVdv8911VVVZ6m6uwj1q3Oe5zyPuTsiIiKNFSVdgIiI5CYFhIiIZKSAEBGRjBQQIiKSkQJCREQyUkCIiEhGJXG9sJnNB04GNrn72AzrrwTOSatjFFDh7lvNbD2wC6gB9rt7lM179u/f34cNG9YB1YuIFIbly5dvdveKTOssrusgzGwGsBu4LVNANNr2FOAr7v6J1PP1QOTum1vznlEU+bJly9pYsYhI4TGz5U39CI/tFJO7Lwa2Zrn52cCdcdUiIiKtl3gbhJn1AI4H7k1b7MCjZrbczC5MpjIRkcIWWxtEK5wC/K+7px9tfMzdN5rZwcAfzezF1BHJ+6QC5EKAoUOHxl+tiEiByIWAmE2j00vuvjF1v8nM7gemAhkDwt3nAfMgtEHEW6qIJOXdd9+lqqqKt99+O+lS8lJZWRmDBw+mtLQ0630SDQgzOxCYCZybtqwnUOTuu1KPjwOuTahEEckRVVVV9O7dm2HDhmFmSZeTV9ydLVu2UFVVxfDhw7PeL85urncCRwH9zawKuBooBXD3m1ObnQE86u7/SNt1AHB/6h9ACXCHuz8SV50ikh/efvtthUMbmRnl5eVUV1e3ar/YAsLdz85im18Bv2q07FVgQjxViUg+Uzi0XVs+u8R7MSVt3z74/vfh0UeTrkREJLcUfECUlsL118M99yRdiYjkqu3bt/PTn/60TfueeOKJbN++Pevtr7nmGn74wx+26b06WsEHhBlEEegCbBFpSnMBsX///mb3ffjhh+nbt28MVcWv4AMCQkCsWQN79yZdiYjkojlz5vDKK68wceJErrzyShYtWsSRRx7JqaeeyujRowE4/fTTqaysZMyYMcybN++9fYcNG8bmzZtZv349o0aN4otf/CJjxozhuOOOY28LXzorV65k2rRpjB8/njPOOINt27YBcNNNNzF69GjGjx/P7NmzAXjiiSeYOHEiEydOZNKkSezatavdf3cuXAeRuCiCmhpYtQqmTUu6GhFpyeWXw8qVHfuaEyfCjTdmXnfdddexZs0aVqbedNGiRaxYsYI1a9a81210/vz5HHTQQezdu5cpU6bw6U9/mvLy8gavs3btWu68807+67/+i8985jPce++9nHvuuY3f7j2f+9zn+PGPf8zMmTP51re+xbe//W1uvPFGrrvuOl577TW6d+/+3umrH/7wh8ydO5fp06eze/duysrK2vmJ6AgCCAEBOs0kItmbOnVqg2sKbrrpJiZMmMC0adPYsGEDa9eufd8+w4cPZ+LEiQBUVlayfv36Jl9/x44dbN++nZkzZwJw3nnnsXhxuF54/PjxnHPOOfzmN7+hpCT8zp8+fTpXXHEFN910E9u3b39veXvoCAIYNAgGDFBAiOSLpn7pd6aePXu+93jRokU89thjLFmyhB49enDUUUdlvOK7e/fu7z0uLi5u8RRTUx566CEWL17M7373O/793/+d1atXM2fOHE466SQefvhhpk+fzsKFCzn88MPb9Pp1dARBfUP18uVJVyIiuah3797NntPfsWMH/fr1o0ePHrz44os8/fTT7X7PAw88kH79+vHkk08C8Otf/5qZM2dSW1vLhg0b+PjHP873v/99duzYwe7du3nllVcYN24cV111FVOmTOHFF19sdw06gkiJIvjDH+Af/4C0HwYiIpSXlzN9+nTGjh3LCSecwEknndRg/fHHH8/NN9/MqFGj+PCHP8y0DmrMvPXWW7nooovYs2cPI0aM4Je//CU1NTWce+657NixA3fnsssuo2/fvnzzm9/k8ccfp6ioiDFjxnDCCSe0+/1jmzAoCe2ZMOj3v4dTToGnnoLp0zu4MBFptxdeeIFRo0YlXUZey/QZJjJhUL6prAz3aocQEQkUECkDB4bGagWEiEiggEijK6pFROopINJEEbz0EuzcmXQlIiLJU0CkiSJwh2eeSboSEZHkKSDSqKFaRKSeAiJNRQUMHaqAEJH269WrV6uW5yIFRCNqqBYRCRQQjUQRrFsHqVF1RUSYM2cOc+fOfe953aQ+u3fv5uijj2by5MmMGzeOBx54IOvXdHeuvPJKxo4dy7hx47j77rsBeOONN5gxYwYTJ05k7NixPPnkk9TU1HD++ee/t+0NN9zQ4X9jJhpqo5G6kV1XrICjj062FhFpQieP9z1r1iwuv/xyLr74YgDuueceFi5cSFlZGffffz99+vRh8+bNTJs2jVNPPTWr+Z/vu+8+Vq5cyapVq9i8eTNTpkxhxowZ3HHHHXzyk5/kG9/4BjU1NezZs4eVK1eyceNG1qxZA9CqGeraI7YjCDObb2abzGxNE+uPMrMdZrYydftW2rrjzewlM1tnZnPiqjETNVSLSGOTJk1i06ZNvP7666xatYp+/foxZMgQ3J2vf/3rjB8/nmOOOYaNGzfy1ltvZfWaTz31FGeffTbFxcUMGDCAmTNnsnTpUqZMmcIvf/lLrrnmGlavXk3v3r0ZMWIEr776KpdeeimPPPIIffr0ifkvDuI8gvgV8BPgtma2edLdT05fYGbFwFzgWKAKWGpmD7r783EVmu6gg2DECAWESE5LYLzvs846iwULFvDmm28ya9YsAG6//Xaqq6tZvnw5paWlDBs2LOMw360xY8YMFi9ezEMPPcT555/PFVdcwec+9zlWrVrFwoULufnmm7nnnnuYP39+R/xZzYrtCMLdFwNb27DrVGCdu7/q7vuAu4DTOrS4FqihWkQamzVrFnfddRcLFizgrLPOAsIw3wcffDClpaU8/vjj/O1vf8v69Y488kjuvvtuampqqK6uZvHixUydOpW//e1vDBgwgC9+8Yt84QtfYMWKFWzevJna2lo+/elP893vfpcVK1bE9Wc2kHQbxEfMbBXwOvBVd38OGARsSNumCjiiM4uKIrjnHti8Gfr378x3FpFcNWbMGHbt2sWgQYMYOHAgAOeccw6nnHIK48aNI4qiVk3Qc8YZZ7BkyRImTJiAmfGDH/yAD3zgA9x6661cf/31lJaW0qtXL2677TY2btzIBRdcQG1tLQDf+973YvkbG4t1uG8zGwb83t3HZljXB6h1991mdiLwI3cfaWZnAse7+xdS230WOMLdL2niPS4ELgQYOnRoZWsSvCmPPw6f+AQ88gh88pPtfjkR6QAa7rv98ma4b3ff6e67U48fBkrNrD+wERiStung1LKmXmeeu0fuHlVUVHRIbZMnh3vNMCcihSyxgDCzD1iqL5iZTU3VsgVYCow0s+Fm1g2YDTzYmbUdeCB86ENqhxCRwhZbG4SZ3QkcBfQ3syrgaqAUwN1vBs4EvmRm+4G9wGwP57v2m9klwEKgGJifapvoVFEEqalgRSRHuHtW1xjI+7WlOSG2gHD3s1tY/xNCN9hM6x4GHo6jrmxFEdxxB7z1FgwYkGQlIgJQVlbGli1bKC8vV0i0kruzZcsWysrKWrVf0r2YclbdFdXLl8OJJyZbi4jA4MGDqaqqorq6OulS8lJZWRmDBw9u1T4KiCZMmgRmoR1CASGSvNLSUoYPH550GQVFg/U1oVcvGDVKDdUiUrgUEM3QFdUiUsgUEM2orIQ33oDXX0+6EhGRzqeAaEZdQ7WOIkSkECkgmjFxIhQVKSBEpDApIJrRoweMGaOAEJHCpIBoQV1DdYxjGoqI5CQFRAuiCKqrYcOGlrcVEelKFBAtUEO1iBQqBUQLxo+HkhIFhIgUHgVEC8rKYNw4BYSIFB4FRBbUUC0ihUgBkYUogm3bYP36pCsREek8CogsqKFaRAqRAiILY8dCt24KCBEpLAqILHTrBhMmKCBEpLAoILIURWF2udrapCsREekcCogsRRHs2AGvvJJ0JSIinUMBkSU1VItIoYktIMxsvpltMrM1Taw/x8yeNbPVZvZnM5uQtm59avlKM8uJr+TRo8NFcwoIESkUcR5B/Ao4vpn1rwEz3X0c8B1gXqP1H3f3ie4exVRfq5SUhPkhFBAiUihiCwh3XwxsbWb9n919W+rp08DguGrpKFEEK1ZATU3SlYiIxC9X2iA+D/wh7bkDj5rZcjO7sLkdzexCM1tmZsuqq6tjLTKKYPduePnlWN9GRCQnJB4QZvZxQkBclbb4Y+4+GTgBuNjMZjS1v7vPc/fI3aOKiopYa1VDtYgUkkQDwszGAz8HTnP3LXXL3X1j6n4TcD8wNZkKGzr88DANqQJCRApBYgFhZkOB+4DPuvvLact7mlnvusfAcUDGnlCdrbgYJk9WQIhIYSiJ64XN7E7gKKC/mVUBVwOlAO5+M/AtoBz4qZkB7E/1WBoA3J9aVgLc4e6PxFVna0UR3HIL7N8fejaJiHRVsX3FufvZLaz/AvCFDMtfBSa8f4/cEEVw443wwgthIiERka4q8UbqfKOGahEpFAqIVho5Enr3VkCISNengGiloiKorFRAiEjXp4BogyiCVavg3XeTrkREJD4KiDaIInjnHXjuuaQrERGJjwKiDdRQLSKFQAHRBiNGQN++CggR6doUEG1gFo4iFBAi0pUpINooiuDZZ0NbhIhIV6SAaKPKytCLafXqpCsREYmHAqKN1FAtIl2dAqKNDjkEyssVECLSdSkg2kgN1SLS1Skg2iGKYM0a2Ls36UpERDqeAqIdoghqasKwGyIiXY0Coh3UUC0iXZkCoh0GDYIBAxQQItI1KSDaQQ3VItKVKSDaKYrC9KO7dyddiYhIx1JAtFMUQW0trFyZdCUiIh0r1oAws/lmtsnM1jSx3szsJjNbZ2bPmtnktHXnmdna1O28OOtsj8rKcK/TTCLS1cR9BPEr4Phm1p8AjEzdLgR+BmBmBwFXA0cAU4GrzaxfrJW20cCBobF6+fKkKxER6VixBoS7Lwa2NrPJacBtHjwN9DWzgcAngT+6+1Z33wb8keaDJlFqqBaRrijpNohBwIa051WpZU0tfx8zu9DMlpnZsurq6tgKbU4UwUsvwc6diby9iEgskg6IdnP3ee4euXtUUVGRSA1RBO7wzDOJvL2ISCySDoiNwJC054NTy5panpPUUC0iXVHSAfEg8LlUb6ZpwA53fwNYCBxnZv1SjdPHpZblpIqKMPy3AkJEupKSOF/czO4EjgL6m1kVoWdSKYC73ww8DJwIrAP2ABek1m01s+8AS1Mvda27N9fYnbjKSgWEiHQtsQaEu5/dwnoHLm5i3Xxgfhx1xSGK4L77YNs26JeTHXJFRFon6VNMXUbdyK4rViRbh4hIR1FAdBA1VItIV6OA6CAHHQQjRiggRKTrUEB0IF1RLSJdiQKiA0URrF8PmzcnXYmISPtlFRBm9mUz65O6XuEXZrbCzI6Lu7h8U9dQrYH7RKQryPYI4v+4+07CBWv9gM8C18VWVZ6anBqsXKeZRKQryDYgLHV/IvBrd38ubZmkHHggfOhDCggR6RqyDYjlZvYoISAWmllvoDa+svKXGqpFpKvINiA+D8wBprj7HsJwGRfEVlUeiyKoqoI330y6EhGR9sk2ID4CvOTu283sXOD/AjviKyt/qaFaRLqKbAPiZ8AeM5sA/CvwCnBbbFXlsUmTwEwBISL5L9uA2J8aWO804CfuPhfoHV9Z+atXLxg1Su0QIpL/sg2IXWb2NUL31ofMrIjUsN3yfmqoFpGuINuAmAW8Q7ge4k3CDG/Xx1ZVnosieOMNeP31pCsREWm7rAIiFQq3Awea2cnA2+6uNogm1DVU6yhCRPJZtkNtfAb4K3AW8BngL2Z2ZpyF5bMJE6CoSAEhIvkt2xnlvkG4BmITgJlVAI8BC+IqLJ/16AFjxiggRCS/ZdsGUVQXDilbWrFvQaprqHZPuhIRkbbJ9kv+ETNbaGbnm9n5wEPAw/GVlf+iCKqrYcOGpCsREWmbbBuprwTmAeNTt3nuflVL+5nZ8Wb2kpmtM7M5GdbfYGYrU7eXzWx72rqatHUPZv0X5Qg1VItIvsu2DQJ3vxe4N9vtzawYmAscC1QBS83sQXd/Pu01v5K2/aXApLSX2OvuE7N9v1wzfjyUlISA+NSnkq5GRKT1mg0IM9sFZDqLboC7e59mdp8KrHP3V1OvdRfhSuznm9j+bODqFivOE2VlMG6cjiBEJH81e4rJ3Xu7e58Mt94thAPAICD9DHxVatn7mNkhwHDgf9IWl5nZMjN72sxOb+pNzOzC1HbLqqurWyipc6mhWkTyWa70RJoNLHD3mrRlh7h7BPwTcKOZHZppR3ef5+6Ru0cVFRWdUWvWogi2bYPXXku6EhGR1oszIDYCQ9KeD04ty2Q2cGf6AnffmLp/FVhEw/aJvKCGahHJZ3EGxFJgpJkNN7NuhBB4X28kMzucMM/1krRl/cyse+pxf2A6Tbdd5KyxY6FbNwWEiOSnrHsxtZa77zezS4CFQDEw392fM7NrgWXuXhcWs4G7UsOJ1xkF3GJmtYQQuy6991O+6NYtDLuhgBCRfBRbQAC4+8M0uqDO3b/V6Pk1Gfb7MzAuzto6SxTB7bdDbW0Yn0lEJF/oKytmUQQ7d8IrryRdiYhI6yggYqaGahHJVwqImI0eHS6aU0CISL5RQMSspAQmTVJAiEj+UUB0gspKWLECampa3lZEJFcoIDpBFMHu3fDyy0lXIiKSPQVEJ1BDtYjkIwVEJzj88DANqQJCRPKJAqITFBfD5MkKCBHJLwqIThJF8MwzsH9/0pWIiGRHAdFJogj27oUXXki6EhGR7CggOokaqkUk3yggOsnIkdC7twJCRPKHAqKTFBWFC+YUECKSLxQQnSiKYNUq2Lcv6UpERFqmgOhEUQTvvAPPPZd0JSIiLVNAdCI1VItIPlFAdKIRI6BvXwWEiOQHBUQnMgtHEQoIEckHCohOFkWwenVoixARyWWxBoSZHW9mL5nZOjObk2H9+WZWbWYrU7cvpK07z8zWpm7nxVlnZ4oiePfdEBIiIrmsJK4XNrNiYC5wLFAFLDWzB939+Uab3u3ulzTa9yDgaiACHFie2ndbXPV2lvSG6rrHIiK5KM4jiKnAOnd/1d33AXcBp2W57yeBP7r71lQo/BE4PqY6O9XQoVBernYIEcl9cQbEIGBD2vOq1LLGPm1mz5rZAjMb0sp9844aqkUkXyTdSP07YJi7jyccJdza2hcwswvNbJmZLauuru7wAuMQRbBmTRjdVUQkV8UZEBuBIWnPB6eWvcfdt7h7XX+enwOV2e6b9hrz3D1y96iioqJDCo9bFEFNTRh2Q0QkV8UZEEuBkWY23My6AbOBB9M3MLOBaU9PBepmS1gIHGdm/cysH3BcalmXoCuqRSQfxNaLyd33m9klhC/2YmC+uz9nZtcCy9z9QeAyMzsV2A9sBc5P7bvVzL5DCBmAa919a1y1drZBg2DAAAWEiOQ2c/eka+gwURT5srZ8686dC8cdFyZt6CQnnwzr14e2CBGRpJjZcnfP2Ok+6Ubq5G3ZAtdcAx/5CPz5z532tlEUph/dvbvT3lJEpFUUEOXlsGQJ9OsHn/gE3Htvp7xtFEFtLaxc2SlvJyLSagoIgMMOCyExeTKcdRbccAPEfOqtMtVfS+0QIpKrFBB1+veHP/0JPvUpuOIKuPzy0Bc1JgMHhsZqBYSI5CoFRLoDDoB77gkBcdNNcOaZsGdPbG+nK6pFJJcpIBorKoL//E/40Y/ggQdCu8SmTbG8VRTBSy/Bzp2xvLyISLsoIJpy2WWhwXrVqtDD6eWXO/wt6i6YW7Giw19aRKTdFBDNOeMMePzx8BP/Ix+B//3fDn15NVSLSC5TQLRk2jR4+unQHfboo+G3v+2wl66ogEMOgeXLO+wlRUQ6jAIiG4ceGi6iq6yEz3wmtFF0UDdYNVSLSK5SQGSrf3947LHQs+mrXw1tFB3QDbayEtatg215P1eeiHQ1CojWOOAAuPvuEBA/+Um4ZqKd3WDVUC0iuUoB0VpFRXD99fDjH8Pvfw8f/3i7usGqoVpEcpUCoq0uuQTuuw9Wrw4N2S+91KaXOeggGDFCASEiuUcB0R6nnQaLFoUhWT/6UXjqqTa9jBqqRSQXKSDaa+rU0A22f3845pgwVEcrRVGYG2Lz5o4vT0SkrRQQHWHEiNANdsoUmDUrtFG0ohtsXUO1rocQkVyigOgo5eXwxz+G6yT+7d9CG8X+/VntOnlyuNdpJhHJJbHNSV2QysrgzjvD5dHXXw9//zvcdRf07NnsbgceCB/6kAJCRHKLjiA6WlER/OAHYZ7rhx+Go46CN99scTc1VItIrok1IMzseDN7yczWmdmcDOuvMLPnzexZM/uTmR2Stq7GzFambg/GWWcs/uVf4L//G55/Pgz09+KLzW4eRVBVlVWWiIh0itgCwsyKgbnACcBo4GwzG91os2eAyN3HAwuAH6St2+vuE1O3U+OqM1annBK6we7ZE7rBLl7c5KZ1DdU//WmsE9mJiGQtziOIqcA6d3/V3fcBdwGnpW/g7o+7e91YFU8Dg2OsJxlTpoRusAcfDMceG9okMpg2DU4+Gb7zHTjiCPVoEpHkxRkQg4ANac+rUsua8nngD2nPy8xsmZk9bWanx1Bf5xk+PHSDPeIIOPts+P7339cNtrQUHnww5MfGjeHyii9/WbPNiUhycqKR2szOBSLg+rTFh7h7BPwTcKOZHdrEvhemgmRZdXV1J1TbRgcdBI8+CrNnw5w5oY2iUTdYs3AZxQsvwEUXheGeRo0KE9t10OjiIiJZizMgNgJD0p4PTi1rwMyOAb4BnOru79Qtd/eNqftXgUXApExv4u7z3D1y96iioqLjqo9DWRncfjtcdRXcfDOcfnoYpqORvn1DJ6i6M1NnnhmaM9av7+yCRaSQxRkQS4GRZjbczLoBs4EGvZHMbBJwCyEcNqUt72dm3VOP+wPTgedjrLXzFBXBddfBz34Gf/gDzJzZZNelqVNh6dIwP9GiRTBmTOhB++67nVuyiBSm2ALC3fcDlwALgReAe9z9OTO71szqeiVdD/QCftuoO+soYJmZrQIeB65z964REHUuuggeeCB0f502LXSHzaCkBK64Iqw+9thw8FFZCUuWdHK9IlJwzLvQye0oinxZvl1ttmxZ6L70zjvhuomZM5vd/IEH4NJLYcMGuPDCcDDSr1/nlCoiXY+ZLU+1975PTjRSF7QoCo0NH/gAHHccnHEG3HgjPPNMxgsiTjstHE1ccQX84hdw+OFwxx1qxBaRjqeAyAXDhoVusBdcAKtWwVe+EkbwKy8PRxfXXw9/+ct7jQ+9eoV2iWXLwq7nnBOyZd26RP8KEelidIopF23YEK66fuKJcF83W13PnjB9OsyYEU5FTZlCTUl3brkFvva1cJbqG98Ig8l2757snyAi+aG5U0wKiHzw5pvw5JMhMJ54AtasCcvLykID98yZbBkzg6/cPY1f39uDD3849KI96qhEqxaRPKCA6Gq2bKkPjMWLYeVKqK2F0lK2jZzKnRtn8MCOmQw7+6N890e9yfXLQ0QkOQqIrm7HjjAfduq0lC9bhtXUsJ9ini2eTMkxMxn7pRkUzTwyXIUnIpKigCg0u3fDkiVUL3iCjXctZtTOv9CdfbgZNmFCfRvGjBlhLm0RKVgKiAJWWwu33bKX+676C5X/WMy5Q55gxKYl2N69YYPRo0NY1AXGwIHJFiwinUoBIVRXw1e/CrfdBh8evo9bL13GEW+n2jCeeqp+TKiRI8PcFQMHhgEGy8vDfePH6iYl0iUoIOQ9jz8eRvl4+eUwcuwNN8DAiv3hwry6rrXLloVEaTTabAM9e2YOjpYed+vWeX+sdIx9+8K/h+rq0EGie/cwkXrfvuG+V68wxpjkJQWENPDOO2FKiv/4j/D/+ve+B//8z1BcnLaReziq2Lo13LZsyf5xS8HSUojU3fftCz16wAEHhFuPHmHiDLO4P6Kubc+e+i/8bG4tTUpSVAR9+tQHRnp4NL5vap2OSBOjgJCM1q6FL30J/vSnMHLsLbfAxIntfNG6YGkqRJoLmOaCpU5R0ftDI9N9Ryzr3j33w8gddu1q3Rf+nj2ZX6u0FCoqmr+Vl4cjih07YPv27O537Gh5LJju3bMLmLr7Pn3CdUDdujV96949/E06ummWAkKa5B7GcrriivBd/eUvw7e/Hc4adHohu3Y1DI7t22Hv3nDbsyfzfbbr2vLv3CyERbduYVjd4uJwS3/cmc937w5f8Js21X/Zb94cDgkzOeCAlr/w0299+sQTiLW1ofZswyTTurpOFW1RUtJ8kLTnVndEaxaCqO5x41tz6zpifVlZGO65DRQQ0qJt28JEd/PmhXEDjzkmjCMYReGoomfPpCtsB/fwJdqWYNmzJ+xbU9Pwtn9/5z/v1at1X/h5/R+tkbqjlrrA2Lkz/HfZt6/zb++8k3ujYw4Y0OS8Mi1RQEjW/vznMCnR0qXw+uthWVFR6A07ZUp9aIwfH360iBSkmpoQFO++G8LCPRwp1T3OdItzfUlJm88PKyCkTV5/PXRoqrstXRrOaEA4sh43rj4wogjGjg3LRSR/KCCkQ7iHgWaXLm0YHNu3h/Xdu4cfMemhMWpUo95RIpJTFBASG3d49dWGobF8ef11dz16hKkt0kNj5Eh1LMk3W7eGXm+vvRZ6II8cCUOHKvy7AgWEdKra2nAhXnpoPPNMfUeUPn3CvNrpoTF8eO73KO3qtm0Lk06tXVt/q3u+dev7ty8thREj4LDDQmAcdlj946FDw2lxyX0KCEnc/v3wwgsNQ2PVqtApBMKv0vTAiCIYPFih0dF27MgcAGvXhp7FdcxgyJD6L/6RI8Nt+PAQFnX7rVtX/zj98orS0rBtpvA45BCFRy5RQEhO2rcvzH2UHhqrV9dPxV13cW6fPtC7d8P71iwrtIt0d+7MHABr19Z3MqgzZEjDAKj7Mj/00Nb1UnMPvSzT3zM9PP7xj/ptS0qaDw91dOhciQWEmR0P/AgoBn7u7tc1Wt8duA2oBLYAs9x9fWrd14DPAzXAZe6+sKX3U0Dkv7174dlnQ1i8+GK4dm7nzvr79Me7d2fXHb20tO3h0rt3/QgfpaXhy63ucd3zJM7D79rV9OmgTZsabjto0PsDYOTIEAIHHBB/re7w1ltNh0ddexWEz7IuPNIDZOTIMP+6wqPjJRIQZlYMvAwcC1QBS4Gz3f35tG3+BRjv7heZ2WzgDHefZWajgTuBqcAHgceAD7l7TXPvqYAoLLW14ZdpemhkCpJslqX/wm0ts6bDo6Oel5SEL/66MHjrrYY1fPCD7w+AuhDo0aN9n3Oc3Ov/rkzhsWtX/bbFxSEkDjsshEh6cMfxeTe1rqs1zDcXEHGeCZwKrHP3V1NF3AWcBjyfts1pwDWpxwuAn5iZpZbf5e7vAK+Z2brU6y2JsV7JM0VF4Rd+797tf62amvBLNlOQ7NkTrod6993QlpLpcUvPM63buze8R7avW14evvRPOqnhEcGhh+bvRdNm4SLgAQPgYx9ruM49jCaSKTyWLoW3367/bDrzTLlZfWCUlDQc8aJufVPPs13W2m0qKsJgzB0tzoAYBGxIe14FHNHUNu6+38x2AOWp5U832ndQpjcxswuBCwGGDh3aIYVL4Skurh8nTnKDGRx8cLhNn978tnWjkWQb2B0V9vv311/MDA0vbm78PNtlbdkmrn+3ed+XwN3nAfMgnGJKuBwRSUDduIaF1iEhbnFerrQRGJL2fHBqWcZtzKwEOJDQWJ3NviIiEqM4A2IpMNLMhptZN2A28GCjbR4Ezks9PhP4Hw+t5g8Cs82su5kNB0YCf42xVhERaSS2U0ypNoVLgIWEbq7z3f05M7sWWObuDwK/AH6daoTeSggRUtvdQ2jQ3g9c3FIPJhER6Vi6UE5EpIA1181VQ6aJiEhGCggREclIASEiIhkpIEREJKMu1UhtZtXA39q4e39gc4tbFQZ9Fg3p82hIn0e9rvBZHOLuFZlWdKmAaA8zW9ZUS36h0WfRkD6PhvR51Ovqn4VOMYmISEYKCBERyUgBUW9e0gXkEH0WDenzaEifR70u/VmoDUJERDLSEYSIiGRU8AFhZseb2Utmts7M5iRdT5LMbIiZPW5mz5vZc2b25aRrSpqZFZvZM2b2+6RrSZqZ9TWzBWb2opm9YGYfSbqmJJnZV1L/n6wxszvNrCzpmjpaQQdEat7sucAJwGjg7NR82IVqP/Cv7j4amAZcXOCfB8CXgReSLiJH/Ah4xN0PByZQwJ+LmQ0CLgMidx9LGLF6drJVdbyCDgjS5s12931A3bzZBcnd33D3FanHuwhfABmnei0EZjYYOAn4edK1JM3MDgRmEIbox933ufv2RItKXglwQGqysx7A6wnX0+EKPSAyzZtdsF+I6cxsGDAJ+EvCpSTpRuDfgNqE68gFw4Fq4JepU24/N7OeSReVFHffCPwQ+DvwBrDD3R9NtqqOV+gBIRmYWS/gXuByd9+ZdD1JMLOTgU3uvjzpWnJECTAZ+Jm7TwL+ARRsm52Z9SOcbRgOfBDoaWbnJltVxyv0gNDc142YWSkhHG539/uSridB04FTzWw94dTjJ8zsN8mWlKgqoMrd644oFxACo1AdA7zm7tXu/i5wH/DRhGvqcIUeENnMm10wzMwI55hfcPf/l3Q9SXL3r7n7YHcfRvh38T/u3uV+IWbL3d8ENpjZh1OLjiZMCVyo/g5MM7Meqf9vjqYLNtrHNid1Pmhq3uyEy0rSdOCzwGozW5la9nV3fzi5kiSHXArcnvox9SpwQcL1JMbd/2JmC4AVhN5/z9AFr6rWldQiIpJRoZ9iEhGRJiggREQkIwWEiIhkpIAQEZGMFBAiIpKRAkIkB5jZURoxVnKNAkJERDJSQIi0gpmda2Z/NbOVZnZLar6I3WZ2Q2pugD+ZWUVq24lm9rSZPWtm96fG78HMDjOzx8xslZmtMLNDUy/fK22+hdtTV+iKJEYBIZIlMxsFzAKmu/tEoAY4B+gJLHP3McATwNWpXW4DrnL38cDqtOW3A3PdfQJh/J43UssnAZcT5iYZQbiyXSQxBT3UhkgrHQ1UAktTP+4PADYRhgO/O7XNb4D7UvMn9HX3J1LLbwV+a2a9gUHufj+Au78NkHq9v7p7Ver5SmAY8FTsf5VIExQQItkz4FZ3/1qDhWbfbLRdW8eveSftcQ36/1MSplNMItn7E3CmmR0MYGYHmdkhhP+Pzkxt80/AU+6+A9hmZkemln8WeCI1U1+VmZ2eeo3uZtajM/8IkWzpF4pIltz9eTP7v8CjZlYEvAtcTJg8Z2pq3SZCOwXAecDNqQBIH/30s8AtZnZt6jXO6sQ/QyRrGs1VpJ3MbLe790q6DpGOplNMIiKSkY4gREQkIx1BiIhIRgoIERHJSAEhIiIZKSBERCQjBYSIiGSkgBARkYz+P+sSBREcuakuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_graph(hist8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unexpected-antarctica",
   "metadata": {},
   "source": [
    "## 5. 모델 평가\n",
    "작사가 모델이 쓴 가사를 평가해본다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-coral",
   "metadata": {},
   "source": [
    "__모델별 생성된 문장__\n",
    "\n",
    "|init_sentence|model3|model7😈|model8|\n",
    "|:---:|:---:|:---:|:---:|\n",
    "|\\<start> her smile|\\<start> her smile fades in the sky \\<end> |\\<start> her smile \\<end>|her smile |\n",
    "|\\<start> i love|\\<start> i love you , liberian girl \\<end> |\\<start> i love \\<end>|i love you|\n",
    "|\\<start> you re|\\<start> you re the only one who knows that \\<end>|\\<start> you re \\<end>|you re fading tired , oh . |\n",
    "|\\<start> a letter|\\<start> a letter of me and i know \\<end> |\\<start> a letter \\<end>|a letter of heaven |\n",
    "|\\<start> you make|\\<start> you make me wanna get you pregnant than you \\<end> |\\<start> you make \\<end>|you make me happy|\n",
    "|※model8에 init_setence에는 \\<start>없이 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fifteen-garlic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
    "    # 테스트를 위해서 입력받은 init_sentence도 텐서로 변환합니다\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    # 단어 하나씩 예측해 문장을 만듭니다\n",
    "    #    1. 입력받은 문장의 텐서를 입력합니다\n",
    "    #    2. 예측된 값 중 가장 높은 확률인 word index를 뽑아냅니다\n",
    "    #    3. 2에서 예측된 word index를 문장 뒤에 붙입니다\n",
    "    #    4. 모델이 <end>를 예측했거나, max_len에 도달했다면 문장 생성을 마칩니다\n",
    "    while True:\n",
    "        # 1\n",
    "        predict = model(test_tensor) \n",
    "        # 2\n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
    "        # 3 \n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "        # 4\n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "    # tokenizer를 이용해 word index를 단어로 하나씩 변환합니다 \n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "actual-scenario",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> her smile fades in the sky <end> \n",
      "<start> i love you , liberian girl <end> \n",
      "<start> you re the only one who knows that <end> \n",
      "<start> a letter of me and i know <end> \n",
      "<start> you make me wanna get you pregnant than you <end> \n"
     ]
    }
   ],
   "source": [
    "# model3 평가하기\n",
    "print(generate_text(model3, tokenizer, init_sentence=\"<start> her smile\"))\n",
    "print(generate_text(model3, tokenizer, init_sentence=\"<start> i love\"))\n",
    "print(generate_text(model3, tokenizer, init_sentence=\"<start> you re\"))\n",
    "print(generate_text(model3, tokenizer, init_sentence=\"<start> a letter\"))\n",
    "print(generate_text(model3, tokenizer, init_sentence=\"<start> you make\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "horizontal-brain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i love <end> '"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model7 평가하기\n",
    "generate_text(model, tokenizer, init_sentence=\"<start> i love\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valuable-fever",
   "metadata": {},
   "source": [
    "양방향 RNN을 사용해서 학습된 model7이 생성해주는 문장 모두 입력된 문장에 \\<end>만 붙여준다....😨 작사가가 아니라 엔드빌런을 만들었네...\n",
    "<br>모든 문장이\\<start>로 시작되어 \\<end>로 끝이나니 \\<end>만 붙여주면 된다고 overfitting되어 학습된 것 같다.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "alternative-statistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <end> token이 존재하지 않으므로 해당 조건 삭제\n",
    "def generate_text(model, tokenizer, init_sentence=\"start\", max_len=15):\n",
    "    # 테스트를 위해서 입력받은 init_sentence도 텐서로 변환합니다\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "#     end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    # 단어 하나씩 예측해 문장을 만듭니다\n",
    "    #    1. 입력받은 문장의 텐서를 입력합니다\n",
    "    #    2. 예측된 값 중 가장 높은 확률인 word index를 뽑아냅니다\n",
    "    #    3. 2에서 예측된 word index를 문장 뒤에 붙입니다\n",
    "    #    4. 모델이 max_len에 도달했다면 문장 생성을 마칩니다\n",
    "    while True:\n",
    "        # 1\n",
    "        predict = model(test_tensor) \n",
    "        # 2\n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
    "        # 3 \n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "        # 4\n",
    "#         if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "    # tokenizer를 이용해 word index를 단어로 하나씩 변환합니다 \n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        if word_index == 0: #pading으로 넣은 0은 인덱스가 아니니 pass\n",
    "            continue\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efficient-juvenile",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model8 평가하기\n",
    "\n",
    "print(generate_text(model8, tokenizer, init_sentence=\"her smile\"))\n",
    "print(generate_text(model8, tokenizer, init_sentence=\"i love\"))\n",
    "print(generate_text(model8, tokenizer, init_sentence=\"you re\"))\n",
    "print(generate_text(model8, tokenizer, init_sentence=\"a letter\"))\n",
    "print(generate_text(model8, tokenizer, init_sentence=\"you make\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focal-slope",
   "metadata": {},
   "source": [
    "모델의 정량적 결과만 두고 본다면 양방향으로 학습된 LSTM이 훨씬 좋은 수치를 보이지만, 문장들을 비교했을 때 모델 학습이 잘 되었다고 하기는 어려울 것 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "better-front",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noted-nebraska",
   "metadata": {},
   "source": [
    "## 프로젝트 정리\n",
    "\n",
    "\n",
    "### 핵심개념\n",
    "\n",
    "__RNN__\n",
    "- 순환신경망은 은닉계층에 이전 정보를 기억시킬 수 있는 방향을 가지고 순환구조를 이루는 인공신경망의 한 종류이다.\n",
    "- 음성, 문자 등 순차적인(Sequential) 데이터 처리에 적합하다.\n",
    "- 이전 출력 결과의 영향을 받아 현재까지 계산된 결과를 메모리에 기억한다는 장점\n",
    "- 출력값이 곱해지는 단계가 반복되면 그 값이 소실되어 학습이 더 이상 이루어지지 않는 Vanishing gradien가 발생한다.(Long-Term dependencies 문제를 발생시킨다.)\n",
    "\n",
    "__BRNN__\n",
    "- RNN은 입력 순서를 순서대로(순방향) 처리하기 때문에 예측결과가 직전 패턴을 기반으로 하는 경향을 보이는 한계가 있다.\n",
    "- BRNN은 서로 연결되지 않는 두 개의 은닉층을 가지고 순방향, 역방향으로 분리된 순환신경망을 통해 학습시키기 때문에 예측정확도를 향상시킨다.\n",
    "\n",
    "__LSTM__\n",
    "- RNN의 기울기가 사라지는 Long-Term dependencies 문제를 극복하기 위해 제안된 RNN 구조\n",
    "- 시계열 데이터와 같은 긴 순서의 데이터에도 기울기 소실 문제없이 처리하게 한다.\n",
    "\n",
    "__Dropout__\n",
    "- 신경망의 뉴런들을 확률적으로 사용하지 않음으로써 과적합을 방지하는 기술\n",
    "- 모델의 일반화 성능을 향상시킨다. \n",
    "\n",
    "(https://www.koreascience.or.kr/article/JAKO202034352378448.pdf}\n",
    "\n",
    "\n",
    "### 시도해본 것\n",
    "\n",
    "1. 2-layer LSTM \n",
    "\n",
    "2. 3-layer LSTM\n",
    "\n",
    "3. 2-layer Bidirect LSTM\n",
    "\n",
    "\n",
    "### 이후에 더 시도해볼 것\n",
    "\n",
    "- 최적의 하이퍼 파라미터 찾기 (Grid Search랑 비교하여 진행해보기)\n",
    "- 양방향 RNN 모델에서 Dropout 이용해 과적합 줄이기\n",
    "\n",
    "\n",
    "### 기타\n",
    "\n",
    "- [History of model](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/History)\n",
    "    - model.fit을 object로 받으면 history 객체를 얻을 수 있어, epoch 별로 변화되는 추이를 그래프로 표현할 수 있다.\n",
    "    - history 객체가 갖고있는 정보: 매 epoch 마다 손실값(loss), 훈련 정확도(accuracy), 검증 손실값(val_loss), 검증 정확도(val_accuracy)\n",
    "\n",
    "    \n",
    "- save and load models<br>\n",
    "> 학습이 오래 걸리는 편이라 중간에 학습이 멈추거나 나중에 다시 그 모델의 결과를 확인하고 싶을때 모델을 다시 훈련시키는데 어려움이 있었다. 이럴 때 checkpoint를 사용할 수 있다고 한다.\n",
    "    - [ModelCheckpoint](https://www.tensorflow.org/tutorials/keras/save_and_load): 훈련중간과 마지막에 checkpoint를 자동으로 저장, 모델을 재사용하거나 훈련과정이 중지된 경우 이어서 훈련을 진행 할 수 있다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-softball",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
