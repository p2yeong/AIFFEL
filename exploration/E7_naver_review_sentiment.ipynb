{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "blessed-jesus",
   "metadata": {},
   "source": [
    "# 네이버 영화리뷰 감성분석 🎭"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generic-robert",
   "metadata": {},
   "source": [
    "사용할 데이터:[ Naver sentiment movie corpus](https://github.com/e9t/nsmc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-visit",
   "metadata": {},
   "source": [
    "## 1. 데이터 준비와 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sweet-tracker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import urllib.request\n",
    "# urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt\", filename=\"ratings.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "intimate-johnson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from collections import Counter\n",
    "\n",
    "# 데이터를 로드\n",
    "dir_path = dir_path = os.getenv('HOME')+'/aiffel/sentiment_classification/data'\n",
    "train_data = pd.read_table(os.path.join(dir_path, 'ratings_train.txt'))\n",
    "test_data = pd.read_table(os.path.join(dir_path, 'ratings_test.txt'))\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lucky-hundred",
   "metadata": {},
   "source": [
    "## 2. 데이터로더 구성\n",
    "다음의 기능을 수행하는 `data_loder`를 만든다.\n",
    "- 데이터의 중복 제거\n",
    "- NaN 결측치 제거\n",
    "- 한국어 토크나이저로 토큰화\n",
    "- 불용어(Stopwords) 제거\n",
    "- 사전word_to_index 구성\n",
    "- 텍스트 스트링을 사전 인덱스 스트링으로 변환\n",
    "- X_train, y_train, X_test, y_test, word_to_index 리턴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hired-involvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "tokenizer = Mecab()\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다'] # 불용어\n",
    "\n",
    "# 데이터 로더 함수 정의\n",
    "def load_data(train_data, test_data, num_words=10000):\n",
    "    # train data 전처리\n",
    "    train_data.drop_duplicates(subset=['document'], inplace=True)  # 중복 제거\n",
    "    train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")  # 특수문자 제거\n",
    "    train_data['document'].replace('', np.nan, inplace=True)  # 공백은 Null로 변경\n",
    "    train_data = train_data.dropna(how = 'any')  # 결측치 제거\n",
    "    # test data 전처리\n",
    "    test_data.drop_duplicates(subset=['document'], inplace=True)  # 중복 제거\n",
    "    test_data['document'] = test_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")  # 특수문자 제거\n",
    "    test_data['document'].replace('', np.nan, inplace=True)  # 공백은 Null로 변경\n",
    "    test_data = test_data.dropna(how = 'any')  # 결측치 제거\n",
    "\n",
    "    X_train = []\n",
    "    for sentence in train_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_train.append(temp_X)\n",
    "\n",
    "    X_test = []\n",
    "    for sentence in test_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_test.append(temp_X)\n",
    "    \n",
    "    # 단어사전 만들기\n",
    "    words = np.concatenate(X_train).tolist()\n",
    "    counter = Counter(words)\n",
    "    counter = counter.most_common(10000-4)  # 단어 빈도순으로 (10000-4)개 가져오기\n",
    "    vocab = ['<PAD>', '<BOS>', '<UNK>', '<UNUSED>'] + [key for key, _ in counter]  # 앞부분 4개 추가\n",
    "    word_to_index = {word:index for index, word in enumerate(vocab)}  # {단어:인덱스} 단어사전 생성\n",
    "    \n",
    "    # 리뷰 텍스트를 단어사전 인덱스로 변환\n",
    "    def wordlist_to_indexlist(wordlist):\n",
    "        return [word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in wordlist]\n",
    "    \n",
    "    X_train = list(map(wordlist_to_indexlist, X_train))\n",
    "    X_test = list(map(wordlist_to_indexlist, X_test))\n",
    "\n",
    "    return X_train, np.array(list(train_data['label'])), X_test, np.array(list(test_data['label'])), word_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "spoken-airplane",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  if __name__ == '__main__':\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data 개수: 145791, test data 개수: 48995\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data)\n",
    "print(\"train data 개수: {}, test data 개수: {}\".format(len(X_train), len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consistent-morgan",
   "metadata": {},
   "source": [
    "__index_to_word__ 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "crazy-alabama",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '<PAD>',\n",
       " 1: '<BOS>',\n",
       " 2: '<UNK>',\n",
       " 3: '<UNUSED>',\n",
       " 4: '영화',\n",
       " 5: '다',\n",
       " 6: '고',\n",
       " 7: '하',\n",
       " 8: '을',\n",
       " 9: '보',\n",
       " 10: '게',\n",
       " 11: '지',\n",
       " 12: '있',\n",
       " 13: '없',\n",
       " 14: '좋',\n",
       " 15: '나',\n",
       " 16: '었',\n",
       " 17: '만',\n",
       " 18: '는데',\n",
       " 19: '너무',\n",
       " 20: '봤',\n",
       " 21: '적',\n",
       " 22: '안',\n",
       " 23: '정말',\n",
       " 24: '로',\n",
       " 25: '것',\n",
       " 26: '음',\n",
       " 27: '아',\n",
       " 28: '네요',\n",
       " 29: '어',\n",
       " 30: '재밌',\n",
       " 31: '지만',\n",
       " 32: '같',\n",
       " 33: '진짜',\n",
       " 34: '에서',\n",
       " 35: '했',\n",
       " 36: '기',\n",
       " 37: '네',\n",
       " 38: '않',\n",
       " 39: '점',\n",
       " 40: '거',\n",
       " 41: '았',\n",
       " 42: '수',\n",
       " 43: '되',\n",
       " 44: '면',\n",
       " 45: 'ㅋㅋ',\n",
       " 46: '인',\n",
       " 47: '말',\n",
       " 48: '연기',\n",
       " 49: '주',\n",
       " 50: '최고',\n",
       " 51: '내',\n",
       " 52: '평점',\n",
       " 53: '이런',\n",
       " 54: '던',\n",
       " 55: '어요',\n",
       " 56: '할',\n",
       " 57: '왜',\n",
       " 58: '겠',\n",
       " 59: '스토리',\n",
       " 60: '해',\n",
       " 61: 'ㅋㅋㅋ',\n",
       " 62: '습니다',\n",
       " 63: '듯',\n",
       " 64: '아니',\n",
       " 65: '드라마',\n",
       " 66: '생각',\n",
       " 67: '더',\n",
       " 68: '그',\n",
       " 69: '싶',\n",
       " 70: '사람',\n",
       " 71: '때',\n",
       " 72: '감동',\n",
       " 73: '배우',\n",
       " 74: '함',\n",
       " 75: '본',\n",
       " 76: '까지',\n",
       " 77: '뭐',\n",
       " 78: '알',\n",
       " 79: '만들',\n",
       " 80: '내용',\n",
       " 81: '볼',\n",
       " 82: '보다',\n",
       " 83: '감독',\n",
       " 84: '라',\n",
       " 85: '재미',\n",
       " 86: '그냥',\n",
       " 87: '시간',\n",
       " 88: '지루',\n",
       " 89: '중',\n",
       " 90: '재미있',\n",
       " 91: '였',\n",
       " 92: '잼',\n",
       " 93: '년',\n",
       " 94: '사랑',\n",
       " 95: '못',\n",
       " 96: '재미없',\n",
       " 97: '냐',\n",
       " 98: '쓰레기',\n",
       " 99: '서',\n",
       " 100: '라고',\n",
       " 101: '니',\n",
       " 102: '면서',\n",
       " 103: '다시',\n",
       " 104: '번',\n",
       " 105: '나오',\n",
       " 106: '하나',\n",
       " 107: '작품',\n",
       " 108: '야',\n",
       " 109: '이거',\n",
       " 110: '줄',\n",
       " 111: '해서',\n",
       " 112: '남',\n",
       " 113: '마지막',\n",
       " 114: '끝',\n",
       " 115: '정도',\n",
       " 116: '이건',\n",
       " 117: '액션',\n",
       " 118: '개',\n",
       " 119: '임',\n",
       " 120: '건',\n",
       " 121: '기대',\n",
       " 122: '다는',\n",
       " 123: '입니다',\n",
       " 124: '라는',\n",
       " 125: '완전',\n",
       " 126: '참',\n",
       " 127: '많',\n",
       " 128: 'ㅋ',\n",
       " 129: '처음',\n",
       " 130: '장면',\n",
       " 131: '다가',\n",
       " 132: '아깝',\n",
       " 133: '으면',\n",
       " 134: '모르',\n",
       " 135: '지금',\n",
       " 136: '이렇게',\n",
       " 137: '분',\n",
       " 138: '돈',\n",
       " 139: '이게',\n",
       " 140: 'ㅠㅠ',\n",
       " 141: '성',\n",
       " 142: '느낌',\n",
       " 143: '이야기',\n",
       " 144: '일',\n",
       " 145: '최악',\n",
       " 146: '된',\n",
       " 147: '시',\n",
       " 148: '봐도',\n",
       " 149: '님',\n",
       " 150: '어서',\n",
       " 151: '애',\n",
       " 152: '편',\n",
       " 153: '다고',\n",
       " 154: '넘',\n",
       " 155: '인데',\n",
       " 156: '이해',\n",
       " 157: '전',\n",
       " 158: '별로',\n",
       " 159: '걸',\n",
       " 160: '그리고',\n",
       " 161: '명작',\n",
       " 162: '난',\n",
       " 163: '또',\n",
       " 164: '역시',\n",
       " 165: '여자',\n",
       " 166: '한국',\n",
       " 167: '이상',\n",
       " 168: '는지',\n",
       " 169: '많이',\n",
       " 170: '에게',\n",
       " 171: '부터',\n",
       " 172: '주인공',\n",
       " 173: '받',\n",
       " 174: '합니다',\n",
       " 175: '대',\n",
       " 176: '두',\n",
       " 177: '우리',\n",
       " 178: '만든',\n",
       " 179: '길',\n",
       " 180: '엔',\n",
       " 181: '살',\n",
       " 182: '괜찮',\n",
       " 183: '요',\n",
       " 184: '기억',\n",
       " 185: 'ㅡㅡ',\n",
       " 186: '한다',\n",
       " 187: '연출',\n",
       " 188: 'ㅎㅎ',\n",
       " 189: '때문',\n",
       " 190: '저',\n",
       " 191: '이나',\n",
       " 192: '재',\n",
       " 193: '꼭',\n",
       " 194: '며',\n",
       " 195: '현실',\n",
       " 196: '랑',\n",
       " 197: '긴',\n",
       " 198: '무슨',\n",
       " 199: '내내',\n",
       " 200: '죽',\n",
       " 201: '결말',\n",
       " 202: '남자',\n",
       " 203: '전개',\n",
       " 204: '마음',\n",
       " 205: '세요',\n",
       " 206: '소재',\n",
       " 207: '속',\n",
       " 208: '아서',\n",
       " 209: '공포',\n",
       " 210: '데',\n",
       " 211: '다른',\n",
       " 212: '인생',\n",
       " 213: '씨',\n",
       " 214: '짜증',\n",
       " 215: '뿐',\n",
       " 216: '짱',\n",
       " 217: '은데',\n",
       " 218: '아요',\n",
       " 219: '아이',\n",
       " 220: '필요',\n",
       " 221: '유치',\n",
       " 222: '가장',\n",
       " 223: '음악',\n",
       " 224: '일본',\n",
       " 225: '낮',\n",
       " 226: '오',\n",
       " 227: '반전',\n",
       " 228: '수준',\n",
       " 229: '웃',\n",
       " 230: '다니',\n",
       " 231: '매력',\n",
       " 232: '별',\n",
       " 233: '인지',\n",
       " 234: '맞',\n",
       " 235: '가슴',\n",
       " 236: '없이',\n",
       " 237: '원작',\n",
       " 238: '인간',\n",
       " 239: '굿',\n",
       " 240: '높',\n",
       " 241: 'ㄷ',\n",
       " 242: '밋',\n",
       " 243: '만드',\n",
       " 244: '눈물',\n",
       " 245: '급',\n",
       " 246: '보여',\n",
       " 247: '준',\n",
       " 248: '찍',\n",
       " 249: '인가',\n",
       " 250: '노',\n",
       " 251: '코미디',\n",
       " 252: '신',\n",
       " 253: '용',\n",
       " 254: '모든',\n",
       " 255: '마',\n",
       " 256: '화',\n",
       " 257: '추천',\n",
       " 258: '아직',\n",
       " 259: '아닌',\n",
       " 260: '처럼',\n",
       " 261: '쓰',\n",
       " 262: '눈',\n",
       " 263: '자체',\n",
       " 264: '울',\n",
       " 265: '몰입',\n",
       " 266: '대박',\n",
       " 267: '란',\n",
       " 268: '스럽',\n",
       " 269: '몇',\n",
       " 270: '을까',\n",
       " 271: '실망',\n",
       " 272: '대한',\n",
       " 273: '는다',\n",
       " 274: '여',\n",
       " 275: '그런',\n",
       " 276: '죠',\n",
       " 277: '솔직히',\n",
       " 278: '캐릭터',\n",
       " 279: '아주',\n",
       " 280: '모두',\n",
       " 281: '전혀',\n",
       " 282: '가족',\n",
       " 283: '여운',\n",
       " 284: '건지',\n",
       " 285: '연기력',\n",
       " 286: '될',\n",
       " 287: '다면',\n",
       " 288: '뭔가',\n",
       " 289: '그래도',\n",
       " 290: '후',\n",
       " 291: '나라',\n",
       " 292: '시리즈',\n",
       " 293: 'ㅎ',\n",
       " 294: '근데',\n",
       " 295: '표현',\n",
       " 296: '모습',\n",
       " 297: '계속',\n",
       " 298: '작',\n",
       " 299: '공감',\n",
       " 300: '먹',\n",
       " 301: '제목',\n",
       " 302: '비',\n",
       " 303: '이랑',\n",
       " 304: '극장',\n",
       " 305: '치',\n",
       " 306: '이걸',\n",
       " 307: '부분',\n",
       " 308: '그렇',\n",
       " 309: '대사',\n",
       " 310: '바',\n",
       " 311: '대단',\n",
       " 312: '어디',\n",
       " 313: '개봉',\n",
       " 314: '진',\n",
       " 315: '아쉽',\n",
       " 316: '된다',\n",
       " 317: '기분',\n",
       " 318: '작가',\n",
       " 319: '진심',\n",
       " 320: '구',\n",
       " 321: '해도',\n",
       " 322: '놓',\n",
       " 323: '타임',\n",
       " 324: '봐야',\n",
       " 325: '제',\n",
       " 326: '보이',\n",
       " 327: '웃기',\n",
       " 328: '막장',\n",
       " 329: '삶',\n",
       " 330: '물',\n",
       " 331: '친구',\n",
       " 332: '잔잔',\n",
       " 333: '이제',\n",
       " 334: '조금',\n",
       " 335: '억지',\n",
       " 336: '가지',\n",
       " 337: 'ㅠ',\n",
       " 338: '영상',\n",
       " 339: '찾',\n",
       " 340: '라도',\n",
       " 341: '씬',\n",
       " 342: '딱',\n",
       " 343: '요즘',\n",
       " 344: '같이',\n",
       " 345: '스릴러',\n",
       " 346: '믿',\n",
       " 347: '싫',\n",
       " 348: '나왔',\n",
       " 349: '아까운',\n",
       " 350: '중간',\n",
       " 351: '긴장감',\n",
       " 352: '어떻게',\n",
       " 353: '개인',\n",
       " 354: '제대로',\n",
       " 355: '점수',\n",
       " 356: '부족',\n",
       " 357: '이유',\n",
       " 358: '노래',\n",
       " 359: '만큼',\n",
       " 360: 'ㅜㅜ',\n",
       " 361: '라면',\n",
       " 362: '시작',\n",
       " 363: '잇',\n",
       " 364: '구나',\n",
       " 365: '한테',\n",
       " 366: '특히',\n",
       " 367: '려고',\n",
       " 368: '날',\n",
       " 369: '제일',\n",
       " 370: '아름다운',\n",
       " 371: '시대',\n",
       " 372: '니까',\n",
       " 373: '엔딩',\n",
       " 374: '당시',\n",
       " 375: '나름',\n",
       " 376: '무섭',\n",
       " 377: '오랜만',\n",
       " 378: '나온',\n",
       " 379: '이것',\n",
       " 380: '봐',\n",
       " 381: '팬',\n",
       " 382: '해요',\n",
       " 383: '사',\n",
       " 384: '차라리',\n",
       " 385: '절대',\n",
       " 386: '세상',\n",
       " 387: '못하',\n",
       " 388: '감',\n",
       " 389: '의미',\n",
       " 390: '봄',\n",
       " 391: '훌륭',\n",
       " 392: '욕',\n",
       " 393: '너무나',\n",
       " 394: '강추',\n",
       " 395: '드',\n",
       " 396: '따뜻',\n",
       " 397: '됨',\n",
       " 398: '빼',\n",
       " 399: '느끼',\n",
       " 400: '해야',\n",
       " 401: '명',\n",
       " 402: '글',\n",
       " 403: '던데',\n",
       " 404: '뻔',\n",
       " 405: '도대체',\n",
       " 406: '어야',\n",
       " 407: '마다',\n",
       " 408: '답답',\n",
       " 409: '전쟁',\n",
       " 410: '놈',\n",
       " 411: '무엇',\n",
       " 412: '설정',\n",
       " 413: '흥미',\n",
       " 414: '만화',\n",
       " 415: '그저',\n",
       " 416: '감정',\n",
       " 417: '준다',\n",
       " 418: '수작',\n",
       " 419: '행복',\n",
       " 420: '신선',\n",
       " 421: '미국',\n",
       " 422: '앞',\n",
       " 423: '허접',\n",
       " 424: '형',\n",
       " 425: '세',\n",
       " 426: '시절',\n",
       " 427: '관객',\n",
       " 428: '사실',\n",
       " 429: '배경',\n",
       " 430: '어도',\n",
       " 431: '답',\n",
       " 432: '초반',\n",
       " 433: '웃음',\n",
       " 434: '엄청',\n",
       " 435: '자신',\n",
       " 436: '더라',\n",
       " 437: '추억',\n",
       " 438: '군',\n",
       " 439: '질',\n",
       " 440: '캐스팅',\n",
       " 441: '멋있',\n",
       " 442: '라니',\n",
       " 443: '시나리오',\n",
       " 444: '정신',\n",
       " 445: '어색',\n",
       " 446: '첨',\n",
       " 447: '머',\n",
       " 448: '슬프',\n",
       " 449: '밖에',\n",
       " 450: '분위기',\n",
       " 451: '소름',\n",
       " 452: '멋진',\n",
       " 453: '힘들',\n",
       " 454: '오늘',\n",
       " 455: '어이없',\n",
       " 456: '봐서',\n",
       " 457: '간',\n",
       " 458: '집',\n",
       " 459: '구성',\n",
       " 460: '잡',\n",
       " 461: '엄마',\n",
       " 462: '함께',\n",
       " 463: '위해',\n",
       " 464: '잊',\n",
       " 465: '졸작',\n",
       " 466: '류',\n",
       " 467: '이딴',\n",
       " 468: '문제',\n",
       " 469: '등',\n",
       " 470: '유쾌',\n",
       " 471: '킬링',\n",
       " 472: '스러운',\n",
       " 473: '결국',\n",
       " 474: '소리',\n",
       " 475: '낫',\n",
       " 476: '뭘',\n",
       " 477: '뭔',\n",
       " 478: '한데',\n",
       " 479: '역사',\n",
       " 480: '제발',\n",
       " 481: '포스터',\n",
       " 482: '아무리',\n",
       " 483: '코믹',\n",
       " 484: '어떤',\n",
       " 485: '얼마나',\n",
       " 486: '완벽',\n",
       " 487: '맘',\n",
       " 488: '애니메이션',\n",
       " 489: '러',\n",
       " 490: '주연',\n",
       " 491: '보고',\n",
       " 492: '후회',\n",
       " 493: '버리',\n",
       " 494: '뻔한',\n",
       " 495: '나요',\n",
       " 496: '어릴',\n",
       " 497: '진부',\n",
       " 498: '나올',\n",
       " 499: '장난',\n",
       " 500: '출연',\n",
       " 501: '보단',\n",
       " 502: '큰',\n",
       " 503: '책',\n",
       " 504: '됐',\n",
       " 505: '영화관',\n",
       " 506: '밖',\n",
       " 507: '더니',\n",
       " 508: '개연',\n",
       " 509: '둘',\n",
       " 510: 'ㅅ',\n",
       " 511: '충격',\n",
       " 512: '여기',\n",
       " 513: '극',\n",
       " 514: '난다',\n",
       " 515: '평가',\n",
       " 516: '잔인',\n",
       " 517: '아름답',\n",
       " 518: '줬',\n",
       " 519: '얘기',\n",
       " 520: '예술',\n",
       " 521: '갈수록',\n",
       " 522: '매우',\n",
       " 523: '든',\n",
       " 524: '위한',\n",
       " 525: '불',\n",
       " 526: '꺼',\n",
       " 527: '이후',\n",
       " 528: '이리',\n",
       " 529: '자기',\n",
       " 530: '읽',\n",
       " 531: '꽤',\n",
       " 532: '얼굴',\n",
       " 533: '반',\n",
       " 534: '옛날',\n",
       " 535: '깊',\n",
       " 536: '점대',\n",
       " 537: '티비',\n",
       " 538: '이쁘',\n",
       " 539: '원',\n",
       " 540: '시청',\n",
       " 541: '불쌍',\n",
       " 542: '못한',\n",
       " 543: '순수',\n",
       " 544: '별점',\n",
       " 545: '텐데',\n",
       " 546: '겟',\n",
       " 547: '으나',\n",
       " 548: '봐라',\n",
       " 549: '언제',\n",
       " 550: '낭비',\n",
       " 551: '비디오',\n",
       " 552: '라서',\n",
       " 553: '배',\n",
       " 554: '건가',\n",
       " 555: '장르',\n",
       " 556: '머리',\n",
       " 557: '엇',\n",
       " 558: '그래서',\n",
       " 559: '주제',\n",
       " 560: '다음',\n",
       " 561: '생각나',\n",
       " 562: '다운',\n",
       " 563: '다큐',\n",
       " 564: '궁금',\n",
       " 565: '아님',\n",
       " 566: '존나',\n",
       " 567: '그렇게',\n",
       " 568: '하지만',\n",
       " 569: '시키',\n",
       " 570: '애니',\n",
       " 571: '예전',\n",
       " 572: '누구',\n",
       " 573: '미친',\n",
       " 574: '아무',\n",
       " 575: '그만',\n",
       " 576: '미',\n",
       " 577: '진정',\n",
       " 578: '크',\n",
       " 579: '인상',\n",
       " 580: '상황',\n",
       " 581: '그러',\n",
       " 582: '뒤',\n",
       " 583: '감사',\n",
       " 584: '스릴',\n",
       " 585: '이름',\n",
       " 586: '오래',\n",
       " 587: '집중',\n",
       " 588: '본다',\n",
       " 589: '어느',\n",
       " 590: '시즌',\n",
       " 591: '약간',\n",
       " 592: '나와서',\n",
       " 593: '로맨스',\n",
       " 594: '방송',\n",
       " 595: '그나마',\n",
       " 596: '식',\n",
       " 597: '짜리',\n",
       " 598: '마세요',\n",
       " 599: '났',\n",
       " 600: '소설',\n",
       " 601: '까',\n",
       " 602: '그대로',\n",
       " 603: '여주인공',\n",
       " 604: '인물',\n",
       " 605: '걸작',\n",
       " 606: '떨어지',\n",
       " 607: '훨씬',\n",
       " 608: '그것',\n",
       " 609: '힘',\n",
       " 610: '동안',\n",
       " 611: '몰',\n",
       " 612: '케',\n",
       " 613: '죽이',\n",
       " 614: '꿈',\n",
       " 615: '너',\n",
       " 616: '대체',\n",
       " 617: '실화',\n",
       " 618: '만점',\n",
       " 619: '사회',\n",
       " 620: '평',\n",
       " 621: '짓',\n",
       " 622: '해라',\n",
       " 623: '에요',\n",
       " 624: '누가',\n",
       " 625: '전체',\n",
       " 626: '비슷',\n",
       " 627: '막',\n",
       " 628: '발연기',\n",
       " 629: '엉성',\n",
       " 630: '왔',\n",
       " 631: '입',\n",
       " 632: '귀엽',\n",
       " 633: '끝나',\n",
       " 634: '중국',\n",
       " 635: '햇',\n",
       " 636: '초딩',\n",
       " 637: '여주',\n",
       " 638: '비교',\n",
       " 639: '세계',\n",
       " 640: '여배우',\n",
       " 641: '영상미',\n",
       " 642: '감성',\n",
       " 643: '네이버',\n",
       " 644: '는가',\n",
       " 645: '구만',\n",
       " 646: '느껴',\n",
       " 647: '단',\n",
       " 648: '상',\n",
       " 649: 'ㅎㅎㅎ',\n",
       " 650: '순간',\n",
       " 651: '나이',\n",
       " 652: '려는',\n",
       " 653: '대해',\n",
       " 654: '무',\n",
       " 655: '어렸',\n",
       " 656: '첫',\n",
       " 657: '쯤',\n",
       " 658: '꿀',\n",
       " 659: '망',\n",
       " 660: '판',\n",
       " 661: '학교',\n",
       " 662: '갔',\n",
       " 663: '어설픈',\n",
       " 664: '더럽',\n",
       " 665: '생',\n",
       " 666: '돋',\n",
       " 667: '셨',\n",
       " 668: '회',\n",
       " 669: '아야',\n",
       " 670: '느낄',\n",
       " 671: '혼자',\n",
       " 672: '아들',\n",
       " 673: '어린',\n",
       " 674: '가능',\n",
       " 675: '성룡',\n",
       " 676: '졸',\n",
       " 677: '타',\n",
       " 678: '멋지',\n",
       " 679: '바로',\n",
       " 680: '교훈',\n",
       " 681: '잘못',\n",
       " 682: '한마디',\n",
       " 683: '나가',\n",
       " 684: '맛',\n",
       " 685: '당신',\n",
       " 686: '끌',\n",
       " 687: '딸',\n",
       " 688: '화려',\n",
       " 689: '길래',\n",
       " 690: '티',\n",
       " 691: '판타지',\n",
       " 692: '땜',\n",
       " 693: '달',\n",
       " 694: '맨',\n",
       " 695: '잠',\n",
       " 696: '빨리',\n",
       " 697: '똥',\n",
       " 698: '거의',\n",
       " 699: '목소리',\n",
       " 700: '든다',\n",
       " 701: '삼류',\n",
       " 702: '듣',\n",
       " 703: '전부',\n",
       " 704: '봤었',\n",
       " 705: '나온다',\n",
       " 706: '건데',\n",
       " 707: '지루함',\n",
       " 708: '독특',\n",
       " 709: '다르',\n",
       " 710: '한번',\n",
       " 711: '어른',\n",
       " 712: '질질',\n",
       " 713: 'ㅉㅉ',\n",
       " 714: '률',\n",
       " 715: '상당히',\n",
       " 716: '가치',\n",
       " 717: '씩',\n",
       " 718: '아까움',\n",
       " 719: '넣',\n",
       " 720: '아버지',\n",
       " 721: '차',\n",
       " 722: '영',\n",
       " 723: '줄거리',\n",
       " 724: '스타일',\n",
       " 725: '평론가',\n",
       " 726: '대로',\n",
       " 727: '다만',\n",
       " 728: '여러',\n",
       " 729: '갑자기',\n",
       " 730: '이번',\n",
       " 731: '군요',\n",
       " 732: '허무',\n",
       " 733: '의도',\n",
       " 734: '그러나',\n",
       " 735: '저런',\n",
       " 736: '존재',\n",
       " 737: 'ㅂ',\n",
       " 738: '존',\n",
       " 739: '밑',\n",
       " 740: '초',\n",
       " 741: '위',\n",
       " 742: '에선',\n",
       " 743: '너무너무',\n",
       " 744: '째',\n",
       " 745: '당',\n",
       " 746: '예상',\n",
       " 747: '으면서',\n",
       " 748: '성우',\n",
       " 749: '버린',\n",
       " 750: '각본',\n",
       " 751: '이러',\n",
       " 752: '그녀',\n",
       " 753: '화면',\n",
       " 754: 'ㄱ',\n",
       " 755: '비해',\n",
       " 756: '점점',\n",
       " 757: '떠나',\n",
       " 758: '자연',\n",
       " 759: '뻔하',\n",
       " 760: '평범',\n",
       " 761: '굉장히',\n",
       " 762: '만나',\n",
       " 763: '담',\n",
       " 764: '슬픈',\n",
       " 765: '그런지',\n",
       " 766: '예쁘',\n",
       " 767: '복수',\n",
       " 768: '단순',\n",
       " 769: '중요',\n",
       " 770: '낸',\n",
       " 771: '줌',\n",
       " 772: '갖',\n",
       " 773: '댓글',\n",
       " 774: '극장판',\n",
       " 775: '돼',\n",
       " 776: '새로운',\n",
       " 777: '제작',\n",
       " 778: '피',\n",
       " 779: '만족',\n",
       " 780: '못했',\n",
       " 781: '앗',\n",
       " 782: '일단',\n",
       " 783: '쉽',\n",
       " 784: '선택',\n",
       " 785: '한편',\n",
       " 786: '쓴',\n",
       " 787: '버렸',\n",
       " 788: '굳',\n",
       " 789: '아빠',\n",
       " 790: '관람',\n",
       " 791: '요소',\n",
       " 792: '불편',\n",
       " 793: '항상',\n",
       " 794: '스',\n",
       " 795: '지나',\n",
       " 796: '거기',\n",
       " 797: '한다는',\n",
       " 798: '나옴',\n",
       " 799: '연출력',\n",
       " 800: '그때',\n",
       " 801: '탄탄',\n",
       " 802: '롭',\n",
       " 803: '잃',\n",
       " 804: '에로',\n",
       " 805: '려',\n",
       " 806: '흥행',\n",
       " 807: '한심',\n",
       " 808: '부',\n",
       " 809: '물론',\n",
       " 810: '거나',\n",
       " 811: '예요',\n",
       " 812: '역대',\n",
       " 813: '편집',\n",
       " 814: '따라',\n",
       " 815: '관계',\n",
       " 816: '전형',\n",
       " 817: '산',\n",
       " 818: '진행',\n",
       " 819: '삼',\n",
       " 820: '짧',\n",
       " 821: '아닌가',\n",
       " 822: '충분히',\n",
       " 823: '멜',\n",
       " 824: '법',\n",
       " 825: '총',\n",
       " 826: '에겐',\n",
       " 827: '조',\n",
       " 828: '던가',\n",
       " 829: '안타깝',\n",
       " 830: '이하',\n",
       " 831: '따',\n",
       " 832: '식상',\n",
       " 833: '자꾸',\n",
       " 834: '훈훈',\n",
       " 835: '도록',\n",
       " 836: '게임',\n",
       " 837: '미안',\n",
       " 838: '아까워',\n",
       " 839: '화이팅',\n",
       " 840: '곳',\n",
       " 841: '김',\n",
       " 842: '원래',\n",
       " 843: '그게',\n",
       " 844: '구요',\n",
       " 845: '자극',\n",
       " 846: '몰랐',\n",
       " 847: '몸',\n",
       " 848: '손',\n",
       " 849: '어쩔',\n",
       " 850: '풀',\n",
       " 851: '사건',\n",
       " 852: '똑같',\n",
       " 853: '뭔지',\n",
       " 854: '설명',\n",
       " 855: '잖아',\n",
       " 856: '어울리',\n",
       " 857: '나쁜',\n",
       " 858: '팔',\n",
       " 859: '그래픽',\n",
       " 860: '노력',\n",
       " 861: '귀신',\n",
       " 862: '짐',\n",
       " 863: '도저히',\n",
       " 864: '상상',\n",
       " 865: '과거',\n",
       " 866: '조차',\n",
       " 867: '간다',\n",
       " 868: '됬',\n",
       " 869: '아프',\n",
       " 870: '닿',\n",
       " 871: '장',\n",
       " 872: '개그',\n",
       " 873: '황당',\n",
       " 874: '프랑스',\n",
       " 875: '무조건',\n",
       " 876: '홍콩',\n",
       " 877: '취향',\n",
       " 878: '죽음',\n",
       " 879: '듬',\n",
       " 880: '코메디',\n",
       " 881: '미치',\n",
       " 882: '발',\n",
       " 883: '중반',\n",
       " 884: '빠',\n",
       " 885: '속편',\n",
       " 886: '새끼',\n",
       " 887: '했었',\n",
       " 888: '빠져',\n",
       " 889: '소중',\n",
       " 890: '프로',\n",
       " 891: '짱짱',\n",
       " 892: '무비',\n",
       " 893: '병맛',\n",
       " 894: '더빙',\n",
       " 895: '빙',\n",
       " 896: '역',\n",
       " 897: 'ㅜ',\n",
       " 898: '나쁘',\n",
       " 899: '간만에',\n",
       " 900: '좋아하',\n",
       " 901: '아쉬운',\n",
       " 902: '멋',\n",
       " 903: '넘치',\n",
       " 904: '상영',\n",
       " 905: '진지',\n",
       " 906: '빠지',\n",
       " 907: '끝내',\n",
       " 908: '더욱',\n",
       " 909: '참신',\n",
       " 910: '괜히',\n",
       " 911: '쳐',\n",
       " 912: '무서운',\n",
       " 913: '특유',\n",
       " 914: '유명',\n",
       " 915: '척',\n",
       " 916: '심리',\n",
       " 917: '결혼',\n",
       " 918: '전설',\n",
       " 919: '엄청난',\n",
       " 920: '숨',\n",
       " 921: '오히려',\n",
       " 922: '헐',\n",
       " 923: '예고편',\n",
       " 924: '짜',\n",
       " 925: '또한',\n",
       " 926: '고자',\n",
       " 927: '후반부',\n",
       " 928: '틀',\n",
       " 929: '아저씨',\n",
       " 930: '바보',\n",
       " 931: '심하',\n",
       " 932: '왕',\n",
       " 933: '연기자',\n",
       " 934: '촬영',\n",
       " 935: '리',\n",
       " 936: '아도',\n",
       " 937: '천재',\n",
       " 938: '소녀',\n",
       " 939: '느꼈',\n",
       " 940: '그리',\n",
       " 941: '로맨틱',\n",
       " 942: '조연',\n",
       " 943: '비추',\n",
       " 944: '최근',\n",
       " 945: '이란',\n",
       " 946: '희망',\n",
       " 947: '으니',\n",
       " 948: '억지로',\n",
       " 949: '가볍',\n",
       " 950: '는구나',\n",
       " 951: 'ㄴ',\n",
       " 952: '마무리',\n",
       " 953: '표정',\n",
       " 954: '쩔',\n",
       " 955: '현재',\n",
       " 956: '전편',\n",
       " 957: '아무것',\n",
       " 958: '온',\n",
       " 959: '힘든',\n",
       " 960: '로서',\n",
       " 961: '부모',\n",
       " 962: '어라',\n",
       " 963: '이야',\n",
       " 964: '던지',\n",
       " 965: '동화',\n",
       " 966: '순',\n",
       " 967: '대작',\n",
       " 968: '아쉬움',\n",
       " 969: '점주',\n",
       " 970: '서로',\n",
       " 971: '저질',\n",
       " 972: '진실',\n",
       " 973: '즐겁',\n",
       " 974: '노출',\n",
       " 975: '대한민국',\n",
       " 976: '빨',\n",
       " 977: '흠',\n",
       " 978: '메세지',\n",
       " 979: '우연히',\n",
       " 980: '적당',\n",
       " 981: '그림',\n",
       " 982: '묘사',\n",
       " 983: '여성',\n",
       " 984: '이미',\n",
       " 985: '그런데',\n",
       " 986: '땐',\n",
       " 987: '지난',\n",
       " 988: '엉망',\n",
       " 989: '이래',\n",
       " 990: '경찰',\n",
       " 991: '그닥',\n",
       " 992: '프로그램',\n",
       " 993: '살인',\n",
       " 994: '쩌',\n",
       " 995: '유머',\n",
       " 996: '오빠',\n",
       " 997: '남기',\n",
       " 998: '어설프',\n",
       " 999: '십',\n",
       " ...}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "index_to_word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "treated-problem",
   "metadata": {},
   "source": [
    "__Encode/Decode 함수__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "operating-andrews",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트 벡터로 변환해 주는 함수입니다. \n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "# 여러 개의 문장 리스트를 한꺼번에 단어 인덱스 리스트 벡터로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "flush-prevention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27, 67, 895, 33, 214, 15, 28, 699]\n",
      "더 빙 진짜 짜증 나 네요 목소리\n",
      "Label:  0\n",
      "[977, 481, 491, 636, 4, 110, 1554, 48, 866, 949, 11, 38, 364]\n",
      "포스터 보고 초딩 영화 줄 오버 연기 조차 가볍 지 않 구나\n",
      "Label:  1\n",
      "[19, 192, 2]\n",
      "재 <UNK>\n",
      "Label:  0\n",
      "[8035, 143, 4134, 277, 85, 13, 5, 52, 3326]\n",
      "이야기 구먼 솔직히 재미 없 다 평점 조정\n",
      "Label:  0\n",
      "[2, 8488, 1051, 48, 2702, 54, 4, 2625, 34, 1118, 29, 326, 36, 17, 35, 54, 2, 2, 393, 2850, 1677, 5]\n",
      "익살 스런 연기 돋보였 던 영화 스파이더맨 에서 늙 어 보이 기 만 했 던 <UNK> <UNK> 너무나 이뻐 보였 다\n",
      "Label:  1\n",
      "[627, 2, 2, 425, 171, 1464, 661, 1592, 665, 46, 2, 4, 61, 2167, 118, 718]\n",
      "<UNK> <UNK> 세 부터 초등 학교 학년 생 인 <UNK> 영화 ㅋㅋㅋ 별반 개 아까움\n",
      "Label:  0\n",
      "[237, 351, 8, 354, 1909, 51, 11, 780, 5]\n",
      "긴장감 을 제대로 살려 내 지 못했 다\n",
      "Label:  0\n",
      "[232, 1344, 132, 5, 392, 705, 2, 2, 48, 1434, 269, 93, 233, 23, 882, 24, 321, 608, 501, 475, 546, 5, 3165, 8489, 17, 1386, 1386, 65, 282, 13, 5, 48, 95, 7, 70, 17, 2, 37]\n",
      "반개 아깝 다 욕 나온다 <UNK> <UNK> 연기 생활 몇 년 인지 정말 발 로 해도 그것 보단 낫 겟 다 납치 감금 만 반복 반복 드라마 가족 없 다 연기 못 하 사람 만 <UNK> 네\n",
      "Label:  0\n",
      "[117, 13, 18, 85, 12, 269, 22, 43, 4]\n",
      "없 는데 재미 있 몇 안 되 영화\n",
      "Label:  1\n",
      "[57, 612, 52, 225, 706, 531, 81, 17, 478, 1403, 596, 688, 74, 17, 19, 2, 12, 15]\n",
      "케 평점 낮 건데 꽤 볼 만 한데 헐리우드 식 화려 함 만 너무 <UNK> 있 나\n",
      "Label:  1\n"
     ]
    }
   ],
   "source": [
    "# decode된 문장과 라벨을 비교하여 일치하는지 확인\n",
    "for i in range(10):\n",
    "    print(X_train[i])\n",
    "    print(get_decoded_sentence(X_train[i], index_to_word))\n",
    "    print('Label: ', y_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clinical-firmware",
   "metadata": {},
   "source": [
    "## 3. 모델 구성을 위한 데이터 분석 및 가공"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complicated-relaxation",
   "metadata": {},
   "source": [
    "### 3.1 데이터셋 내 문장 길이 분포\n",
    "embedding 레이어의 input 이 되는 문장 벡터는 그 길이가 일정 해야 한다. 문장 최대 길이 maxlen의 값 설정은 전체 모델 성능에 영향을 미치게 되므로, 적절한 값을 찾기 위해서 전체 데이터 셋의 분포를 확인해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "addressed-reggae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  13.757179674103888\n",
      "문장길이 최대 :  83\n",
      "문장길이 표준편차 :  11.462771769216866\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEGCAYAAACkQqisAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAZY0lEQVR4nO3de7BlZXnn8e8voHgPIC2FgGnULiMaRWwBS5JBnSCICThjFCYJLUHJJBhwRo3tZQJRKbFMvCWGiIHQOipSXkKPtmKHgMZRkeYyXLXsgSY0QWjlrhMUeOaP9Z64OZzTZ7O699ln9/l+qlbttZ69Ls/e7D4P77vWeleqCkmS+vilcScgSZpcFhFJUm8WEUlSbxYRSVJvFhFJUm/bjzuB+bbLLrvU0qVLx52GJE2USy655EdVtWR6fNEVkaVLl7Ju3bpxpyFJEyXJDTPF7c6SJPVmEZEk9WYRkST1ZhGRJPVmEZEk9WYRkST1ZhGRJPVmEZEk9WYRkST1tujuWF8Ilq788ozxDaceNs+ZSNKWsSUiSerNIiJJ6m1k3VlJ9gQ+AewKFHB6VX04ycnA64FNbdW3V9Wats3bgGOB+4ETquq8Fj8E+DCwHfB3VXVqi+8FnA08EbgE+P2q+tmoPtOo2c0ladKMsiVyH/CmqtobOAA4Psne7b0PVtU+bZoqIHsDRwLPAg4B/ibJdkm2Az4KHArsDRw1sJ/3tX09HbidrgBJkubJyIpIVd1cVZe2+buBa4HdN7PJ4cDZVXVvVV0PrAf2a9P6qrqutTLOBg5PEuAlwOfa9quAI0byYSRJM5qXcyJJlgLPAy5qoTckuSLJmUl2arHdgRsHNtvYYrPFnwjcUVX3TYvPdPzjkqxLsm7Tpk0zrSJJ6mHkRSTJ44DPA2+sqruA04CnAfsANwN/Oeocqur0qlpeVcuXLHnIg7kkST2N9D6RJI+gKyCfqqovAFTVLQPvfxz4Ulu8CdhzYPM9WoxZ4j8GdkyyfWuNDK4vSZoHI2uJtHMWZwDXVtUHBuK7Daz2SuCqNr8aODLJDu2qq2XAd4GLgWVJ9krySLqT76urqoALgFe17VcA547q80iSHmqULZEXAb8PXJnk8hZ7O93VVfvQXfa7AfhDgKq6Osk5wDV0V3YdX1X3AyR5A3Ae3SW+Z1bV1W1/bwXOTvIe4DK6oiVJmicjKyJV9U0gM7y1ZjPbnAKcMkN8zUzbVdV1dFdvSZLGwDvWJUm9WUQkSb1ZRCRJvVlEJEm9WUQkSb1ZRCRJvVlEJEm9WUQkSb1ZRCRJvVlEJEm9WUQkSb1ZRCRJvVlEJEm9WUQkSb1ZRCRJvVlEJEm9WUQkSb1ZRCRJvVlEJEm9WUQkSb1ZRCRJvVlEJEm9WUQkSb1ZRCRJvVlEJEm9WUQkSb1ZRCRJvVlEJEm9WUQkSb1ZRCRJvW0/7gTU39KVX571vQ2nHjaPmUharEbWEkmyZ5ILklyT5OokJ7b4zknWJvlBe92pxZPkI0nWJ7kiyb4D+1rR1v9BkhUD8ecnubJt85EkGdXnkSQ91Ci7s+4D3lRVewMHAMcn2RtYCZxfVcuA89sywKHAsjYdB5wGXdEBTgL2B/YDTpoqPG2d1w9sd8gIP48kaZqRFZGqurmqLm3zdwPXArsDhwOr2mqrgCPa/OHAJ6rzHWDHJLsBLwPWVtVtVXU7sBY4pL33hKr6TlUV8ImBfUmS5sG8nFhPshR4HnARsGtV3dze+iGwa5vfHbhxYLONLba5+MYZ4jMd/7gk65Ks27Rp05Z9GEnSvxt5EUnyOODzwBur6q7B91oLokadQ1WdXlXLq2r5kiVLRn04SVo0RlpEkjyCroB8qqq+0MK3tK4o2uutLX4TsOfA5nu02Obie8wQlyTNk1FenRXgDODaqvrAwFurgakrrFYA5w7Ej25XaR0A3Nm6vc4DDk6yUzuhfjBwXnvvriQHtGMdPbAvSdI8GOV9Ii8Cfh+4MsnlLfZ24FTgnCTHAjcAr27vrQFeDqwHfgocA1BVtyV5N3BxW+9dVXVbm/9j4Czg0cBX2iRJmicjKyJV9U1gtvs2XjrD+gUcP8u+zgTOnCG+Dnj2FqQpSdoCDnsiSerNIiJJ6m2oIpLkwCTHtPklSfYabVqSpEkwZxFJchLwVuBtLfQI4H+OMilJ0mQYpiXySuC3gZ8AVNW/Ao8fZVKSpMkwTBH52eCd5UkeO9qUJEmTYpgick6Sj9ENiPh64B+Bj482LUnSJJjzPpGq+oskvwncBTwD+LOqWjvyzCRJC95QNxu2omHhkCQ9yKxFJMndzDzCbuhuMH/CyLKSJE2EWYtIVXkFliRps4bqzmrPOz+QrmXyzaq6bKRZSZImwjA3G/4Z3WNsnwjsApyV5J2jTkyStPAN0xL5XeC5VfVvAElOBS4H3jPCvCRJE2CY+0T+FXjUwPIO+ARBSRLDtUTuBK5OspbunMhvAt9N8hGAqjphhPlJkhawYYrIF9s05cLRpCJJmjTD3LG+aj4S0da1dOWXZ4xvOPWwec5E0rZsmKuzXpHksiS3Jbkryd1J7pqP5CRJC9sw3VkfAv4TcGUbzVeSJGC4q7NuBK6ygEiSphumJfKnwJokXwfunQpW1QdGlpUkaSIMU0ROAe6hu1fkkaNNR5I0SYYpIk+uqmePPBNJ0sQZ5pzImiQHjzwTSdLEGaaI/BHw1ST/z0t8JUmDhrnZ0OeKSJJmNOzzRHYCljEwEGNVfWNUSUmSJsOcRSTJ64ATgT3ohoA/APg28JKRZiZJWvCGOSdyIvAC4IaqejHwPOCOUSYlSZoMwxSRfxt4INUOVfU94BmjTUuSNAmGKSIbk+wI/AOwNsm5wA1zbZTkzCS3JrlqIHZykpuSXN6mlw+897Yk65N8P8nLBuKHtNj6JCsH4nsluajFP5vEGyElaZ7NWUSq6pVVdUdVnQz8D+AM4Igh9n0WcMgM8Q9W1T5tWgOQZG/gSOBZbZu/SbJdku2AjwKHAnsDR7V1Ad7X9vV04Hbg2CFykiRtRcMMBf+0JDtMLQJLgcfMtV27euu2IfM4HDi7qu6tquuB9cB+bVpfVddV1c+As4HDk4TuxP7n2varGK6wSZK2omG6sz4P3J/k6cDpwJ7Ap7fgmG9IckXr7tqpxXanGy14ysYWmy3+ROCOqrpvWnxGSY5Lsi7Juk2bNm1B6pKkQcMUkQfaH+tXAn9VVW8Bdut5vNOApwH7ADcDf9lzPw9LVZ1eVcuravmSJUvm45CStCgMc7Phz5McBawAfqvFHtHnYFV1y9R8ko8DX2qLN9G1cKbs0WLMEv8xsGOS7VuBG1xfkjRPhmmJHAO8EDilqq5PshfwyT4HSzLYgnklMHXl1mrgyCQ7tP0vA74LXAwsa1diPZLu5Pvq9oCsC4BXte1XAOf2yUmS1N8wY2ddA5wwsHw93ZVRm5XkM8BBwC5JNgInAQcl2QcoYAPwh22fVyc5B7gGuA84vqrub/t5A3AesB1wZlVd3Q7xVuDsJO8BLqO7akySNI+GGjurj6o6aobwrH/oq+oUugdgTY+vAdbMEL+O7uotSdKYDNOdJUnSjGYtIkk+2V5PnL90JEmTZHMtkecneTLwB0l2SrLz4DRfCUqSFq7NnRP5W+B84KnAJXR3q0+pFpckLWKztkSq6iNV9Uy6K6KeWlV7DUwWEEnSUJf4/lGS5wK/3kLfqKorRpuWJGkSDDMA4wnAp4AntelTSf5k1IlJkha+Ye4TeR2wf1X9BCDJ++gej/tXo0xMkrTwDXOfSID7B5bv58En2SVJi9QwLZG/By5K8sW2fAQOMSJJYrgT6x9IciFwYAsdU1WXjTQrSdJEGGrsrKq6FLh0xLlIkiaMY2dJknob2Si+i8nSlV+eMb7h1MPmORNJml+bLSJJtgP+sapePE/5aEwshJL62Gx3Vnsw1ANJfnme8pEkTZBhurPuAa5Mshb4yVSwqk6YfRNJ0mIwTBH5QpskSXqQYe4TWZXk0cBTqur785CTJGlCDDMA428BlwNfbcv7JFk94rwkSRNgmPtETgb2A+4AqKrL8YFUkiSGKyI/r6o7p8UeGEUykqTJMsyJ9auT/BdguyTLgBOAb402LQ2a7R4OSRq3YVoifwI8C7gX+AxwF/DGEeYkSZoQw1yd9VPgHe1hVFVVd48+LUnSJBjm6qwXJLkSuILupsP/k+T5o09NkrTQDXNO5Azgj6vqnwGSHEj3oKrnjDIxSdLCN8w5kfunCghAVX0TuG90KUmSJsWsLZEk+7bZryf5GN1J9QJeA1w4+tQkSQvd5rqz/nLa8kkD8zWCXCRJE2bWIuIzRCRJc5nzxHqSHYGjgaWD6881FHySM4FXALdW1bNbbGfgs21fG4BXV9XtSQJ8GHg58FPgte257iRZAbyz7fY9VbWqxZ8PnAU8GlgDnFhVC6qF5E2CkrZ1w5xYX0P3R/9K4JKBaS5nAYdMi60Ezq+qZcD5bRngUGBZm44DToN/LzonAfvTjd91UpKd2janAa8f2G76sSRJIzbMJb6Pqqr//nB3XFXfSLJ0Wvhw4KA2v4ruBP1bW/wTrSXxnSQ7Jtmtrbu2qm4DaA/GOiTJhcATquo7Lf4J4AjgKw83T0lSf8O0RD6Z5PVJdkuy89TU83i7VtXNbf6HwK5tfnfgxoH1NrbY5uIbZ4hLkubRMC2RnwHvB97BL67KKrZwOPiqqiTzcg4jyXF03WQ85SlPmY9DStKiMExL5E3A06tqaVXt1aa+BeSW1k1Fe721xW8C9hxYb48W21x8jxniM6qq06tqeVUtX7JkSc/UJUnTDVNE1tNdMbU1rAZWtPkVwLkD8aPTOQC4s3V7nQccnGSndkL9YOC89t5dSQ5oV3YdPbAvSdI8GaY76yfA5UkuoBsOHhjqEt/P0J0Y3yXJRrqrrE4FzklyLHAD8Oq2+hq6y3unCtYx7Ri3JXk3cHFb711TJ9mBP+YXl/h+BU+qS9K8G6aI/EObHpaqOmqWt146w7oFHD/Lfs4Ezpwhvg549sPNS5K09QzzPJFV85GIFqbZbpjccOph85yJpIVomDvWr2eGsbK24OS6JGkbMUx31vKB+UcBvwP0vU9EkrQNmfPqrKr68cB0U1V9CLAvQ5I0VHfWvgOLv0TXMhmmBSNJ2sYNUwwGnytyH2303ZFkI0maKMNcneVzRSRJMxqmO2sH4D/z0OeJvGt0aUmSJsEw3VnnAnfSPUPk3jnWlSQtIsMUkT2qygc+SZIeYpgBGL+V5NdGnokkaeIM0xI5EHhtu3P9XiB0w109Z6SZSZIWvGGKyKEjz0KSNJGGucT3hvlIRJI0eYY5JyJJ0owsIpKk3hwDa5GZ7fkgktSHLRFJUm8WEUlSbxYRSVJvFhFJUm8WEUlSbxYRSVJvFhFJUm8WEUlSbxYRSVJvFhFJUm8WEUlSbxYRSVJvFhFJUm8WEUlSbxYRSVJvYykiSTYkuTLJ5UnWtdjOSdYm+UF73anFk+QjSdYnuSLJvgP7WdHW/0GSFeP4LJK0mI3zoVQvrqofDSyvBM6vqlOTrGzLbwUOBZa1aX/gNGD/JDsDJwHLgQIuSbK6qm6fzw+hB5vtoVcbTj1snjORNB8WUnfW4cCqNr8KOGIg/onqfAfYMcluwMuAtVV1Wysca4FD5jlnSVrUxlVECvhakkuSHNdiu1bVzW3+h8CubX534MaBbTe22Gzxh0hyXJJ1SdZt2rRpa30GSVr0xtWddWBV3ZTkScDaJN8bfLOqKkltrYNV1enA6QDLly/favuVpMVuLC2Rqrqpvd4KfBHYD7ildVPRXm9tq98E7Dmw+R4tNltckjRP5r2IJHlsksdPzQMHA1cBq4GpK6xWAOe2+dXA0e0qrQOAO1u313nAwUl2aldyHdxikqR5Mo7urF2BLyaZOv6nq+qrSS4GzklyLHAD8Oq2/hrg5cB64KfAMQBVdVuSdwMXt/XeVVW3zd/HkCTNexGpquuA584Q/zHw0hniBRw/y77OBM7c2jlKkoazkC7xlSRNGIuIJKk3i4gkqbdxDnuiRcThUKRtky0RSVJvFhFJUm92Z6mX2bqnJC0utkQkSb1ZRCRJvVlEJEm9WUQkSb15Yl0LkveVSJPBlogkqTeLiCSpN7uzHgbvjZCkB7OIaKJ4rkRaWOzOkiT1ZhGRJPVmd5a2aZs7j2UXmLTlLCJatDy/Im05u7MkSb3ZEtFYTdJl07ZcpIeyJSJJ6s2WiLSFHm4LxRaNtiUWEWmB2FrFaDabK1IWNvVlEdE2YZLOrUwSi4vm4jkRSVJvtkSkaWzVSMOziEgjshiLkd1fi49FRFrgtlYxWoxFTaNnEZH0sD3cgmQLZds18SfWkxyS5PtJ1idZOe58JGkxmeiWSJLtgI8CvwlsBC5OsrqqrhlvZpKGsTXvddF4THQRAfYD1lfVdQBJzgYOBywi0jZoa53XsRhtPZNeRHYHbhxY3gjsP32lJMcBx7XFe5J8v+fxdgF+1HPbxcLvaDh+T3Mb2XeU941ir2Mxn7+jX5kpOOlFZChVdTpw+pbuJ8m6qlq+FVLaZvkdDcfvaW5+R3NbCN/RpJ9YvwnYc2B5jxaTJM2DSS8iFwPLkuyV5JHAkcDqMeckSYvGRHdnVdV9Sd4AnAdsB5xZVVeP8JBb3CW2CPgdDcfvaW5+R3Mb+3eUqhp3DpKkCTXp3VmSpDGyiEiSerOIDMGhVWaWZM8kFyS5JsnVSU5s8Z2TrE3yg/a607hzHbck2yW5LMmX2vJeSS5qv6nPtgtDFq0kOyb5XJLvJbk2yQv9HT1Ukv/W/q1dleQzSR417t+SRWQOA0OrHArsDRyVZO/xZrVg3Ae8qar2Bg4Ajm/fzUrg/KpaBpzflhe7E4FrB5bfB3ywqp4O3A4cO5asFo4PA1+tql8Fnkv3Xfk7GpBkd+AEYHlVPZvuYqIjGfNvySIyt38fWqWqfgZMDa2y6FXVzVV1aZu/m+4f/u5038+qttoq4IixJLhAJNkDOAz4u7Yc4CXA59oqi/o7SvLLwG8AZwBU1c+q6g78Hc1ke+DRSbYHHgPczJh/SxaRuc00tMruY8plwUqyFHgecBGwa1Xd3N76IbDruPJaID4E/CnwQFt+InBHVd3Xlhf7b2ovYBPw963L7++SPBZ/Rw9SVTcBfwH8C13xuBO4hDH/liwi2mJJHgd8HnhjVd01+F5115Av2uvIk7wCuLWqLhl3LgvY9sC+wGlV9TzgJ0zrulrsvyOAdk7ocLqi+2TgscAhY00Ki8gwHFplM5I8gq6AfKqqvtDCtyTZrb2/G3DruPJbAF4E/HaSDXRdoS+h6//fsXVJgL+pjcDGqrqoLX+Orqj4O3qw/whcX1WbqurnwBfofl9j/S1ZRObm0CqzaH37ZwDXVtUHBt5aDaxo8yuAc+c7t4Wiqt5WVXtU1VK6384/VdXvAhcAr2qrLfbv6IfAjUme0UIvpXucg7+jB/sX4IAkj2n/9qa+p7H+lrxjfQhJXk7Xrz01tMop481oYUhyIPDPwJX8or//7XTnRc4BngLcALy6qm4bS5ILSJKDgDdX1SuSPJWuZbIzcBnwe1V17xjTG6sk+9BdePBI4DrgGLr/yfV3NCDJnwOvobsy8jLgdXTnQMb2W7KISJJ6sztLktSbRUSS1JtFRJLUm0VEktSbRUSS1JtFRItCkntGsM992uXfU8snJ3nzFuzvd9oIthdsnQx757EhyS7jzEGTwyIi9bcP8PK5VnoYjgVeX1Uv3or7lEbKIqJFJ8lbklyc5Ip28xZJlrZWwMfb8xq+luTR7b0XtHUvT/L+9iyHRwLvAl7T4q9pu987yYVJrktywizHPyrJlW0/72uxPwMOBM5I8v5p6++W5BvtOFcl+fUWPy3Jupbvnw+svyHJe9v665Lsm+S8JP83yX9t6xzU9vnldM/K+dskD/l7kOT3kny37etj7dEI0i9UlZPTNj8B97TXg4HTgdD9T9SX6IYhX0p3F/A+bb1z6O78BbgKeGGbPxW4qs2/FvjrgWOcDHwL2AHYBfgx8IhpeTyZbviKJXQDD/4TcER770K6Z0VMz/1NwDva/HbA49v8zgOxC4HntOUNwB+1+Q8CVwCPb8e8pcUPAv4NeGrbfi3wqoHtdwGeCfyvqc8A/A1w9Lj/WzotrMmWiBabg9t0GXAp8KvAsvbe9VV1eZu/BFiaZEe6P9rfbvFPz7H/L1fVvVX1I7oBA6cPX/4C4MLqBtG7D/gUXRHbnIuBY5KcDPxadc9uAXh1kkvbZ3kW3UPTpkyN73YlcFFV3V1Vm4B722cC+G51z8m5H/gMXUto0EuB5wMXJ7m8LT91jly1yGw/9yrSNiXAe6vqYw8Kds9DGRxv6H7g0T32P30fW/xvrKq+keQ36B5sdVaSD9CNWfZm4AVVdXuSs4BHzZDHA9NyemAgp+ljHk1fDrCqqt62pZ9B2y5bIlpszgP+oD0DhSS7J3nSbCtX94S9u5Ps30JHDrx9N1030cPxXeA/JNmlnV84Cvj65jZI8it03VAfpxukcF/gCXTP3bgzya50j29+uPZro1P/Et2gft+c9v75wKumvp90zzz/lR7H0TbMlogWlar6WpJnAt/uRtPmHuD36FoNszkW+HiSB+j+4N/Z4hcAK1tXz3uHPP7NSVa2bUPX/TXX0N0HAW9J8vOW79FVdX2Sy4Dv0T15838Pc/xpLgb+Gnh6y+eL03K9Jsk7ga+1QvNz4Hi6EXUlwFF8pTkleVxV3dPmVwK7VdWJY05riwwOSz/mVDThbIlIczssydvo/r3cQHdVliRsiUiStoAn1iVJvVlEJEm9WUQkSb1ZRCRJvVlEJEm9/X9qhqrc3V9xKAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 텍스트데이터 문장을 담은 리스트 생성\n",
    "total_data_text = list(X_train) + list(X_test)\n",
    "\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "plt.fig=((12,6))\n",
    "plt.hist([len(s) for s in total_data_text], bins=50)\n",
    "plt.xlabel('length of sample')\n",
    "plt.ylabel('number of sample')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-stream",
   "metadata": {},
   "source": [
    "### 3.2 적절한 최대 문장 길이 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "upper-stanford",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad_sequences maxlen :  48\n",
      "전체 문장의 0.9726161017732281%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "# 최대 길이를 (평균 + 3*표준편차)로 지정  \n",
    "max_tokens = np.mean(num_tokens) + 3 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-stuff",
   "metadata": {},
   "source": [
    "### 3.3 패딩 추가\n",
    "RNN은 입력데이터가 순차적으로 처리되어, 가장 마지막 입력이 최종 state값에 가장 영향을 많이 미치게 된다. 그러므로 마지막 입력이 무의미한 padding으로 채워지는 것은 비효율 적이다. 따라서 'pre' padding으로 진행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "funny-vinyl",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145791, 48)\n"
     ]
    }
   ],
   "source": [
    "# padding으로 문장 길이 맞추기\n",
    "X_train = keras.preprocessing.sequence.pad_sequences(X_train,\n",
    "                                       value=word_to_index[\"<PAD>\"],\n",
    "                                       padding='post',\n",
    "                                       maxlen=maxlen)\n",
    "\n",
    "X_test = keras.preprocessing.sequence.pad_sequences(X_test,\n",
    "                                       value=word_to_index[\"<PAD>\"],\n",
    "                                       padding='post',\n",
    "                                       maxlen=maxlen)\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-catering",
   "metadata": {},
   "source": [
    "## 4. 모델구성 및 validation set 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "classical-president",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 16  # 워드 벡터의 차원 수 (변경 가능한 하이퍼파라미터), 단어 하나를 표현하는 임베딩 벡터의 차원 수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrated-layout",
   "metadata": {},
   "source": [
    "### 4.1 CNN\n",
    "\n",
    "- 텍스트 처리를 하기위해 `1-D Convolution Neural Netword(1-D CNN)`를 사용할 수 있다.\n",
    "- `1-D CNN`은 문장 체페를 한꺼번에 한 방향으로 길이 n짜리 필터로 스캐닝 하면서 n단어 이내에서 발견되는 특징을 추출하고, 그것으로 문장을 분류하는 방식으로 사용된다.\n",
    "- CNN 계열은 RNN 계열보다 병렬처리가 효율적이기 때문에 학습 속도도 훨씬 빠르게 진행된다.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "blind-institution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_14 (Embedding)     (None, None, 200)         2000000   \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, None, 16)          9616      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, None, 16)          784       \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_5 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,010,545\n",
      "Trainable params: 2,010,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = keras.Sequential()\n",
    "model1.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model1.add(keras.layers.Conv1D(16, 3, activation='relu'))\n",
    "model1.add(keras.layers.MaxPooling1D(5))\n",
    "model1.add(keras.layers.Conv1D(16, 3, activation='relu'))\n",
    "model1.add(keras.layers.GlobalMaxPooling1D())\n",
    "model1.add(keras.layers.Dense(8, activation='relu'))\n",
    "model1.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "russian-progressive",
   "metadata": {},
   "source": [
    "### 4.2 LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominant-administrator",
   "metadata": {},
   "source": [
    "RNN은 시간의 흐름에 따라 새롭게 들어오는 입력에 따라 변하는 현재 상태를 묘사하는 state machine으로 설계되었다.LSTM은 RNN의 문제를 해결하기 위해 나온 모델로 주로 사용되는 모델이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passive-distance",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.Sequential()\n",
    "model2.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model2.add(keras.layers.LSTM(8))# LSTM state 벡터의 차원수 (변경가능)\n",
    "# model2.add(keras.layers.Dense(8, activation='relu'))\n",
    "model2.add(keras.layers.Dense(1, activation='sigmoid')) # 최종 출력은 긍정/부정을 나타내는 1dim\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banned-title",
   "metadata": {},
   "source": [
    "### 4.3 GlobalMaxPooling1D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-knock",
   "metadata": {},
   "source": [
    "아주 간단하게는 GlobalMaxPooling1D() 레이어 하나만 사용할 수 도 있다. 이 방식은 전체 문장 중에서 단 하나의 가장 중요한 단어만 피처로 추출하여 그것으로 문장의 긍/부정을 평가하는 방식이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "instructional-compound",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, None, 200)         2000000   \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 8)                 1608      \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,001,617\n",
      "Trainable params: 2,001,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = keras.Sequential()\n",
    "model3.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model3.add(keras.layers.GlobalMaxPooling1D())\n",
    "model3.add(keras.layers.Dense(8, activation='relu'))\n",
    "model3.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "synthetic-eligibility",
   "metadata": {},
   "source": [
    "## 5. 모델 훈련 개시\n",
    "1. train과 validation set으로 분리하고\n",
    "2. 모델을 훈련시킨다,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "shaped-snapshot",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(115791, 48)\n",
      "(115791,)\n"
     ]
    }
   ],
   "source": [
    "# train, validation set 분리\n",
    "\n",
    "# validation set 30000건 분리\n",
    "x_val = X_train[:30000]   \n",
    "y_val = y_train[:30000]\n",
    "\n",
    "# validation set을 제외한 나머지 11만여 건\n",
    "partial_x_train = X_train[30000:]  \n",
    "partial_y_train = y_train[30000:]\n",
    "\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plain-reggae",
   "metadata": {},
   "source": [
    "### 5.1 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "organizational-bundle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1930/1930 [==============================] - 22s 11ms/step - loss: 0.0173 - accuracy: 0.9927 - val_loss: 1.6118 - val_accuracy: 0.8162\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 2/20\n",
      "1930/1930 [==============================] - 21s 11ms/step - loss: 0.0152 - accuracy: 0.9935 - val_loss: 1.6309 - val_accuracy: 0.8165\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 3/20\n",
      "1930/1930 [==============================] - 21s 11ms/step - loss: 0.0131 - accuracy: 0.9940 - val_loss: 1.5658 - val_accuracy: 0.8161\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 4/20\n",
      "1930/1930 [==============================] - 21s 11ms/step - loss: 0.0141 - accuracy: 0.9938 - val_loss: 1.5122 - val_accuracy: 0.8190\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 5/20\n",
      "1930/1930 [==============================] - 21s 11ms/step - loss: 0.0146 - accuracy: 0.9936 - val_loss: 1.5961 - val_accuracy: 0.8182\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 6/20\n",
      "1930/1930 [==============================] - 21s 11ms/step - loss: 0.0129 - accuracy: 0.9942 - val_loss: 1.6840 - val_accuracy: 0.8160\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 7/20\n",
      "1930/1930 [==============================] - 21s 11ms/step - loss: 0.0139 - accuracy: 0.9940 - val_loss: 1.6474 - val_accuracy: 0.8207\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 8/20\n",
      "1930/1930 [==============================] - 21s 11ms/step - loss: 0.0127 - accuracy: 0.9942 - val_loss: 1.6184 - val_accuracy: 0.8169\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 00008: early stopping\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "model1.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model1.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=[es, mc], \n",
    "                    batch_size=60,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "internal-shuttle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1532/1532 - 3s - loss: 1.7517 - accuracy: 0.8093\n",
      "[1.7516815662384033, 0.8092662692070007]\n"
     ]
    }
   ],
   "source": [
    "# 학습이 끝난 모델을 테스트셋으로 평가\n",
    "results1 = model1.evaluate(X_test,  y_test, verbose=2)\n",
    "print(results1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-services",
   "metadata": {},
   "source": [
    "### 5.2 LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-speed",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history2 = model2.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=[es, mc], \n",
    "                    batch_size=60,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-exhibit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습이 끝난 모델을 테스트셋으로 평가\n",
    "results2 = model2.evaluate(X_test,  y_test, verbose=2)\n",
    "print(results2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-pocket",
   "metadata": {},
   "source": [
    "### 5.3  GlobalMaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "traditional-sigma",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-209-c019b0c6184a>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-209-c019b0c6184a>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    callbacks=[es, mc],\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "model3.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history3 = model3.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs\n",
    "                    callbacks=[es, mc], \n",
    "                    batch_size=60,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "white-ivory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습이 끝난 모델을 테스트셋으로 평가\n",
    "results3 = model3.evaluate(X_test,  y_test, verbose=2)\n",
    "print(results3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handy-kingston",
   "metadata": {},
   "source": [
    "__모델들의 Loss, Accuracy 결과 요약__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "black-characterization",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = [l for l, a in [results1, results2, results3]]\n",
    "accuracy = [a for l, a in [results1, results2, results3]]\n",
    "df_score = pd.DataFrame({'Loss':loss, 'Accuracy':accuracy}, index=['CNN','LSTM','GMP'])\n",
    "df_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaningful-poetry",
   "metadata": {},
   "source": [
    "LSTM > GMP > CNN 순으로 정확도가 높다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separate-suggestion",
   "metadata": {},
   "source": [
    "## 6. Loss, Accuracy 그래프 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capital-hurricane",
   "metadata": {},
   "source": [
    "### 6.1 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revolutionary-saudi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화할 항목 세팅\n",
    "history_dict1 = history.history\n",
    "acc = history_dict1['accuracy']\n",
    "val_acc = history_dict1['val_accuracy']\n",
    "loss = history_dict1['loss']\n",
    "val_loss = history_dict1['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# Accuracy 그래프\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, acc, label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "# Loss 그래프\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, loss, label='Training Loss')\n",
    "plt.plot(epochs, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-teaching",
   "metadata": {},
   "source": [
    "### 6.2 LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-fundamentals",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화할 항목 세팅\n",
    "history_dict2 = history2.history\n",
    "acc = history_dict2['acc']\n",
    "val_acc = history_dict2['val_acc']\n",
    "loss = history_dict2['loss']\n",
    "val_loss = history_dict2['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# Accuracy 그래프\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, acc, label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "# Loss 그래프\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, loss, label='Training Loss')\n",
    "plt.plot(epochs, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "careful-thong",
   "metadata": {},
   "source": [
    "### 6.3 GlobalMaxPooling1D¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-exception",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화할 항목 세팅\n",
    "history_dict3 = history3.history\n",
    "acc = history_dict3['accuracy']\n",
    "val_acc = history_dict3['val_accuracy']\n",
    "loss = history_dict3['loss']\n",
    "val_loss = history_dict3['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# Accuracy 그래프\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, acc, label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "# Loss 그래프\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, loss, label='Training Loss')\n",
    "plt.plot(epochs, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verified-hollywood",
   "metadata": {},
   "source": [
    "## 7. 학습된 Embedding 레이어 분석\n",
    "gensim을 활용하여 자체학습한 임베딩을 분석한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "dying-disease",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gensim\n",
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "from tensorflow.keras.initializers import Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "persistent-latitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word2vec_file(model,word2vec_file_path):\n",
    "    # 임베딩 레이어 차원 확인\n",
    "    embedding_layer = model.layers[0]\n",
    "    weights = embedding_layer.get_weights()[0]\n",
    "\n",
    "    # 학습한 Embedding 파라미터를 파일에 써서 저장합니다. \n",
    "    f = open(word2vec_file_path, 'w')\n",
    "    f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다.\n",
    "\n",
    "    # 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록합니다. \n",
    "    vectors = model.get_weights()[0]\n",
    "    for i in range(4,vocab_size):\n",
    "        f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "    f.close()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-sustainability",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_file_path1 = os.getenv('HOME')+f'/aiffel/sentiment_classification/data/word2vec_cnn.txt'\n",
    "word2vec_file_path2 = os.getenv('HOME')+f'/aiffel/sentiment_classification/data/word2vec_lstm.txt'\n",
    "word2vec_file_path3 = os.getenv('HOME')+f'/aiffel/sentiment_classification/data/word2vec_fgm.txt'\n",
    "\n",
    "get_word2vec_file(model1,word2vec_file_path1)\n",
    "get_word2vec_file(model2,word2vec_file_path2)\n",
    "get_word2vec_file(model3,word2vec_file_path3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operational-eating",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에 남긴 임베딩 파라미터를 읽어서 word vector로 활용\n",
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors1 = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path1, binary=False)\n",
    "vector1 = word_vectors1['추천']\n",
    "\n",
    "word_vectors2 = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path2, binary=False)\n",
    "vector2 = word_vectors2['추천']\n",
    "\n",
    "word_vectors3 = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path3, binary=False)\n",
    "vector3 = word_vectors3['추천']\n",
    "\n",
    "print('[CNN]','='*70)\n",
    "print(vector1)\n",
    "print('[LSTM]','='*70)\n",
    "print(vector2)\n",
    "print('[GlobalMaxPooling]','='*60)\n",
    "print(vector3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-letter",
   "metadata": {},
   "source": [
    "워드 벡터가 의미벡터 공간상에 유의미하게 학습되었는지 확인하기위해 유사도를 확인해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-worthy",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[CNN]','='*70)\n",
    "print(word_vectors1.similar_by_word(\"흥미\"))\n",
    "print('[LSTM]','='*70)\n",
    "print(word_vectors2.similar_by_word(\"흥미\"))\n",
    "print('[GlobalMaxPooling]','='*60)\n",
    "print(word_vectors3.similar_by_word(\"흥미\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executive-strengthening",
   "metadata": {},
   "source": [
    "LSTM으로 학습한 결과는 '추천'이라는 단어와 꽤 관련있는 단어들을 결과물로 내어줬지만, 다른 두 모델은 그리 관련된 단어들을 보여주지 않는다.\n",
    "<br>=> 학습을 반복해보니 전체적으로 연관성이 떨어진다.\n",
    "사전학습된 워드 임베딩 모델을 활용하여 벡터를 정교하게 학습시켜본다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historical-tournament",
   "metadata": {},
   "source": [
    "## 8. 한국어 Word2Vec 임베딩 활용하여 성능개선\n",
    "네이버 영화리뷰 데이터 감성분석 정확도를 85% 이상 달성하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-brother",
   "metadata": {},
   "source": [
    "한국어 Word2Vec 임베딩 모델\n",
    "- [Pre-trained word vectors of 30+ languages](https://github.com/Kyubyong/wordvectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "thorough-subscriber",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용하기 위해서 필요한 spec에 따라 라이브러리 버전 조정\n",
    "# pip install --upgrade gensim==3.8.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "disturbed-witness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "word2vec_path = os.getenv('HOME')+'/aiffel/sentiment_classification/data/ko_tar/ko.vec'\n",
    "word2vec = KeyedVectors.load_word2vec_format(word2vec_path)\n",
    "vector = word2vec['흥미']\n",
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "manual-blame",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('호기심', 0.6089121103286743),\n",
       " ('관심', 0.5792118310928345),\n",
       " ('취미', 0.5322762131690979),\n",
       " ('상상력', 0.5259734392166138),\n",
       " ('재미있', 0.524858832359314),\n",
       " ('매력', 0.5103601813316345),\n",
       " ('재미', 0.502285897731781),\n",
       " ('관심사', 0.48539993166923523),\n",
       " ('실감', 0.47706544399261475),\n",
       " ('해박', 0.47447964549064636)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.similar_by_word(\"흥미\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-graph",
   "metadata": {},
   "source": [
    "학습이 잘되어 유사한 단어들을 결과물로 준다. 이전 스텝에서 학습했던 모델의 임베딩 레이어를 Word2Vec의 것으로 교체하여 다시 학습시켜본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "distributed-plasma",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 200  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드 벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cardiac-robin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 48, 200)           2000000   \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 128)               168448    \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 8)                 1032      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,169,489\n",
      "Trainable params: 2,169,489\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 200  # 워드 벡터의 차원 수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "# 모델 구성\n",
    "model_wv = keras.Sequential()\n",
    "model_wv.add(keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "model_wv.add(keras.layers.LSTM(128))\n",
    "model_wv.add(keras.layers.Dense(8, activation='relu'))\n",
    "model_wv.add(keras.layers.Dense(1, activation='sigmoid')) # 최종 출력은 긍정/부정을 나타내는 1dim\n",
    "\n",
    "model_wv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "competent-shelter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "227/227 [==============================] - 13s 49ms/step - loss: 0.6929 - accuracy: 0.5002 - val_loss: 0.6035 - val_accuracy: 0.7312\n",
      "Epoch 2/5\n",
      "227/227 [==============================] - 11s 48ms/step - loss: 0.4640 - accuracy: 0.7878 - val_loss: 0.3531 - val_accuracy: 0.8452\n",
      "Epoch 3/5\n",
      "227/227 [==============================] - 11s 48ms/step - loss: 0.3231 - accuracy: 0.8611 - val_loss: 0.3285 - val_accuracy: 0.8561\n",
      "Epoch 4/5\n",
      "227/227 [==============================] - 11s 48ms/step - loss: 0.2825 - accuracy: 0.8827 - val_loss: 0.3366 - val_accuracy: 0.8559\n",
      "Epoch 5/5\n",
      "227/227 [==============================] - 11s 48ms/step - loss: 0.2544 - accuracy: 0.8948 - val_loss: 0.3288 - val_accuracy: 0.8570\n"
     ]
    }
   ],
   "source": [
    "# 학습 진행\n",
    "model_wv.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=5# 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history_wv = model_wv.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "proud-packing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1532/1532 - 6s - loss: 0.3370 - accuracy: 0.8528\n",
      "[0.33699408173561096, 0.8528013229370117]\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋을 통한 모델 평가\n",
    "results = model_wv.evaluate(X_test,  y_test, verbose=2)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "second-fleece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 시각화할 항목 세팅\n",
    "history_dict = history_wv.history\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# Accuracy 그래프\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, acc, label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "# Loss 그래프\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, loss, label='Training Loss')\n",
    "plt.plot(epochs, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-amber",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 진행\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "model_wv2.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "# model2.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history_wv2 = model_wv2.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=[es, mc], \n",
    "                    batch_size=60,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-cruise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화할 항목 세팅\n",
    "history_dict = history_wv.history\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# Accuracy 그래프\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, acc, label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "# Loss 그래프\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, loss, label='Training Loss')\n",
    "plt.plot(epochs, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-conviction",
   "metadata": {},
   "source": [
    "## 9. 리뷰 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chicken-order",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_predict(new_sentence):\n",
    "  new_sentence = tokenizer.morphs(new_sentence, stem=True) # 토큰화\n",
    "  new_sentence = [word for word in new_sentence if not word in stopwords] # 불용어 제거\n",
    "  encoded = tokenizer.texts_to_sequences([new_sentence]) # 정수 인코딩\n",
    "  pad_new = pad_sequences(encoded, maxlen = max_len) # 패딩\n",
    "  score = float(loaded_model.predict(pad_new)) # 예측\n",
    "  if(score > 0.5):\n",
    "    print(\"{:.2f}% 확률로 긍정 리뷰입니다.\\n\".format(score * 100))\n",
    "  else:\n",
    "    print(\"{:.2f}% 확률로 부정 리뷰입니다.\\n\".format((1 - score) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-pixel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confused-stroke",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-reminder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-nature",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-dublin",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "republican-basin",
   "metadata": {},
   "source": [
    "## 프로젝트 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threatened-catalog",
   "metadata": {},
   "source": [
    "- 1-D CNN, LSTM, GlobalMaxPolling으로 모델을 설계하였다. 정확도는 81-83% 수준이었고 LSTM > GMP > CNN 순으로 정확도가 높았다.\n",
    "- gensim의 `similar_by_word`로 자체학습한 임베딩과 사전학습 임베딩 결과를 비교하였다. '흥미'라는 단어로 결과를 비교해봤는데, 자체 학습한 모델들은 '흥미'와는 상관없어 보이는 단어들을 결과로 내어주는 경우가 많았다. fastText는 호기심, 관심, 취미, 상상력, 재미있, 매력등 '흥미'와 유사도가 높은 단어들을 결과로 보여주어 사전학습이 잘 이루어진 것을 확인할 수 있었다.\n",
    "- fastText 파일안에는 모델과 벡터 두가지를 제공하는데 모델파일은 인코딩에러로 열리지 않아 벡터를 이용해서 진행하였다. 이번 프로젝트에서는 학습된 벡터를 가지고 결과를 비교해보는 것이여서 벡터로도 충분하였지만 추가적인 학습을 하려면 모델을 이용해서 진행할 수 있다고 한다. \n",
    "- 사전 모델이 결과로 내어준 유사 단어 결과를 보고 모델 성능이 크게 향상될거라 기대했지만 결과는 생각보다 크게 향상하지는 않았다. 그래도 목표하던 85%이상은 달성하였다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
