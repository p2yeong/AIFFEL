{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cheap-investor",
   "metadata": {},
   "source": [
    "# 텍스트 요약 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matched-papua",
   "metadata": {},
   "source": [
    "## 학습 목표\n",
    "- Extractive/Abstractive summarization 이해하기\n",
    "- 단어장 크기를 줄이는 다양한 text normalization 적용해보기\n",
    "- seq2seq의 성능을 Up시키는 Attention Mechanism 적용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial-athens",
   "metadata": {},
   "source": [
    "## 텍스트 요약(Text Summarization)이란?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-passion",
   "metadata": {},
   "source": [
    "- Document 원문을 핵심 주제만으로 구성된 짧은 Summary 문장들로 변화하는 것을 말한다.\n",
    "-  예)뉴스 기사로 뉴스 제목 생성\n",
    "- 요약 전후에 정보 손실 발생이 최소화 되어야 한다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-movement",
   "metadata": {},
   "source": [
    "### 추출적 요약(Extractive Summarization)\n",
    "- 원문에서 __문장들을 추출__해서 요약하는 방식\n",
    "- 예)10개의 문장으로 구성된 텍스트에서 핵심적인 문장 3개를 꺼내온다\n",
    "- Text Classification 문제로 볼 수 있다\n",
    "- 문장들 간의 호응이 자연스럽지 않을 수 있다\n",
    "- 주로 ML인 텍스트 랭크(TextRank) 같은 알고리즘을 사용한다\n",
    "- 사례)네이버 뉴스 서비스 요약봇\n",
    "\n",
    "![요약봇](https://media.vlpt.us/images/dev_halo/post/fc1bf96f-0877-4db1-a4ee-a4a67f3e9c6c/20171128000144_0640.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-registration",
   "metadata": {},
   "source": [
    "### 추상적 요약(Abxtractive Summarization)\n",
    "- 원문에서 내용이 요약된 __새로운 문장을 생성__하는 방식\n",
    "- Natural Language Generation의 영역"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developing-overhead",
   "metadata": {},
   "source": [
    "### Seq2seq\n",
    "\n",
    "- 두 개의 RNN 아키텍처를 사용하여 입력 시퀀스로 부터 출력 시퀀스를 생성해내는 모델\n",
    "- 원문을 encoder(1st RNN)으로 입력하면 하나의 고정된 벡터로 변환(context vector)\n",
    "- decoder(2nd RNN)은 context vector을 입력으로 받아 한 단어씩 생성해내서 요약 문장을 완성한다.\n",
    "\n",
    "- encoder, decoder로 __LSTM__을 사용 → time step의 셀에 hidden state와 cell state가 함께 전달(context vector에도 hidden state와 cell state 모두 존재)\n",
    "- 데이터의 예측 대상 시퀀스의 앞, 뒤에는 __시작 토큰과 종료 토큰__을 넣어주는 전처리를 해주어 어디서 멈춰야 하는지를 알려줄 필요가 있다.\n",
    "- __Attention Mechanism__은 encoder의 모든 step의 hidden state의 정보가 context vector에 전부 반영되도록 하는 것\n",
    "- decoder의 현재 스텝에 따라 동적으로 달라지는 encoder의 context vector를 사용해서 현재의 예측에 활용하면, decoder가 좀 더 정확한 예측을 할 수 있게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-causing",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "random-antarctica",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /aiffel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normal-welsh",
   "metadata": {},
   "source": [
    "## 데이터 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-attention",
   "metadata": {},
   "source": [
    "[아마존 리뷰 데이터셋](https://www.kaggle.com/bittlingmayer/amazonreviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "nutritional-digit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 100000\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(os.getenv(\"HOME\")+\"/aiffel/news_summarization/data/Reviews.csv\", nrows=100000)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "controversial-script",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extraordinary-powell",
   "metadata": {},
   "source": [
    "학습에 사용될 Summary, Text 컬럼만 분리해 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "loving-escape",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16957</th>\n",
       "      <td>The plant was healthy and looked just like the...</td>\n",
       "      <td>Carnivorous pitcher plant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1891</th>\n",
       "      <td>Got these at a fraction of the price that they...</td>\n",
       "      <td>Pop Chips...Yummy!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31422</th>\n",
       "      <td>I use Spike on popcorn, veggies, meats, soups,...</td>\n",
       "      <td>Spike can be used on so many things, it's amaz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81875</th>\n",
       "      <td>I came across this PetSafe Lickety Stik and de...</td>\n",
       "      <td>Fantastic Product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96544</th>\n",
       "      <td>Having always been partial to Barilla sauces, ...</td>\n",
       "      <td>Nice meal!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39747</th>\n",
       "      <td>Bought a pack of these since I saw them on sal...</td>\n",
       "      <td>My cat loves it.. I don't know if I do.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47831</th>\n",
       "      <td>This is the best vanilla extract I have ever t...</td>\n",
       "      <td>Excellent Vanilla Extract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78693</th>\n",
       "      <td>Package arrived DOUBLE boxed, wrapped, and the...</td>\n",
       "      <td>Amazing Service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67383</th>\n",
       "      <td>MMMmmm.. Tasty!!  Just wish these pumpkin popt...</td>\n",
       "      <td>Treat yourself to a slice of heaven:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58312</th>\n",
       "      <td>Very smooth and mild, no \"off\" tastes - but un...</td>\n",
       "      <td>Mild to the point of being Bland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2963</th>\n",
       "      <td>I received this box with great anticipation si...</td>\n",
       "      <td>Awful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34604</th>\n",
       "      <td>Fell in love with these chips years ago when I...</td>\n",
       "      <td>happy death rain fan.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56548</th>\n",
       "      <td>These are hands-down the absolute best Salt &amp; ...</td>\n",
       "      <td>The Supreme Salt &amp; Vinegar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69735</th>\n",
       "      <td>Of all the brands of Earl Grey, Stash is my fa...</td>\n",
       "      <td>My Favorite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7988</th>\n",
       "      <td>Behind the 12 packets of Via instant coffee, S...</td>\n",
       "      <td>In a pinch, Via is a portable and affordable c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  \\\n",
       "16957  The plant was healthy and looked just like the...   \n",
       "1891   Got these at a fraction of the price that they...   \n",
       "31422  I use Spike on popcorn, veggies, meats, soups,...   \n",
       "81875  I came across this PetSafe Lickety Stik and de...   \n",
       "96544  Having always been partial to Barilla sauces, ...   \n",
       "39747  Bought a pack of these since I saw them on sal...   \n",
       "47831  This is the best vanilla extract I have ever t...   \n",
       "78693  Package arrived DOUBLE boxed, wrapped, and the...   \n",
       "67383  MMMmmm.. Tasty!!  Just wish these pumpkin popt...   \n",
       "58312  Very smooth and mild, no \"off\" tastes - but un...   \n",
       "2963   I received this box with great anticipation si...   \n",
       "34604  Fell in love with these chips years ago when I...   \n",
       "56548  These are hands-down the absolute best Salt & ...   \n",
       "69735  Of all the brands of Earl Grey, Stash is my fa...   \n",
       "7988   Behind the 12 packets of Via instant coffee, S...   \n",
       "\n",
       "                                                 Summary  \n",
       "16957                          Carnivorous pitcher plant  \n",
       "1891                                  Pop Chips...Yummy!  \n",
       "31422  Spike can be used on so many things, it's amaz...  \n",
       "81875                                  Fantastic Product  \n",
       "96544                                         Nice meal!  \n",
       "39747            My cat loves it.. I don't know if I do.  \n",
       "47831                          Excellent Vanilla Extract  \n",
       "78693                                    Amazing Service  \n",
       "67383              Treat yourself to a slice of heaven:)  \n",
       "58312                   Mild to the point of being Bland  \n",
       "2963                                               Awful  \n",
       "34604                              happy death rain fan.  \n",
       "56548                         The Supreme Salt & Vinegar  \n",
       "69735                                        My Favorite  \n",
       "7988   In a pinch, Via is a portable and affordable c...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[['Text','Summary']]\n",
    "data.head()\n",
    "\n",
    "#랜덤한 15개 샘플 출력\n",
    "data.sample(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wired-thriller",
   "metadata": {},
   "source": [
    "Text 열의 내용을 요약한 게 Summay 내용이다. Text 시퀀스를 입력받으면, Summary 시퀀스를 예측하도록 인공 신경망을 훈련시킨다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-vision",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increasing-utility",
   "metadata": {},
   "source": [
    "### 중복 샘플과 NULL 값이 존재하는 샘플 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fewer-charter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 열에서 중복을 배제한 유일한 샘플의 수 : 88426\n",
      "Summary 열에서 중복을 배제한 유일한 샘플의 수 : 72348\n"
     ]
    }
   ],
   "source": [
    "# 중복 샘플 유무 확인\n",
    "print('Text 열에서 중복을 배제한 유일한 샘플의 수 :', data['Text'].nunique())\n",
    "print('Summary 열에서 중복을 배제한 유일한 샘플의 수 :', data['Summary'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "light-europe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 88426\n"
     ]
    }
   ],
   "source": [
    "# 중복 샘플 제거\n",
    "# inplace=True 를 설정하면 DataFrame 타입 값을 return 하지 않고 data 내부를 직접적으로 바꿉니다\n",
    "data.drop_duplicates(subset = ['Text'], inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "institutional-morning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text       0\n",
      "Summary    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 데이터의 NULL값 확인\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aboriginal-threat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 88425\n"
     ]
    }
   ],
   "source": [
    "## NULL값 제거\n",
    "data.dropna(axis=0, inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "terminal-header",
   "metadata": {},
   "source": [
    "### 텍스트 정규화와 불용어 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-router",
   "metadata": {},
   "source": [
    "__텍스트 정규화(Text normalization)__ : 같은 의미인데 다른 표현으로 쓰여 다른 단어로 간주되는 경우\n",
    "학습전에 미리 같은 표현으로 통일 시켜주어 연산량을 줄인다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "later-appeal",
   "metadata": {},
   "source": [
    "[정규화 사전 출처](https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "consolidated-excess",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화 사전의 수:  120\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 정규화를 위한 사전\n",
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "print(\"정규화 사전의 수: \", len(contractions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-software",
   "metadata": {},
   "source": [
    "__불용어__: 텍스트에 자주 등장하지만 자연어 처리를 할 때 실질적으로 도움이 되지 않는 단어들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "entitled-terrain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 : 179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# LTK에서 제공하는 불용어 리스트를 참조\n",
    "print('불용어 개수 :', len(stopwords.words('english') ))\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "obvious-occupation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 함수\n",
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\", sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "    # 불용어 제거 (Text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    # 불용어 미제거 (Summary)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fifty-birthday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "everything bought great infact ordered twice third ordered wasfor mother father\n",
      "great way to start the day\n"
     ]
    }
   ],
   "source": [
    "# 전처리 함수 결과 확인\n",
    "temp_text = 'Everything I bought was great, infact I ordered twice and the third ordered was<br />for my mother and father.'\n",
    "temp_summary = 'Great way to start (or finish) the day!!!'\n",
    "\n",
    "print(preprocess_sentence(temp_text))\n",
    "print(preprocess_sentence(temp_summary, False))  # 불용어를 제거하지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "rocky-eight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257.8480975627899  seconds\n",
      "['bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better'\n",
      " 'product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo'\n",
      " 'confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch'\n",
      " ...\n",
      " 'favorite brand korean ramen spicy used eating spicy food make sure use spice pack add egg soup makes great snack'\n",
      " 'like noodles although say spicy somewhat understatement one else family tolerates spicy well seeing looking forward extra little something palate disappointed completely honest usually drain liquid almost much'\n",
      " 'love noodle twice week amazing thing feel well cold hot bowl noodle cure upset stomach headache running nose may work definitely try']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.amazon.com/gp/product/b007i7yygy/ref=cm_cr_rev_prod_title\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.141042232513428  seconds\n",
      "['good quality dog food' 'not as advertised' 'delight says it all' ...\n",
      " 'great ramen' 'spicy'\n",
      " 'this spicy noodle cures my cold upset stomach and headache every time']\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터 전체에 대해서 전처리를 수행\n",
    "\n",
    "import multiprocessing as mp   # 멀티 프로세싱으로 전처리 속도를 획기적으로 줄여봅시다\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "import time\n",
    "from functools import partial  # map을 할 때 함수에 여러 인자를 넣어줄 수 있도록 합니다\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# num_cores 만큼 쪼개진 데이터를 전처리하여 반환합니다\n",
    "def appendTexts(sentences, remove_stopwords):\n",
    "  texts = []\n",
    "  for s in sentences:\n",
    "    texts += preprocess_sentence(s, remove_stopwords),\n",
    "  return texts\n",
    "\n",
    "def preprocess_data(data, remove_stopwords=True):\n",
    "  start_time = time.time()\n",
    "  num_cores = mp.cpu_count()  # 컴퓨터의 코어 수를 구합니다\n",
    "\n",
    "  text_data_split = np.array_split(data, num_cores)  # 코어 수만큼 데이터를 배분하여 병렬적으로 처리할 수 있게 합니다\n",
    "  pool = Pool(num_cores)\n",
    "\n",
    "  processed_data = np.concatenate(pool.map(partial(appendTexts, remove_stopwords=remove_stopwords), text_data_split))  # 각자 작업한 데이터를 하나로 합쳐줍니다\n",
    "  pool.close()\n",
    "  pool.join()\n",
    "  print(time.time() - start_time, \" seconds\")\n",
    "  return processed_data\n",
    "\n",
    "clean_text = preprocess_data(data['Text'])\n",
    "print(clean_text)\n",
    "\n",
    "clean_summary = preprocess_data(data['Summary'], remove_stopwords=False) # 불용어를 제거를 하지 않습니다.\n",
    "print(clean_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stunning-acrobat",
   "metadata": {},
   "source": [
    "텍스트 정제 과정을 거친 후에는 빈 샘플이 생겼는지 확인해보는 게 좋다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "intensive-security",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Text'] = clean_text\n",
    "data['Summary'] = clean_summary\n",
    "\n",
    "# 빈 값을 Null 값으로 변환\n",
    "data.replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "mobile-papua",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text        0\n",
       "Summary    70\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "angry-resident",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 88355\n"
     ]
    }
   ],
   "source": [
    "# 정제과정에서 생긴 Null값 삭제\n",
    "data.dropna(axis=0, inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "double-indie",
   "metadata": {},
   "source": [
    "## 훈련 데이터와 테스트 데이터 나누기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desirable-dressing",
   "metadata": {},
   "source": [
    "### 샘플의 최대 길이 정하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-queens",
   "metadata": {},
   "source": [
    "Text와 Summary의 최소, 최대, 평균 길이를 구하고 또한 길이 분포를 시각화해본다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adaptive-tribune",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 2\n",
      "텍스트의 최대 길이 : 1235\n",
      "텍스트의 평균 길이 : 38.792428272310566\n",
      "요약의 최소 길이 : 1\n",
      "요약의 최대 길이 : 28\n",
      "요약의 평균 길이 : 4.010729443721352\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 길이 분포 출력\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_len = [len(s.split()) for s in data['Text']]\n",
    "summary_len = [len(s.split()) for s in data['Summary']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('요약의 최소 길이 : {}'.format(np.min(summary_len)))\n",
    "print('요약의 최대 길이 : {}'.format(np.max(summary_len)))\n",
    "print('요약의 평균 길이 : {}'.format(np.mean(summary_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(summary_len)\n",
    "plt.title('Summary')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('Text')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('Summary')\n",
    "plt.hist(summary_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Text')\n",
    "plt.hist(text_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "arabic-lebanon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ext의 최대 길이와 Summary의 적절한 최대 길이를 임의로 정한다.\n",
    "text_max_len = 50\n",
    "summary_max_len = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "unnecessary-boxing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 길이를 선택했을 때, 얼만큼의 샘플을 포함할 수 있는지\n",
    "def below_threshold_len(max_len, nested_list):\n",
    "  cnt = 0\n",
    "  for s in nested_list:\n",
    "    if(len(s.split()) <= max_len):\n",
    "        cnt = cnt + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "american-philip",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 50 이하인 샘플의 비율: 0.7745119121724859\n",
      "전체 샘플 중 길이가 8 이하인 샘플의 비율: 0.9424593967517402\n"
     ]
    }
   ],
   "source": [
    "below_threshold_len(text_max_len, data['Text'])\n",
    "below_threshold_len(summary_max_len,  data['Summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "representative-southeast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 65818\n"
     ]
    }
   ],
   "source": [
    "# 정해진 길이보다 길면 제외한다.\n",
    "data = data[data['Text'].apply(lambda x: len(x.split()) <= text_max_len)]\n",
    "data = data[data['Summary'].apply(lambda x: len(x.split()) <= summary_max_len)]\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accompanied-warrant",
   "metadata": {},
   "source": [
    "### 시작 토큰과 종료 토큰 추가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "muslim-eight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bought several vitality canned dog food produc...</td>\n",
       "      <td>good quality dog food</td>\n",
       "      <td>sostoken good quality dog food</td>\n",
       "      <td>good quality dog food eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>product arrived labeled jumbo salted peanuts p...</td>\n",
       "      <td>not as advertised</td>\n",
       "      <td>sostoken not as advertised</td>\n",
       "      <td>not as advertised eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>confection around centuries light pillowy citr...</td>\n",
       "      <td>delight says it all</td>\n",
       "      <td>sostoken delight says it all</td>\n",
       "      <td>delight says it all eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>looking secret ingredient robitussin believe f...</td>\n",
       "      <td>cough medicine</td>\n",
       "      <td>sostoken cough medicine</td>\n",
       "      <td>cough medicine eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great taffy great price wide assortment yummy ...</td>\n",
       "      <td>great taffy</td>\n",
       "      <td>sostoken great taffy</td>\n",
       "      <td>great taffy eostoken</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text                Summary  \\\n",
       "0  bought several vitality canned dog food produc...  good quality dog food   \n",
       "1  product arrived labeled jumbo salted peanuts p...      not as advertised   \n",
       "2  confection around centuries light pillowy citr...    delight says it all   \n",
       "3  looking secret ingredient robitussin believe f...         cough medicine   \n",
       "4  great taffy great price wide assortment yummy ...            great taffy   \n",
       "\n",
       "                    decoder_input                  decoder_target  \n",
       "0  sostoken good quality dog food  good quality dog food eostoken  \n",
       "1      sostoken not as advertised      not as advertised eostoken  \n",
       "2    sostoken delight says it all    delight says it all eostoken  \n",
       "3         sostoken cough medicine         cough medicine eostoken  \n",
       "4            sostoken great taffy            great taffy eostoken  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 요약 데이터에는 시작 토큰과 종료 토큰을 추가한다.\n",
    "data['decoder_input'] = data['Summary'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['Summary'].apply(lambda x : x + ' eostoken')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "opposite-accused",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더, 디코더의 입력과 레이블을 각각 Numpy 타입으로 저장한다.\n",
    "encoder_input = np.array(data['Text']) # 인코더의 입력\n",
    "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
    "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "varying-finance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34411 52000  1373 ... 24282 35578 42893]\n"
     ]
    }
   ],
   "source": [
    "# encoder_input과 크기와 형태가 같은 순서가 섞인 정수 시퀀스를 만든다.\n",
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "inside-lounge",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  정수 시퀀스를 이용해 다시 데이터의 샘플 순서를 정의해 주면 잘 섞인 샘플이 된다.\n",
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "olive-sampling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터의 수 : 13163\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터와 테스트 데이터 분리\n",
    "n_of_val = int(len(encoder_input)*0.2)\n",
    "print('테스트 데이터의 수 :', n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "stupid-switzerland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 52655\n",
      "훈련 레이블의 개수 : 52655\n",
      "테스트 데이터의 개수 : 13163\n",
      "테스트 레이블의 개수 : 13163\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "# 테스트 데이터\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latin-lesbian",
   "metadata": {},
   "source": [
    "## 정수 인코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-petroleum",
   "metadata": {},
   "source": [
    "### 단어 집합(vocabulary) 만들기 및 정수 인코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considered-malta",
   "metadata": {},
   "source": [
    "__단어 집합__: 훈련 데이터와 테스트 데이터의 단어들을 모두 정수로 만든다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handed-transcript",
   "metadata": {},
   "source": [
    "#### Text 데이터 정수 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "civil-arabic",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tokenizer = Tokenizer() # 토크나이저 정의\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 입력된 데이터로부터 단어 집합 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-attention",
   "metadata": {},
   "source": [
    "단어 집합은 `src_tokenizer.word_index`에 저장되어 있다.\n",
    "`src_tokenizer.word_counts.items()`에는 단어와 각 단어의 등장 빈도수가 저장돼 있는데, 이를 통해서 통계적인 정보를 얻을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dominant-benchmark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 31965\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 23720\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 8245\n",
      "단어 집합에서 희귀 단어의 비율: 74.20616299077115\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.3861640844305407\n"
     ]
    }
   ],
   "source": [
    "threshold = 7\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "talented-continuity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 등장빈도가 6회 이하인 단어들은 훈련 데이터에서 제거\n",
    "src_vocab = 8000\n",
    "src_tokenizer = Tokenizer(num_words=src_vocab) # 단어 집합의 크기를 8,000으로 제한\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fluid-electron",
   "metadata": {},
   "source": [
    "`texts_to_sequences()`는 생성된 단어 집합에 기반하여 입력으로 주어진 텍스트 데이터의 단어들을 모두 정수로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "referenced-rebel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[705, 3658, 16, 9, 74, 1783, 151, 3, 1150, 6454, 4, 412, 5, 6118, 3722, 26, 331, 265, 34, 208, 896, 705, 27, 106, 822, 1021, 604, 39], [180, 53, 227, 1033, 685, 1262, 206, 4924, 576, 951, 1048, 266, 122, 13, 480, 654, 951, 266, 569], [114, 36, 155, 185, 6, 134, 768, 3460, 17, 240, 3, 292, 1720]]\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "# 잘 진행되었는지 샘플 출력\n",
    "print(encoder_input_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brief-rugby",
   "metadata": {},
   "source": [
    "#### Summary 정수 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "diagnostic-bernard",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "stunning-casino",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 10536\n",
      "등장 빈도가 5번 이하인 희귀 단어의 수: 8165\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 2371\n",
      "단어 집합에서 희귀 단어의 비율: 77.49620349278665\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 5.927576265562311\n"
     ]
    }
   ],
   "source": [
    "threshold = 6\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "arabic-theology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "input  [[1, 629], [1, 4, 87, 7, 5], [1, 28, 43, 360], [1, 21, 3], [1]]\n",
      "target\n",
      "decoder  [[629, 2], [4, 87, 7, 5, 2], [28, 43, 360, 2], [21, 3, 2], [2]]\n"
     ]
    }
   ],
   "source": [
    "# 등장빈도가 5회 이하인 단어들은 훈련 데이터에서 제거\n",
    "tar_vocab = 2000\n",
    "tar_tokenizer = Tokenizer(num_words=tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "# 잘 변환되었는지 확인\n",
    "print('input')\n",
    "print('input ',decoder_input_train[:5])\n",
    "print('target')\n",
    "print('decoder ',decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "reserved-artwork",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 1266\n",
      "삭제할 테스트 데이터의 개수 : 337\n",
      "훈련 데이터의 개수 : 51389\n",
      "훈련 레이블의 개수 : 51389\n",
      "테스트 데이터의 개수 : 12826\n",
      "테스트 레이블의 개수 : 12826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "# 빈도수가 낮은 단어가 삭제되어 생긴 빈 샘플 제거 (길이 1인 경우)\n",
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :', len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :', len(drop_test))\n",
    "\n",
    "encoder_input_train = np.delete(encoder_input_train, drop_train, axis=0)\n",
    "decoder_input_train = np.delete(decoder_input_train, drop_train, axis=0)\n",
    "decoder_target_train = np.delete(decoder_target_train, drop_train, axis=0)\n",
    "\n",
    "encoder_input_test = np.delete(encoder_input_test, drop_test, axis=0)\n",
    "decoder_input_test = np.delete(decoder_input_test, drop_test, axis=0)\n",
    "decoder_target_test = np.delete(decoder_target_test, drop_test, axis=0)\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generous-heaven",
   "metadata": {},
   "source": [
    "### 패딩하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binding-imagination",
   "metadata": {},
   "source": [
    "텍스트 시퀀스를 정수 시퀀스로 변환했다면, 이제 서로 다른 길이의 샘플들을 병렬 처리하기 위해 같은 길이로 맞춰주는 패딩 작업을 해준다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "secondary-realtor",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen=text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen=text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen=summary_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen=summary_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen=summary_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen=summary_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-seattle",
   "metadata": {},
   "source": [
    "## 모델 설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "multiple-massage",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "killing-sauce",
   "metadata": {},
   "source": [
    "### encoder 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "charitable-scope",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "# 인코더 설계 시작\n",
    "embedding_dim = 128 # 임베딩 벡터의 차원\n",
    "hidden_size = 256 # lstm에서 얼만큼의 수용력(capacity)를 가질지 정하는 파라미터\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "molecular-monthly",
   "metadata": {},
   "source": [
    "### decoder 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "covered-organic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "# 디코더 설계\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "reflected-costa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50, 128)      1024000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 50, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 50, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    256000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 50, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 2000)   514000      lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 3,633,104\n",
      "Trainable params: 3,633,104\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax') # tar_vocab에서 하나의 단어를 선택하는 다중 클래스 분류 문제\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressed-fleece",
   "metadata": {},
   "source": [
    "### 어텐션 매커니즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "mobile-seller",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구현된 어텐션 함수 다운로드\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/thushv89/attention_keras/master/src/layers/attention.py\", filename=\"attention.py\")\n",
    "from attention import AttentionLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "minute-citizenship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50, 128)      1024000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 50, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 50, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    256000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 50, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 256),  131328      lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 512)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 2000)   1026000     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 4,276,432\n",
      "Trainable params: 4,276,432\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changed-specification",
   "metadata": {},
   "source": [
    "## 모델 훈련하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlikely-outreach",
   "metadata": {},
   "source": [
    "#### 모델저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "worth-factory",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"ex10/LSTM2.ckpt\"             # 저장할 가중치의 확장자 및 파일 이름\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)  # 저장할 경로\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, # 학습 시 callback함수를 반환하여 학습\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungarian-orbit",
   "metadata": {},
   "source": [
    "#### Early Stopping\n",
    "모니터링 항목의 개선이 중지되면 학습을 중지하는 함수\n",
    "\n",
    "|Args||\n",
    "|------:|:---|\n",
    "|monitor|모니터링 할 성능|\n",
    "|patience|성능이 증가하지 않는 epoch 을 몇 번이나 허용할 것인가를 정의|\n",
    "|min_delta|개선의 자격을 갖추기 위해 모니터링되는 수량의 최소 변경, 즉 min_delta 미만의 절대 변경은 개선되지 않은 것으로 간주.|\n",
    "|verbose|1 로 지정하면, 언제 keras 에서 training 을 멈추었는지를 화면에 출력|\n",
    "|mode|{\"auto\", \"min\", \"max\"}, auto는 keras에서 알아서 min,max 선택,performance measure를 정의하고, 이것을 최대화 할지, 최소화 할지를 지정하는 것이다. 그러면 keras 에서 알아서 적절한 epoch 에서 training 을 멈춘다.|\n",
    "|baseline|performance measure 를 practical 하게 설정한 경우 성능의 증가의 기준을 직접 정의. 모델이 기준선보다 개선되지 않으면 학습이 중지|\n",
    "|restore_best_weights|모니터링된 수량의 최상의 값으로 에포크에서 모델 가중치를 복원할지 여부|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "explicit-leather",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "201/201 [==============================] - 171s 789ms/step - loss: 3.1169 - val_loss: 2.4262\n",
      "\n",
      "Epoch 00001: saving model to ex10/LSTM2.ckpt\n",
      "Epoch 2/50\n",
      "201/201 [==============================] - 161s 801ms/step - loss: 2.4178 - val_loss: 2.3174\n",
      "\n",
      "Epoch 00002: saving model to ex10/LSTM2.ckpt\n",
      "Epoch 3/50\n",
      "201/201 [==============================] - 161s 800ms/step - loss: 2.2806 - val_loss: 2.1803\n",
      "\n",
      "Epoch 00003: saving model to ex10/LSTM2.ckpt\n",
      "Epoch 4/50\n",
      "201/201 [==============================] - 162s 808ms/step - loss: 2.1582 - val_loss: 2.0882\n",
      "\n",
      "Epoch 00004: saving model to ex10/LSTM2.ckpt\n",
      "Epoch 5/50\n",
      "201/201 [==============================] - 161s 804ms/step - loss: 2.0581 - val_loss: 2.0420\n",
      "\n",
      "Epoch 00005: saving model to ex10/LSTM2.ckpt\n",
      "Epoch 6/50\n",
      "201/201 [==============================] - 161s 803ms/step - loss: 1.9850 - val_loss: 1.9899\n",
      "\n",
      "Epoch 00006: saving model to ex10/LSTM2.ckpt\n",
      "Epoch 7/50\n",
      "201/201 [==============================] - 162s 805ms/step - loss: 1.9341 - val_loss: 1.9591\n",
      "\n",
      "Epoch 00007: saving model to ex10/LSTM2.ckpt\n",
      "Epoch 8/50\n",
      "201/201 [==============================] - 160s 797ms/step - loss: 1.8816 - val_loss: 1.9379\n",
      "\n",
      "Epoch 00008: saving model to ex10/LSTM2.ckpt\n",
      "Epoch 9/50\n",
      "201/201 [==============================] - 161s 802ms/step - loss: 1.8374 - val_loss: 1.9073\n",
      "\n",
      "Epoch 00009: saving model to ex10/LSTM2.ckpt\n",
      "Epoch 10/50\n",
      "201/201 [==============================] - 160s 797ms/step - loss: 1.8005 - val_loss: 1.8958\n",
      "\n",
      "Epoch 00010: saving model to ex10/LSTM2.ckpt\n",
      "Epoch 11/50\n",
      "201/201 [==============================] - 161s 801ms/step - loss: 1.7709 - val_loss: 1.8775\n",
      "\n",
      "Epoch 00011: saving model to ex10/LSTM2.ckpt\n",
      "Epoch 12/50\n",
      "201/201 [==============================] - 161s 799ms/step - loss: 1.7309 - val_loss: 1.8669\n",
      "\n",
      "Epoch 00012: saving model to ex10/LSTM2.ckpt\n",
      "Epoch 13/50\n",
      "201/201 [==============================] - 161s 801ms/step - loss: 1.7021 - val_loss: 1.8632\n",
      "\n",
      "Epoch 00013: saving model to ex10/LSTM2.ckpt\n",
      "Epoch 14/50\n",
      "201/201 [==============================] - 162s 804ms/step - loss: 1.6772 - val_loss: 1.8509\n",
      "\n",
      "Epoch 00014: saving model to ex10/LSTM2.ckpt\n",
      "Epoch 15/50\n",
      "201/201 [==============================] - 162s 804ms/step - loss: 1.6546 - val_loss: 1.8489\n",
      "\n",
      "Epoch 00015: saving model to ex10/LSTM2.ckpt\n",
      "Epoch 16/50\n",
      "201/201 [==============================] - 162s 806ms/step - loss: 1.6285 - val_loss: 1.8466\n",
      "\n",
      "Epoch 00016: saving model to ex10/LSTM2.ckpt\n",
      "Epoch 17/50\n",
      "201/201 [==============================] - 161s 803ms/step - loss: 1.5949 - val_loss: 1.8413\n",
      "\n",
      "Epoch 00017: saving model to ex10/LSTM2.ckpt\n",
      "Epoch 18/50\n",
      "201/201 [==============================] - 162s 805ms/step - loss: 1.5828 - val_loss: 1.8429\n",
      "\n",
      "Epoch 00018: saving model to ex10/LSTM2.ckpt\n",
      "Epoch 19/50\n",
      "201/201 [==============================] - 161s 803ms/step - loss: 1.5508 - val_loss: 1.8409\n",
      "\n",
      "Epoch 00019: saving model to ex10/LSTM2.ckpt\n",
      "Epoch 20/50\n",
      "201/201 [==============================] - 162s 804ms/step - loss: 1.5261 - val_loss: 1.8454\n",
      "\n",
      "Epoch 00020: saving model to ex10/LSTM2.ckpt\n",
      "Epoch 21/50\n",
      "201/201 [==============================] - 159s 792ms/step - loss: 1.5159 - val_loss: 1.8457\n",
      "\n",
      "Epoch 00021: saving model to ex10/LSTM2.ckpt\n",
      "Epoch 00021: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "earlystopping = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), \\\n",
    "          batch_size=256, callbacks=[checkpoint ,earlystopping], epochs=50) # model.fit()에 callback으로 es객체를 넣어줘야 es 적용 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "optional-fossil",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 훈련 과정 시각화\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affecting-invention",
   "metadata": {},
   "source": [
    "## 인퍼런스 모델 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "racial-shadow",
   "metadata": {},
   "source": [
    "> __인퍼런스란?__\n",
    "학습을 마친 모델로 실제 과제를 수행하는 행위 혹은 그 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "adverse-asset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수로 된 데이터를 실제로 복원해야 하므로 필요한 사전을 세팅한다.\n",
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innovative-month",
   "metadata": {},
   "source": [
    "- Seq2seq는 훈련할 때와 인퍼런스 단계의 방식이 달라 그에 맞는 모델 설계를 별개로 진행해야 한다\n",
    "- 훈련 단계: 인코더와 디코더를 엮은 모델 준비\n",
    "- 인퍼런스 단계: 인코더 모델과 디코더 모델을 분리해서 설계(정답X, 디코더가 반복구조로 동작할 필요)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "consecutive-affiliation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "round-indonesian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션 메커니즘을 사용하는 출력층 설계\n",
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "quiet-impact",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 시퀀스를 완성하는 함수\n",
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if (sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (summary_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swedish-neighbor",
   "metadata": {},
   "source": [
    "## 모델 테스트하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "sunset-minister",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if (i!=0):\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2summary(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if ((i!=0 and i!=tar_word_to_index['sostoken']) and i!=tar_word_to_index['eostoken']):\n",
    "            temp = temp + tar_index_to_word[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "elder-revision",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 : really love cheez sit front tv box know half gone different know expected little box yet seemed fall short nail directly head get wrong still enjoyed left odd taste mouth honestly crazy much else say hope review helped one way enjoy \n",
      "실제 요약 : an okay taste from delicious brand \n",
      "예측 요약 :  not as pictured\n",
      "\n",
      "\n",
      "원문 : received packet gold gourmet hot chocolate sample bland bitter slight mushroom smell aftertaste understand type mushroom expect forward drink neither sweet enough enjoyable lighter chocolate drink rich enough good dark chocolate drink really would recommend give two stars completely undrinkable close \n",
      "실제 요약 : weak flavor unusual smell \n",
      "예측 요약 :  not for me\n",
      "\n",
      "\n",
      "원문 : trying lose pounds weight watchers best chips around love potatoes keep diet tasty low fat oil boyfriend diet also enjoys chips yum \n",
      "실제 요약 : these rock \n",
      "예측 요약 :  great snack\n",
      "\n",
      "\n",
      "원문 : local grocery stores started stocking chewy kashi breakfast bars husband went absolute favorite kashi crunchy honey toasted grain eaten banana every morning thanks amazon com regular shipment scheduled every months mornings happy \n",
      "실제 요약 : kashi breakfast on the go \n",
      "예측 요약 :  great snack\n",
      "\n",
      "\n",
      "원문 : buy bars prefer others tried sweet plus want sugary fluff might want try another variety peanut flavor preferable well worth try want kids acquire craving sweets \n",
      "실제 요약 : great bars \n",
      "예측 요약 :  great taste\n",
      "\n",
      "\n",
      "원문 : green tastes terrible water forms clumps fully dissolve buy worth money \n",
      "실제 요약 : low quality powder \n",
      "예측 요약 :  bad taste\n",
      "\n",
      "\n",
      "원문 : never ordered sea salt thought great afraid would additional flavor wouldnt like instead fresh tasting natural like pink color glad doesnt come pink \n",
      "실제 요약 : himalayan salt \n",
      "예측 요약 :  very tasty\n",
      "\n",
      "\n",
      "원문 : got pre birthday gift husband loved price starbucks website save shipping amazon great buy \n",
      "실제 요약 : my husband loves this \n",
      "예측 요약 :  great gift\n",
      "\n",
      "\n",
      "원문 : love stuff first encountered sauce lucky cafe sacramento ca could find live oregon stuff available amazon taylors market go get \n",
      "실제 요약 : highly addictive flavor \n",
      "예측 요약 :  the best\n",
      "\n",
      "\n",
      "원문 : subscribe save service good product delivered required actually save money coffee great good full bodied taste delicious keeps wide awake working \n",
      "실제 요약 : another great coffee \n",
      "예측 요약 :  great coffee\n",
      "\n",
      "\n",
      "원문 : use soup part daily effort control type diabetes tasty filling spike blood sugar little extra treat add little grilled chicken crispy red jalapeno peppers love much cans automatically shipped every month \n",
      "실제 요약 : tasty and filling low on carbs \n",
      "예측 요약 :  great soup\n",
      "\n",
      "\n",
      "원문 : peanut shells get mix thank goodness allergy esp since looked like flower first even stained red looked like petals least warning could peanut allergens product class action waiting happen \n",
      "실제 요약 : peanut shells \n",
      "예측 요약 :  delicious\n",
      "\n",
      "\n",
      "원문 : mine costco cheap like compare amazon charge great snack lower fat content since made like soy nuts careful portion size great snacks opinion \n",
      "실제 요약 : great snacks \n",
      "예측 요약 :  great snack\n",
      "\n",
      "\n",
      "원문 : dad love pickled garlic preferred brand reason garlic nearly strong would raw like pickles garlic try \n",
      "실제 요약 : we love it \n",
      "예측 요약 :  great taste\n",
      "\n",
      "\n",
      "원문 : best tasting green ever love creamy soups split pea one favorites usually easy make delicious creamy soup without adding sort meat flavoring peas delicious without cooked sort meat chicken based flavorings nice fresh gray colored little things sold plastic bags grocery store peas even smell fresh bag \n",
      "실제 요약 : full of flavor \n",
      "예측 요약 :  delicious\n",
      "\n",
      "\n",
      "원문 : disappointed chips oily tasted smelled rancid since supposedly high end snacks live \n",
      "실제 요약 : sea salt cut potato chips \n",
      "예측 요약 :  stale\n",
      "\n",
      "\n",
      "원문 : really enjoyed mixed pack ordering blueberry next time really good \n",
      "실제 요약 : very good \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : outstanding difficult find product tasty much less expensive whole wheat orzo found specialty shops \n",
      "실제 요약 : awesome whole wheat \n",
      "예측 요약 :  great crackers\n",
      "\n",
      "\n",
      "원문 : peppercorns much better quality would gotten places aroma even opened package arrived fresher ever tasted peppercorns life seller professional quick shipment highly recommended \n",
      "실제 요약 : excellent quality \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : good value flavored coffee pound less price full pound lightly flavored medium roasted coffee using single cup brewer smooth non bitter light cup coffee tried using cup drip machine coffees little stronger done way \n",
      "실제 요약 : smooth light roast coffee good price to value \n",
      "예측 요약 :  good coffee\n",
      "\n",
      "\n",
      "원문 : bought roommate joke gift going regular bottles month problem stuff plus great starter decoration recommend tabasco fan \n",
      "실제 요약 : bigger is better \n",
      "예측 요약 :  great gift\n",
      "\n",
      "\n",
      "원문 : rarely eat anything whole wheat pasta every eat treat almost good pastas ate italy make sure cook \n",
      "실제 요약 : me of italy \n",
      "예측 요약 :  great gluten free pasta\n",
      "\n",
      "\n",
      "원문 : taste nasty much love chocolate would even touch last earth \n",
      "실제 요약 : taste is horrible \n",
      "예측 요약 :  not the best\n",
      "\n",
      "\n",
      "원문 : warning stuff hot adding drop pho much like handle spice warned enjoy \n",
      "실제 요약 : hot \n",
      "예측 요약 :  hot hot sauce\n",
      "\n",
      "\n",
      "원문 : family enjoys snack much lighter alternative chips vinegar light overpower flavor fries \n",
      "실제 요약 : yummy chip alternative \n",
      "예측 요약 :  great snack\n",
      "\n",
      "\n",
      "원문 : dissapointed product tops sealed properly half ended throwing half away order product \n",
      "실제 요약 : cup coffee \n",
      "예측 요약 :  very disappointed\n",
      "\n",
      "\n",
      "원문 : coffee good every cup broke use making mess inside cup purchase \n",
      "실제 요약 : not good \n",
      "예측 요약 :  great coffee\n",
      "\n",
      "\n",
      "원문 : like food bits etc unless chopped pate perfect consistancy tho still add little hot water make bit soupy know bad teeth wants food temperature dead critter however eat thats miracle \n",
      "실제 요약 : my cat loves the \n",
      "예측 요약 :  not for\n",
      "\n",
      "\n",
      "원문 : made chocolate ice cream using best tasting one far better nestle good service fast buy future \n",
      "실제 요약 : really high quality chocolate \n",
      "예측 요약 :  best hot chocolate\n",
      "\n",
      "\n",
      "원문 : ordered millet flour bulk twice order third time none expired fine use lot never problem \n",
      "실제 요약 : fine flour \n",
      "예측 요약 :  dented cans\n",
      "\n",
      "\n",
      "원문 : bar super yummy agree advertising almond walnut macadamia bar bar peanuts big turn \n",
      "실제 요약 : excellent for peanut bar \n",
      "예측 요약 :  great snack\n",
      "\n",
      "\n",
      "원문 : like reviewer bought world market disgusting boxes bought straight trash \n",
      "실제 요약 : absolutely disgusting \n",
      "예측 요약 :  horrible\n",
      "\n",
      "\n",
      "원문 : really locally grown comes olive oil hard california oil close georgia able get taste amazing also really like nourishing idea using olive oil ordered elsewhere cheaper amazon pleased order \n",
      "실제 요약 : great product \n",
      "예측 요약 :  great oil\n",
      "\n",
      "\n",
      "원문 : innova evo cat kitten food dry good fancy feast \n",
      "실제 요약 : happy cats \n",
      "예측 요약 :  my cat loves this\n",
      "\n",
      "\n",
      "원문 : gum refreshing lasts long time also like contain artificial flavorings many big brand gums one piece takes \n",
      "실제 요약 : refreshing \n",
      "예측 요약 :  great gum\n",
      "\n",
      "\n",
      "원문 : picture description pure butter mini shortbread round decided order love bad got package came mini chocolate chip shortbread like \n",
      "실제 요약 : little bit disapointed \n",
      "예측 요약 :  not as good as the picture\n",
      "\n",
      "\n",
      "원문 : warned chips salt want taste interesting flavor unique variety corn sodium blue color artificial chemical coloring healthful corn great source healthful benefits highly recommended especially corn lovers regards \n",
      "실제 요약 : fine product from company \n",
      "예측 요약 :  best chips ever\n",
      "\n",
      "\n",
      "원문 : decent coffee sure reviews rave particularly smooth bitterness beans also bit dry looking bad sign well \n",
      "실제 요약 : just ok coffee \n",
      "예측 요약 :  good coffee\n",
      "\n",
      "\n",
      "원문 : little guys tasty refreshing usually eat salads lunch terrible things breath eat lunch find problem sugar free great tasty enough almost think part lunch good bulk value buy would highly recommend mints cheers \n",
      "실제 요약 : great for after lunch \n",
      "예측 요약 :  great for on the go\n",
      "\n",
      "\n",
      "원문 : customer like chips product like eat chips small spoon miss \n",
      "실제 요약 : highly recommended \n",
      "예측 요약 :  great chips\n",
      "\n",
      "\n",
      "원문 : happy bisquick came gluten free version tried many brands pancake waffle mix hands bisquick best made waffles morning husband floored good outside crisp inside soft said great pancakes \n",
      "실제 요약 : we love it \n",
      "예측 요약 :  great gluten free snack\n",
      "\n",
      "\n",
      "원문 : got licorice cheese shop new york time got home gone got computer found bought much liked done regret buying yumm \n",
      "실제 요약 : soft just the right of flavor \n",
      "예측 요약 :  licorice\n",
      "\n",
      "\n",
      "원문 : calories high protein bought several boxes flavors best snack kids like way healthier crap could eating school great taste softer cheaper hard jerky \n",
      "실제 요약 : great snack \n",
      "예측 요약 :  great snack for kids\n",
      "\n",
      "\n",
      "원문 : taste like pad thai noodles still delicious tanginess like add teaspoon crunchy peanut butter final stir kicks richness bit \n",
      "실제 요약 : mm mm \n",
      "예측 요약 :  yummy\n",
      "\n",
      "\n",
      "원문 : introduced brand high end restaurant secret apparently primary ingredient corn rather rice mushy gf pasta incredible \n",
      "실제 요약 : what relief to have good pasta again \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : popcorn good makes half tast good like theater popcorn \n",
      "실제 요약 : popcorn \n",
      "예측 요약 :  great popcorn\n",
      "\n",
      "\n",
      "원문 : always loved fruit snacks could resist trying ones shaped like bunnies slightly softer texture traditional fruit snacks strong realistic fruit flavors tropical ones definitely favorite prefer brands traditional fruit snacks however price little high buy regular basis \n",
      "실제 요약 : delicious snack \n",
      "예측 요약 :  great for kids\n",
      "\n",
      "\n",
      "원문 : pretty good would recommend like peanuts little dry though fill hungry cal fat carb protein \n",
      "실제 요약 : pretty good \n",
      "예측 요약 :  good but not great\n",
      "\n",
      "\n",
      "원문 : excellent sauce right hot little spicy kids put sticky rice vegetables meatless dieting really saved diet days \n",
      "실제 요약 : love this sauce \n",
      "예측 요약 :  great for\n",
      "\n",
      "\n",
      "원문 : delicious still light refreshing enough pre post work drink drink flavor plain coco water sweet \n",
      "실제 요약 : like light \n",
      "예측 요약 :  great taste\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터 약 50개의 샘플에 대해서 실제 요약과 예측된 요약을 비교\n",
    "for i in range(50, 100):\n",
    "    print(\"원문 :\", seq2text(encoder_input_test[i]))\n",
    "    print(\"실제 요약 :\", seq2summary(decoder_input_test[i]))\n",
    "    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-miami",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "delayed-symposium",
   "metadata": {},
   "source": [
    "## 추출적 요약 해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-preference",
   "metadata": {},
   "source": [
    "매트릭스 시놉시스를 `Summa`의 추출적 요약 모듈인 summarize를 이용해 요약해본다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-advertiser",
   "metadata": {},
   "source": [
    "### 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "australian-world",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from summa.summarizer import summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "certain-dating",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 매트릭스 시놉시스 다운로드\n",
    "text = requests.get('http://rare-technologies.com/the_matrix_synopsis.txt').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "lightweight-puzzle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The screen is filled with green, cascading code which gives way to the title, The Matrix.\r\n",
      "\r\n",
      "A phone rings and text appears on the screen: \"Call trans opt: received. 2-19-98 13:24:18 REC: Log>\" As a conversation takes place between Trinity (Carrie-Anne Moss) and Cypher (Joe Pantoliano), two free humans, a table of random green numbers are being scanned and individual numbers selected, creating a series of digits not unlike an ordinary phone number, as if a code is being deciphered or a call is being traced.\r\n",
      "\r\n",
      "Trinity discusses some unknown person. Cypher taunts Trinity, suggesting she enjoys watching him. Trinity counters that \"Morpheus (Laurence Fishburne) says he may be 'the One',\" just as the sound of a number being selected alerts Trinity that someone may be tracing their call. She ends the call.\r\n",
      "\r\n",
      "Armed policemen move down a darkened, decrepit hallway in the Heart O' the City Hotel, their flashlight beam bouncing just ahead of them. They come to room 303, kick down the door and find a woman dressed in black, facing away from them. It's Trinity. She brings her hands up from the laptop she's working on at their command.\r\n",
      "\r\n",
      "Outside the hotel a car drives up and three agents appear in neatly pressed black suits. They are Agent Smith (Hugo Weaving), Agent Brown (Paul Goddard), and Agent Jones (Robert Taylor). Agent Smith and the presiding police lieutenant argue. Agent Smith admonishes the policeman that they were given specific orders to contact the agents first, for their\n"
     ]
    }
   ],
   "source": [
    "# 내용 확인\n",
    "print(text[:1500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relevant-diameter",
   "metadata": {},
   "source": [
    "### summarize 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "former-dynamics",
   "metadata": {},
   "source": [
    "#### summa의 summarize()\n",
    "\n",
    "|Args||\n",
    "|:------|:---|\n",
    "|text (str)|요약할 테스트|\n",
    "|ratio (float, optional)|요약문에서 원본에서 선택되는 문장 비율. 0~1 사이값|\n",
    "|words (int or None, optional)|출력에 포함할 단어 수.만약, ratio와 함께 두 파라미터가 모두 제공되는 경우 ratio는 무시한다.|\n",
    "|split (bool, optional)|True면 문장 list / False는 조인(join)된 문자열을 반환|\n",
    "\n",
    "* 내부적으로 문장토큰화 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fitted-prospect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "Morpheus, Trinity, Neo, Apoc, Switch, Mouse and Cypher are jacked into the Matrix.\n",
      "Trinity brings the helicopter down to the floor that Morpheus is on and Neo opens fire on the three Agents.\n"
     ]
    }
   ],
   "source": [
    "print('Summary:')\n",
    "print(summarize(text, ratio=0.005)) # 요약문으로 선택되는 문장의 개수, 원문의 0.005%만을 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "presidential-printer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "['Morpheus, Trinity, Neo, Apoc, Switch, Mouse and Cypher are jacked into the Matrix.', 'Trinity brings the helicopter down to the floor that Morpheus is on and Neo opens fire on the three Agents.']\n"
     ]
    }
   ],
   "source": [
    "# 리스트로 결과 출력\n",
    "print('Summary:')\n",
    "print(summarize(text, ratio=0.005, split=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "sexual-excitement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "Trinity takes Neo to Morpheus.\n",
      "Morpheus, Trinity, Neo, Apoc, Switch, Mouse and Cypher are jacked into the Matrix.\n",
      "Trinity brings the helicopter down to the floor that Morpheus is on and Neo opens fire on the three Agents.\n"
     ]
    }
   ],
   "source": [
    "# 50개의 단어로 요약문의 크기 조정\n",
    "print('Summary:')\n",
    "print(summarize(text, words=50))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
