{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dimensional-colorado",
   "metadata": {},
   "source": [
    "# 6.임베딩 내 편향성 알아보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effective-first",
   "metadata": {},
   "source": [
    "## 6-1. 들어가며"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mediterranean-combine",
   "metadata": {},
   "source": [
    "### 인공지능은 객관적일까?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unauthorized-filing",
   "metadata": {},
   "source": [
    "우리가 가진 데이터가 이미 편향되어 있다면 이를 이용하여 만든 알고리즘 또한 편향될 확률이 매우 높습니다. 그래서 최근에는 인공지능이 가진 편향성을 예방하기 위한 연구가 지속되고 있습니다. 특히 자연어처리 분야, 그중에서도 워드 임베딩과 관련된 연구가 많이 이루어지고 있습니다.\n",
    "\n",
    "왜 그럴까요? 몇 가지 이유를 생각해 볼 수 있는데요. 우선 언어의 사용패턴이 담긴 코퍼스야말로 인간 무의식 속에 감추어진 편향성이 고스란히 드러나는 데이터셋이기 때문입니다.다른 이유로는 그 언어의 의미가 워드 임베딩에 추상적인 형태로 담겨 있는데, 최근 연구를 통해 그 임베딩 공간에서 편향성을 정량적으로 측정하는 방법론들이 발표되면서 이 분야의 연구가 활기를 띠게 되었기 때문입니다.\n",
    "\n",
    "그래서 오늘은 워드 임베딩에 숨어 있는 편향성을 측정하는 대표적인 방법론인 Word Embedding Association Test (WEAT)라는 기법에 대해 알아보고, 이를 활용해 우리가 학습시킨 Word2Vec 임베딩 내의 편향성을 측정해 보면서 실제로 이 방법론이 우리 머리 속에 있는 편향성을 잘 반영하는지도 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-logic",
   "metadata": {},
   "source": [
    "### 학습 목표\n",
    "- 데이터의 편향성에 대한 문제의식을 갖는다.\n",
    "- 임베딩 모델의 편향성을 체크하는 방법 중 하나인 Word Embedding Association Test (WEAT)를 알아본다.\n",
    "- WEAT 수식의 의미를 이해하고 이를 구현해본다.\n",
    "- pre-train된 모델을 불러와서 WEAT score를 구해본다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hired-science",
   "metadata": {},
   "source": [
    "### 목차\n",
    "1. 워드 임베딩의 편향성\n",
    "2. WEAT를 통한 편향성 측정\n",
    "3. WEAT 구현하기\n",
    "4. 사전학습된 Word Embedding에 WEAT 적용\n",
    "5. 직접 만드는 Word Embedding에 WEAT 적용(1)\n",
    "6. 직접 만드는 Word Embedding에 WEAT 적용(2)\n",
    "7. 프로젝트 : 모든 장르 간 편향성 측정해 보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nervous-tracker",
   "metadata": {},
   "source": [
    "## 6-2. 워드 임베딩의 편향성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescription-participant",
   "metadata": {},
   "source": [
    "### 워드 임베딩 속의 편향성\n",
    "['Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings'](https://arxiv.org/pdf/1607.06520.pdf)\n",
    "\n",
    "이 논문의 저자는 학습된 Word Embedding을 2차원으로 차원 축소해서 시각화했을 때, 분명히 젠더 중립적인 단어임에도 불구하고 Programmer, Doctor, Engineer 등의 단어는 남성대명사 He에 가깝게, Homemaker, Nurse, Hairdresser 등의 단어는 여성대명사 She에 가깝게 위치하는 것을 보여 줌으로써 큰 반향을 불러일으켰습니다. 우리가 가지고 있을지도 모를 편견이 워드 임베딩 속 벡터들에 고스란히 반영되어 있었다는 것을 보여 주었기 때문입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-platinum",
   "metadata": {},
   "source": [
    "### WEAT(Word Embedding Association Test)\n",
    "Word Embedding Association Test (WEAT)는 임베딩 모델의 편향을 측정하는 방식 중 하나로, 2016년에 Aylin Caliskan이 제안했습니다.\n",
    "\n",
    "- [논문 원본 : Semantics derived automatically from language corpora necessarily contain human biases](https://arxiv.org/pdf/1608.07187.pdf)\n",
    "\n",
    "만약 Science와 Art가 모두 완벽히 젠더 중립적이라면, Word Embedding 상에서도 Science, Art가 Male, Female의 두 단어와의 거리가 동일해야 할 것입니다. 그러나 만약 정말 편향이 존재한다면, Science와 Male 간의 거리가 Science와 Female 간의 거리보다 가깝고, 거꾸로 Art와 Male 간의 거리는 Art와 Female간의 거리보다 멀어야겠죠?\n",
    "\n",
    "우리는 워드 임베딩 간의 거리를 코사인 유사도로 계산할 수 있다는 것을 이미 알고 있으니, 그런 방식으로 계산해 보면 편향성을 쉽게 구할 수 있을 것 같습니다! 아주 간단한 아이디어죠?\n",
    "\n",
    "WEAT는 Male과 Female, Science와 Art라는 개념을 가장 잘 대표하는 단어들을 여러 개 골라 단어 셋(set)을 만듭니다. 단어 셋에 속한 모든 단어들끼리의 편향성을 전부 계산해서 평균을 수치화해보면 보다 명확하게 개념적인 편향성이 존재함을 밝힐 수 있지 않을까요?\n",
    "\n",
    "이러한 단어 셋을 WEAT에서는 각각 __target__과 __attribute__라고 합니다.\n",
    "\n",
    "위의 예를 다시 들자면, Science를 대표하는 target 단어 셋 X와 Art를 대표하는 target 단어 셋 Y가 있다고 하면 X-Y 셋을 통한 개념축 하나가 얻어집니다. Male을 대표하는 attribute 단어 셋 A와 Female을 대표하는 attribute 단어 셋 B가 있다면 A-B 셋을 통한 개념축 하나가 또 얻어집니다. 편향성이 없다면, X에 속한 단어들은 A에 속한 단어들과의 거리와 B에 속한 단어들과의 거리가 별 차이가 없어야 합니다. 반대의 경우라면 뚜렷하게 차이가 나겠죠. Y의 경우도 마찬가지입니다.\n",
    "\n",
    "다음 스텝에 수식을 통해 보다 명확하게 설명할 WEAT score는 바로 위와 같은 방식으로 계산된 수치입니다. 절댓값이 클수록 두 개념축 사이의 편향성이 크게 나타나는 것으로 해석됩니다.\n",
    "\n",
    "(참고)\n",
    "WEAT 개념의 아이디어는 심리학의 __IAT(Implicit Association Test)__ 라는 인지편향성 실험 구조에서 따온 것입니다. IAT는 WEAT처럼 X-Y, A-B 두 개념축을 설정하는 점에서는 동일합니다. 다만 단어들 사이의 거리를 측정하는 방법이 워드 임베딩간 코사인 유사도를 계산하는 방식이 아니라, 피실험자들에게 전자적으로 단어 연상 실험을 하면서 응답 반응 속도를 측정하는 방식을 사용했을 뿐입니다. 매우 재미있는 아이디어이므로 심리학에 관심이 있으시다면 아래 링크를 열어서 IAT 테스트를 수행하여 본인 무의식 속에 있는 편향성을 측정해 보세요.\n",
    "- [IAT 홈페이지 : Project Implicit](https://implicit.harvard.edu/implicit/education.html)\n",
    "\n",
    "아래 표는 구글의 테크블로그에서 WEAT 개념을 소개하면서 첨부한 실험 결과표입니다.\n",
    "\n",
    "- [Text Embedding Models Contain Bias. Here's Why That Matters](https://developers.googleblog.com/2018/04/text-embedding-models-contain-bias.html)\n",
    "\n",
    "표에서 파란색은 사람의 편향과 같은 경우이고, 노란색은 사람의 편향과 반대인 경우를 의미합니다. (사람이 가진 편향은 Implicit Association Tests로 측정했습니다.)\n",
    "\n",
    "표를 보면 대부분의 색이 파란색인 것을 볼 수 있습니다. 이 표가 또한 말해주는 것은 사람이 가진 편향이 자연어 코퍼스 데이터에 반영되어 있고, 이 데이터로 만든 워드 임베딩 모델은 그 편향을 내재할 수밖에 없다는 점입니다.\n",
    "\n",
    "꽃과 벌레, 유쾌함과 불쾌함 등 누구나 동의할만한 편향성이 존재하는 경우엔 대부분의 경우 WEAT score의 절댓값이 1.5 이상으로 뚜렷한 편향성 수치가 나오는 것을 볼 수 있습니다. 그 외에도 다양한 개념축간 편향성이 존재하는 것을 흥미롭게 살펴볼 수 있습니다.\n",
    "\n",
    "Glove, Word2Vec 등 다양한 워드 임베딩 모델에 대해 동일한 실험을 하여 WEAT score를 측정해 본 결과도 흥미롭습니다. 모델마다 WEAT score가 동일하게 나오는 것이 아닙니다. 이런 차이점의 원인을 분석해 보는 것도 흥미로울 것 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprising-garlic",
   "metadata": {},
   "source": [
    "## 6-3. WEAT를 통한 편향성 측정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "warming-draft",
   "metadata": {},
   "source": [
    "WEAT score는 다음과 같이 정의합니다.\n",
    "\n",
    "$$ \\frac{mean_{x \\in X^S}(x,A,B)-mean_{y \\in Y^S}(y,A,B)}{std_{w \\in X \\cup Y^S}(w,A,B)}$$\n",
    "\n",
    "이 테스트는 두 벡터의 유사도를 측정하기 위해 cosine similarity를 이용합니다. cosine similarity는 두 벡터 사이의 cosine 값을 이용하여 두 벡터의 유사도를 측정합니다. 다시 말해, 두 벡터 $i,J$가 주어졌을 때, cosine similarity $cos(\\theta)$는 dot product와 magnitude를 사용하여 구할 수 있습니다.\n",
    "$$cos(\\theta)=\\frac{i*j}{\\left\\|i\\right\\|\\left\\|j\\right\\|}$$\n",
    "- $cos(\\theta)=1$: 두 벡터의 방향이 똑같을 때\n",
    "- $cos(\\theta)=0$: 두 벡터가 직교할 때\n",
    "- $cos(\\theta)=-1$: 두 벡터의 방향이 반대일 때\n",
    "\n",
    "cosine similarity는 -1에서 1을 가질 수 있으며 두 벡터의 방향이 얼마나 유사한지를 나타내게 됩니다.\n",
    "\n",
    "벡터 $\\overrightarrow{i}$와 $\\overrightarrow{j}$가 있을 때, $cos(\\overrightarrow{i},\\overrightarrow{j})$는 벡터 $\\overrightarrow{i}$와 $\\overrightarrow{j}$의 cosine similarity를 의미하므로, 아래 식의 $s(w, A, B)$가 의미하는 것은 target에 있는 단어 $w$가 두 attribute 셋 A, B에 속한 단어들과의 유사도의 평균(mean)값이 얼마나 차이 나는지를 측정합니다. 즉, $s(w, A, B)$는 개별 단어 $w$가 개념축 A-B에 대해 가지는 편향성을 계산한 값이 됩니다. 이 편향성 값은 -2에서 2사이의 값을 가지게 되며, 그 절댓값이 클수록 w는 A-B 개념축에 대해 편향성을 가진다는 뜻이 됩니다.\n",
    "\n",
    "$$ s(w, A, B)=mean_{a \\in A}cos(\\overrightarrow{w},\\overrightarrow{a})-mean_{b \\in B}cos(\\overrightarrow{w},\\overrightarrow{b})$$\n",
    "\n",
    "이제 맨 위에 소개했던 WEAT score의 정의로 되돌아가 봅시다.\n",
    "\n",
    "위 식의 분자 부분은 target X, Y에 속하는 각 단어 $x$, $y$들이 개념축 A-B에 대해 가지는 편향성을 r각각 평균 내서 뺀 차이입니다. 즉, X에 속하는 단어들과 Y에 속하는 단어들이 A-B 개념축에 대해 가지는 편향성의 정도가 뚜렷이 차이 날수록 이 WEAT score 식의 분자값의 절댓값은 커지게 됩니다. 이 값을 X, Y에 속하는 모든 단어들이 가지는 편향성 값의 표준편차(std)로 normalize한 값이 최종 WEAT score가 됩니다.\n",
    "\n",
    "설명이 좀 복잡했지만 다음 스텝에서 구현 예시를 통해 좀 더 명확히 이해해 봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "partial-belle",
   "metadata": {},
   "source": [
    "## 6-4. WEAT 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "prerequisite-opportunity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝~\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "print(\"슝~\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affecting-aerospace",
   "metadata": {},
   "source": [
    "우선 두 개의 target 단어 셋 X, Y와 두 개의 attribute 단어 셋 A, B를 정의합니다.\n",
    "단어 셋을 정할 때는 두 개의 target 셋의 크기가 같아야 하고, 두 개의 attribute 셋의 크기가 같아야 합니다.\n",
    "\n",
    "- targets\n",
    "    - X set(꽃) : 장미, 튤립, 백합, 데이지\n",
    "    - Y set(곤충) : 거미, 모기, 파리, 메뚜기\n",
    "\n",
    "- attributes\n",
    "    - A set(유쾌) : 사랑, 행복, 웃음\n",
    "    - B set(불쾌) : 재난, 고통, 증오\n",
    "\n",
    "위 단어들의 임베딩 결과가 다음과 같다고 해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "colored-holly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝~\n"
     ]
    }
   ],
   "source": [
    "target_X = {\n",
    "    '장미': [4.1, 1.2, -2.4, 0.5, 4.1],\n",
    "    '튤립': [3.1, 0.5, 3.6, 1.7, 5.8],\n",
    "    '백합': [2.9, -1.3, 0.4, 1.1, 3.7],\n",
    "    '데이지': [5.4, 2.5, 4.6, -1.0, 3.6]\n",
    "}\n",
    "target_Y = {\n",
    "    '거미': [-1.5, 0.2, -0.6, -4.6, -5.3],\n",
    "    '모기': [0.4, 0.7, -1.9, -4.5, -2.9],\n",
    "    '파리': [0.9, 1.4, -2.3, -3.9, -4.7],\n",
    "    '메뚜기': [0.7, 0.9, -0.4, -4.1, -3.9]\n",
    "}\n",
    "attribute_A = {\n",
    "    '사랑':[2.8,  4.2, 4.3,  0.3, 5.0],\n",
    "    '행복':[3.8,  3. , -1.2,  4.4, 4.9],\n",
    "    '웃음':[3.7, -0.3,  1.2, -2.5, 3.9]\n",
    "}\n",
    "attribute_B = {\n",
    "    '재난': [-0.2, -2.8, -4.7, -4.3, -4.7],\n",
    "    '고통': [-4.5, -2.1,  -3.8, -3.6, -3.1],\n",
    "    '증오': [-3.6, -3.3, -3.5,  -3.7, -4.4]\n",
    "}\n",
    "\n",
    "print(\"슝~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "intellectual-tucson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.1  1.2 -2.4  0.5  4.1]\n",
      " [ 3.1  0.5  3.6  1.7  5.8]\n",
      " [ 2.9 -1.3  0.4  1.1  3.7]\n",
      " [ 5.4  2.5  4.6 -1.   3.6]]\n",
      "[[-1.5  0.2 -0.6 -4.6 -5.3]\n",
      " [ 0.4  0.7 -1.9 -4.5 -2.9]\n",
      " [ 0.9  1.4 -2.3 -3.9 -4.7]\n",
      " [ 0.7  0.9 -0.4 -4.1 -3.9]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([v for v in target_X.values()])\n",
    "Y = np.array([v for v in target_Y.values()])\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sealed-training",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.8  4.2  4.3  0.3  5. ]\n",
      " [ 3.8  3.  -1.2  4.4  4.9]\n",
      " [ 3.7 -0.3  1.2 -2.5  3.9]]\n",
      "[[-0.2 -2.8 -4.7 -4.3 -4.7]\n",
      " [-4.5 -2.1 -3.8 -3.6 -3.1]\n",
      " [-3.6 -3.3 -3.5 -3.7 -4.4]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([v for v in attribute_A.values()])\n",
    "B = np.array([v for v in attribute_B.values()])\n",
    "print(A)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-apparel",
   "metadata": {},
   "source": [
    "`s('장미', A, B)` 를 계산해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "happy-railway",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6457646122337399\n"
     ]
    }
   ],
   "source": [
    "def cos_sim(i, j):\n",
    "    return dot(i, j.T)/(norm(i)*norm(j))\n",
    "\n",
    "def s(w, A, B):\n",
    "    c_a = cos_sim(w, A)\n",
    "    c_b = cos_sim(w, B)\n",
    "    mean_A = np.mean(c_a, axis=-1)\n",
    "    mean_B = np.mean(c_b, axis=-1)\n",
    "    return mean_A - mean_B #, c_a, c_b\n",
    "\n",
    "print(s(target_X['장미'], A, B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understanding-baking",
   "metadata": {},
   "source": [
    "WEAT score값이 양수이므로, target_X에 있는 '장미'라는 단어는 attribute_B(불쾌)보다 attribute_A(유쾌)와 더 가깝다는 것을 알 수 있습니다. target_Y에 있는 '거미'와 attribute_A, attribute_B와의 관계도 계산해봅시다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "suspended-detection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.794002342033094\n"
     ]
    }
   ],
   "source": [
    "print(s(target_Y['거미'], A, B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "every-render",
   "metadata": {},
   "source": [
    "위와 반대로 WEAT score가 음수가 나왔으므로, '거미'는 attribute_B와 더 가깝다는 것을 알 수 있습니다.\n",
    "\n",
    "그럼 target_X와 attribute_A, attribute_B 사이의 평균값, 그리고 target_Y와 attribute_A, attribute_B 사의의 평균값은 어떻게 될까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "distinct-steps",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.29551989 0.51723181 0.26499096 0.50924109]\n",
      "0.397\n"
     ]
    }
   ],
   "source": [
    "print(s(X, A, B))\n",
    "print(round(np.mean(s(X, A, B)), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-review",
   "metadata": {},
   "source": [
    "target_X와 attribute_A, attribute_B 사이의 평균값은 0.397입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "frozen-panel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.44713039 -0.28310853 -0.33144878 -0.26030641]\n",
      "-0.33\n"
     ]
    }
   ],
   "source": [
    "print(s(Y, A, B))\n",
    "print(round(np.mean(s(Y, A, B)), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acquired-water",
   "metadata": {},
   "source": [
    "target_Y와 attribute_A, attribute_B 사이의 평균값은 -0.33입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "partial-library",
   "metadata": {},
   "source": [
    "그럼 이번에는 WEAT score의 수식 전체를 코드로 나타내 봅시다.\n",
    "\n",
    "$$ \\frac{mean_{x \\in X^S}(x,A,B)-mean_{y \\in Y^S}(y,A,B)}{std_{w \\in X \\cup Y^S}(w,A,B)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "minus-barcelona",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.932\n"
     ]
    }
   ],
   "source": [
    "def weat_score(X, Y, A, B):\n",
    "    \n",
    "    s_X = s(X, A, B)\n",
    "    s_Y = s(Y, A, B)\n",
    "\n",
    "    mean_X = np.mean(s_X)\n",
    "    mean_Y = np.mean(s_Y)\n",
    "    \n",
    "    std_dev = np.std(np.concatenate([s_X, s_Y], axis=0))\n",
    "    \n",
    "    return  (mean_X-mean_Y)/std_dev\n",
    "\n",
    "print(round(weat_score(X, Y, A, B), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coral-pastor",
   "metadata": {},
   "source": [
    "WEAT score가 매우 높게 나온 것을 알 수 있습니다. 즉, 꽃은 유쾌한 단어와 상대적으로 가깝고, 곤충은 불쾌한 단어와 가깝다는 것을 수치적으로 확인할 수 있었습니다.\n",
    "\n",
    "이제 이를 시각적으로 확인해볼까요? PCA를 통해 5차원이었던 벡터를 2차원으로 줄여 그림을 그려보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "soviet-power",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fcd41de7990>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pc_A = pca.fit_transform(A)\n",
    "pc_B = pca.fit_transform(B)\n",
    "pc_X = pca.fit_transform(X)\n",
    "pc_Y = pca.fit_transform(Y)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(pc_A[:,0],pc_A[:,1], c='blue', label='A')\n",
    "ax.scatter(pc_B[:,0],pc_B[:,1], c='red', label='B')\n",
    "ax.scatter(pc_X[:,0],pc_X[:,1], c='skyblue', label='X')\n",
    "ax.scatter(pc_Y[:,0],pc_Y[:,1], c='pink', label='Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-arena",
   "metadata": {},
   "source": [
    "파란색 점(A)과 하늘색 점(X)이 가깝고, 빨간색 점(B)과 분홍색 점(Y)이 가깝게 표현된 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-sperm",
   "metadata": {},
   "source": [
    "## 6-5. 사전학습된 Word Embedding에 WEAT 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indie-heather",
   "metadata": {},
   "source": [
    "지금까지 WEAT가 어떻게 계산되는지 확인해보았습니다. 이제 실제 pretrain된 임베딩 모델을 이용하여 계산해볼까요?\n",
    "\n",
    "구글에서 학습한 모델을 사용해보도록 하겠습니다.\n",
    "\n",
    "우선 ~/aiffel/weat 폴더를 만들고 링크를 걸어 줍니다. 압축을 풀면 대략 3G 정도 됩니다. (아래 링크에서 다운받아 로컬에서도 확인해볼수 있습니다.)\n",
    "\n",
    "[GoogleNews-vectors-negative300.bin.gz](https://drive.google.com/u/0/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM&export=download)\n",
    "\n",
    "```$ mkdir -p ~/aiffel/weat\n",
    "$ ln -s ~/data/* ~/aiffel/weat/\n",
    "$ cd ~/aiffel/weat\n",
    "$ ls -l```\n",
    "\n",
    "gensim 설치 후 다음 코드에서 data_dir 변수에 본인의 경로를 잘 설정해서 모델을 불러오도록 합니다.( 클라우드 사용자는 이미 설치가 되어있습니다.)\n",
    "\n",
    "`$ pip install gensim`\n",
    "\n",
    "> 💡 참고<br>\n",
    "w2v를 사용하다가 메모리 부족이 발생할 수 있습니다. 이때는 워드 임베딩 내 300만 개의 단어 중 자주 쓰는 단어 50만 개만 꺼내어 사용하도록 아래와 같이 limit 파라미터값을 주면 메모리 사용량을 크게 줄일 수 있습니다.\n",
    "\n",
    "`w2v = KeyedVectors.load_word2vec_format(model_dir, binary=True, limit=500000)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "nearby-xerox",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_dir = '~/aiffel/weat' \n",
    "model_dir = os.path.join(data_dir, 'GoogleNews-vectors-negative300.bin')\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# 50만개의 단어만 활용합니다. 메모리가 충분하다면 limit 파라미터값을 생략하여 300만개를 모두 활용할 수 있습니다. \n",
    "w2v = KeyedVectors.load_word2vec_format(model_dir, binary=True, limit=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "logical-baseball",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x7fcd41d475d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "configured-confirmation",
   "metadata": {},
   "source": [
    "w2v에 있는 단어 개수와 벡터 크기를 살펴볼까요?\n",
    "\n",
    "> 💡 참고<br>\n",
    "2021년 3월, Gensim이 4.0 으로 버전업되면서 KeyedVectors에 vocab dict가 제거되었습니다. 상세한 내용은 아래 링크를 참고해 주세요.\n",
    "\n",
    "- [Migrating from Gensim 3.x to 4](https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "prompt-contact",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500000\n",
      "300\n",
      "(500000, 300)\n"
     ]
    }
   ],
   "source": [
    "# print(len(w2v.vocab))   # Gensim 3.X 버전까지는 w2v.vocab을 직접 접근할 수 있습니다. \n",
    "print(len(w2v.index_to_key))   # Gensim 4.0부터는 index_to_key를 활용해 vocab size를 알 수 있습니다. \n",
    "print(len(w2v['I']))                    # 혹은 단어를 key로 직접 vector를 얻을 수 있습니다. \n",
    "print(w2v.vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "musical-conservative",
   "metadata": {},
   "source": [
    "w2v에는 limit으로 지정한 갯수(디폴트는 3,000,000개)의 단어가 있고, 각 단어는 300차원을 갖는다는 것을 알 수 있습니다.\n",
    "\n",
    "'happy'라는 단어의 벡터를 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "english-socket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.18798828e-04,  1.60156250e-01,  1.60980225e-03,  2.53906250e-02,\n",
       "        9.91210938e-02, -8.59375000e-02,  3.24218750e-01, -2.17285156e-02,\n",
       "        1.34765625e-01,  1.10351562e-01, -1.04980469e-01, -2.90527344e-02,\n",
       "       -2.38037109e-02, -4.02832031e-02, -3.68652344e-02,  2.32421875e-01,\n",
       "        3.20312500e-01,  1.01074219e-01,  5.83496094e-02, -2.91824341e-04,\n",
       "       -3.29589844e-02,  2.11914062e-01,  4.32128906e-02, -8.59375000e-02,\n",
       "        2.81250000e-01, -1.78222656e-02,  3.79943848e-03, -1.71875000e-01,\n",
       "        2.06054688e-01, -1.85546875e-01,  3.73535156e-02, -1.21459961e-02,\n",
       "        2.04101562e-01, -3.80859375e-02,  3.61328125e-02, -8.15429688e-02,\n",
       "        8.44726562e-02,  9.37500000e-02,  1.44531250e-01,  7.42187500e-02,\n",
       "        2.51953125e-01, -7.91015625e-02,  8.69140625e-02,  1.58691406e-02,\n",
       "        1.09375000e-01, -2.23632812e-01, -5.15747070e-03,  1.68945312e-01,\n",
       "       -1.36718750e-01, -2.51464844e-02, -3.85742188e-02, -1.33056641e-02,\n",
       "        1.38671875e-01,  1.76757812e-01,  1.10351562e-01,  1.51367188e-01,\n",
       "        7.86132812e-02, -1.69921875e-01,  1.20605469e-01, -4.37500000e-01,\n",
       "       -4.32128906e-02,  1.34765625e-01, -3.45703125e-01,  9.13085938e-02,\n",
       "        4.71191406e-02,  9.66796875e-02, -1.61132812e-02, -4.71191406e-02,\n",
       "       -4.68750000e-02,  1.37695312e-01,  9.96093750e-02,  4.49218750e-02,\n",
       "       -2.49023438e-02,  1.58203125e-01, -3.57421875e-01, -1.21093750e-01,\n",
       "        1.15722656e-01,  9.08203125e-02,  1.40625000e-01,  1.60156250e-01,\n",
       "       -4.42504883e-03,  5.34667969e-02,  2.28515625e-01,  1.88476562e-01,\n",
       "       -3.88183594e-02, -2.53906250e-01, -1.74804688e-01,  9.81445312e-02,\n",
       "        1.08642578e-02,  1.41601562e-01,  7.81250000e-03,  1.36718750e-01,\n",
       "       -2.08007812e-01, -3.41796875e-02, -2.50000000e-01,  1.25976562e-01,\n",
       "        1.57226562e-01,  3.31115723e-03, -1.51367188e-01, -6.98242188e-02,\n",
       "       -1.40625000e-01,  2.06054688e-01, -3.54003906e-02,  1.57226562e-01,\n",
       "        5.83496094e-02, -3.58886719e-02,  2.12890625e-01, -1.13769531e-01,\n",
       "        1.41601562e-01, -1.29394531e-02,  9.13085938e-02, -3.95507812e-02,\n",
       "        9.76562500e-02, -2.69775391e-02,  1.30004883e-02, -1.30859375e-01,\n",
       "        3.32031250e-01, -3.53515625e-01, -5.44433594e-02, -2.50244141e-02,\n",
       "       -1.42578125e-01,  6.49414062e-02,  5.54199219e-02, -4.83398438e-02,\n",
       "       -1.12304688e-01, -1.32812500e-01, -6.73828125e-02, -1.41601562e-01,\n",
       "       -2.05078125e-01, -1.29882812e-01, -1.04003906e-01, -8.10546875e-02,\n",
       "       -1.67968750e-01,  1.63085938e-01, -1.13769531e-01, -5.17578125e-02,\n",
       "        7.61718750e-02,  3.59375000e-01,  1.04003906e-01,  3.59375000e-01,\n",
       "       -8.74023438e-02,  6.54296875e-02, -1.09863281e-02, -1.88476562e-01,\n",
       "       -6.59179688e-02,  2.30468750e-01, -2.96875000e-01,  6.59179688e-03,\n",
       "        1.49414062e-01, -1.73828125e-01,  1.31835938e-01,  2.36328125e-01,\n",
       "       -9.22851562e-02,  1.70898438e-01, -1.70898438e-02,  3.12500000e-02,\n",
       "       -3.37219238e-03,  9.66796875e-02, -2.61718750e-01, -1.84326172e-02,\n",
       "       -1.85546875e-01,  1.24023438e-01,  3.00781250e-01,  2.43164062e-01,\n",
       "        3.06640625e-01, -3.28125000e-01, -5.05371094e-02,  1.01562500e-01,\n",
       "        7.86132812e-02, -1.44531250e-01, -1.25976562e-01, -2.41699219e-02,\n",
       "        2.94921875e-01, -1.50390625e-01, -3.97949219e-02,  2.75390625e-01,\n",
       "        1.26953125e-01, -9.86328125e-02, -1.39648438e-01,  2.52685547e-02,\n",
       "       -8.54492188e-02, -1.72119141e-02,  9.17968750e-02,  1.39648438e-01,\n",
       "       -2.39257812e-01, -2.11914062e-01, -2.21679688e-01,  1.53320312e-01,\n",
       "       -1.58691406e-02, -2.00195312e-01, -2.07519531e-02,  3.58886719e-02,\n",
       "       -6.96629286e-07, -2.13867188e-01,  2.00195312e-01, -1.09375000e-01,\n",
       "       -5.15136719e-02,  6.22558594e-02, -3.22265625e-01, -7.86132812e-02,\n",
       "        5.02929688e-02,  7.08007812e-02,  1.20117188e-01, -1.79687500e-01,\n",
       "        1.59179688e-01, -1.02233887e-03, -3.49609375e-01,  1.25000000e-01,\n",
       "        6.44531250e-02,  8.10546875e-02, -3.39355469e-02,  7.42187500e-02,\n",
       "       -3.08837891e-02, -1.38671875e-01, -3.19824219e-02,  1.99218750e-01,\n",
       "        1.25000000e-01,  5.68847656e-02, -1.67968750e-01,  1.30859375e-01,\n",
       "        2.90527344e-02, -1.49536133e-02, -1.39648438e-01,  4.07714844e-02,\n",
       "       -1.05590820e-02, -1.74804688e-01,  2.12890625e-01, -1.41601562e-01,\n",
       "        2.30712891e-02, -3.36914062e-02, -8.78906250e-02, -6.64062500e-02,\n",
       "       -6.93359375e-02, -7.42187500e-02,  7.03125000e-02, -2.01416016e-02,\n",
       "       -1.26953125e-01, -3.63769531e-02,  5.93261719e-02,  1.18164062e-01,\n",
       "       -6.34765625e-03, -7.42187500e-02,  3.19824219e-02,  6.68945312e-02,\n",
       "       -2.27539062e-01,  6.54296875e-02,  1.79443359e-02,  1.46484375e-01,\n",
       "       -5.49316406e-02, -1.15234375e-01, -2.16796875e-01,  8.74023438e-02,\n",
       "        2.61718750e-01,  1.54296875e-01,  6.71386719e-03, -2.78320312e-02,\n",
       "       -4.15039062e-03, -2.09960938e-02, -5.51757812e-02, -9.76562500e-03,\n",
       "       -1.29882812e-01,  1.31835938e-01, -8.42285156e-03,  2.29492188e-01,\n",
       "        1.78710938e-01,  1.94335938e-01,  4.68750000e-02,  2.18505859e-02,\n",
       "       -2.75878906e-02,  1.73828125e-01,  1.33789062e-01,  1.36718750e-01,\n",
       "        3.10546875e-01,  9.39941406e-03,  9.22851562e-02, -2.44140625e-01,\n",
       "       -5.10253906e-02,  7.81250000e-02, -1.43554688e-01,  9.17968750e-02,\n",
       "        2.96630859e-02,  9.46044922e-03, -2.04101562e-01,  1.60156250e-01,\n",
       "        1.43554688e-01, -2.02636719e-02,  2.13623047e-02, -6.98242188e-02,\n",
       "       -3.11279297e-03, -2.52685547e-02, -1.09863281e-01,  1.07910156e-01,\n",
       "       -7.03125000e-02, -1.27929688e-01, -5.07812500e-02,  4.27246094e-02,\n",
       "       -7.32421875e-02, -3.54003906e-02,  8.88671875e-02, -3.02734375e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v['happy']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-atmosphere",
   "metadata": {},
   "source": [
    "'happy'와 가장 유사한 단어를 보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "reduced-annex",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('glad', 0.7408890724182129),\n",
       " ('pleased', 0.6632170677185059),\n",
       " ('ecstatic', 0.6626912355422974),\n",
       " ('overjoyed', 0.6599286794662476),\n",
       " ('thrilled', 0.6514049172401428),\n",
       " ('satisfied', 0.6437949538230896),\n",
       " ('proud', 0.636042058467865),\n",
       " ('delighted', 0.627237856388092),\n",
       " ('disappointed', 0.6269949674606323),\n",
       " ('excited', 0.6247665286064148)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.most_similar(positive=['happy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerical-administration",
   "metadata": {},
   "source": [
    "다른 단어들도 살펴보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "convertible-photograph",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('relatives', 0.6662653088569641),\n",
       " ('familiy', 0.6517067551612854),\n",
       " ('families', 0.6252894997596741),\n",
       " ('siblings', 0.6140849590301514),\n",
       " ('friends', 0.6128394603729248),\n",
       " ('mother', 0.6065612435340881),\n",
       " ('aunt', 0.5811319947242737),\n",
       " ('grandparents', 0.5762072205543518),\n",
       " ('father', 0.5717043876647949),\n",
       " ('Family', 0.5672314763069153)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.most_similar(positive=['family'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impaired-decision",
   "metadata": {},
   "source": [
    "오타로 추정되는 몇몇 단어도 보입니다. 이 단어들도 데이터 자체에 자주 나왔기 때문에 단어 셋에 포함되었다고 생각할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "gorgeous-hundred",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('elementary', 0.7868632078170776),\n",
       " ('schools', 0.7411909103393555),\n",
       " ('elementary_schools', 0.6597153544425964),\n",
       " ('kindergarten', 0.6529811024665833),\n",
       " ('eighth_grade', 0.6488089561462402),\n",
       " ('School', 0.6477997303009033),\n",
       " ('teacher', 0.63824063539505),\n",
       " ('students', 0.6301522850990295),\n",
       " ('classroom', 0.6281620264053345),\n",
       " ('Schools', 0.6172096133232117)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.most_similar(positive=['school'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alien-perry",
   "metadata": {},
   "source": [
    "어떤가요? 이 모델이 단어의 의미를 담은 벡터로 변환이 잘 되었다고 생각하나요?\n",
    "\n",
    "이제 WEAT를 통해 이 모델의 편향성을 확인해보도록 하겠습니다. 논문에 있던 단어 셋으로 구성해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "talented-analysis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2624874"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_X = ['science', 'technology', 'physics', 'chemistry', 'Einstein', 'NASA', 'experiment', 'astronomy']\n",
    "target_Y = ['poetry', 'art', 'Shakespeare', 'dance', 'literature', 'novel', 'symphony', 'drama']\n",
    "attribute_A = ['brother', 'father', 'uncle', 'grandfather', 'son', 'he', 'his', 'him']\n",
    "attribute_B = ['sister', 'mother', 'aunt', 'grandmother', 'daughter', 'she', 'hers', 'her']\n",
    "\n",
    "X = np.array([w2v[word] for word in target_X])\n",
    "Y = np.array([w2v[word] for word in target_Y])\n",
    "A = np.array([w2v[word] for word in attribute_A])\n",
    "B = np.array([w2v[word] for word in attribute_B])\n",
    "\n",
    "weat_score(X, Y, A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-scheme",
   "metadata": {},
   "source": [
    "과학과 관련된 단어가 남성과 관련된 단어와 가깝고, 예술과 관련된 단어가 여성과 관련된 단어와 가깝게 나타났습니다. 사람의 편향성을 실험하는 IAT에서도 이와 같게 나타났었죠? 많은 사람이 가진 편향이 임베딩 모델에 반영되었다고 볼 수 있습니다.\n",
    "\n",
    "이제 다른 셋을 구성해볼까요? target_X는 인스턴트 식품들로 단어를 구성하였고 target_Y는 그 반대로 구성했습니다. attribute_A는 인스턴트를 의미하는 단어들로, attributes_B는 그 반대로 구성했습니다.\n",
    "\n",
    "이 단어 셋들을 보면 target_X는 attribute_A와 attribute_B 중 어떤 것과 가깝다고 생각하시나요?\n",
    "보통 target_X와 attribute_A가 가깝고, traget_Y는 attribute_B와 가깝다고 대답할 것입니다.\n",
    "임베딩 모델도 그렇게 생각할까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "suspended-marshall",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6909266"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_X = ['pizza', 'coke', 'hamburger', 'ham', 'ramen', 'icecream', 'candy']\n",
    "target_Y = ['salad', 'fruit', 'vegetable', 'herb', 'root', 'greens', 'wholesome']\n",
    "attribute_A = ['junk', 'canned', 'convenience', 'frozen', 'fast']\n",
    "attribute_B = ['health', 'beneficial', 'good', 'nourishing', 'nutritious']\n",
    "\n",
    "X = np.array([w2v[word] for word in target_X])\n",
    "Y = np.array([w2v[word] for word in target_Y])\n",
    "A = np.array([w2v[word] for word in attribute_A])\n",
    "B = np.array([w2v[word] for word in attribute_B])\n",
    "\n",
    "weat_score(X, Y, A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exciting-messaging",
   "metadata": {},
   "source": [
    "모델도 우리의 예상과 맞는 방향으로 상당히 높은 수치를 보이는 것을 확인했습니다. 인스턴트 식품의 예시와 인스턴트를 의미하는 단어가 가까운 것은 당연합니다. 이 경우 모델이 편향되어있다기보다 단어의 의미를 잘 파악했다고 볼 수 있습니다.\n",
    "\n",
    "동일한 target 셋에 다른 attribute 셋을 만들볼까요? attribute_A에는 책과 관련된 단어로 구성하고, attribute_B는 뉴스와 관련된 단어로 구성했습니다. 이번에는 어떤 결과를 가져올까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "willing-classic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.05137869"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_X = ['pizza', 'coke', 'hamburger', 'ham', 'ramen', 'icecream', 'candy']\n",
    "target_Y = ['salad', 'fruit', 'vegetable', 'herb', 'root', 'greens', 'wholesome']\n",
    "attribute_A = ['book', 'essay', 'dictionary', 'magazine', 'novel']\n",
    "attribute_B = ['news', 'report', 'statement', 'broadcast', 'word']\n",
    "\n",
    "X = np.array([w2v[word] for word in target_X])\n",
    "Y = np.array([w2v[word] for word in target_Y])\n",
    "A = np.array([w2v[word] for word in attribute_A])\n",
    "B = np.array([w2v[word] for word in attribute_B])\n",
    "\n",
    "weat_score(X, Y, A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limited-canadian",
   "metadata": {},
   "source": [
    "0에 굉장히 가까운 결과를 보였습니다. 즉, 임베딩 모델이 판단하기에 어느 것끼리 가깝다고 말할 수 없는 것이지요.\n",
    "\n",
    "여러분이 target, attribute 셋을 만들어서 WEAT score를 구해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fixed-meeting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33343452"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_X = ['pizza', 'coke', 'hamburger', 'ham', 'ramen', 'icecream', 'candy']\n",
    "target_Y = ['salad', 'fruit', 'vegetable', 'herb', 'root', 'greens', 'wholesome']\n",
    "attribute_A = ['brother', 'father', 'uncle', 'grandfather', 'son', 'he', 'his', 'him']\n",
    "attribute_B = ['sister', 'mother', 'aunt', 'grandmother', 'daughter', 'she', 'hers', 'her']\n",
    "\n",
    "X = np.array([w2v[word] for word in target_X])\n",
    "Y = np.array([w2v[word] for word in target_Y])\n",
    "A = np.array([w2v[word] for word in attribute_A])\n",
    "B = np.array([w2v[word] for word in attribute_B])\n",
    "\n",
    "weat_score(X, Y, A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "weighted-kinase",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제 완료\n"
     ]
    }
   ],
   "source": [
    "#메모리를 다시 비워줍시다.\n",
    "del w2v\n",
    "print(\"삭제 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-maximum",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
