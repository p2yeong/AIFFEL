{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "asian-angola",
   "metadata": {},
   "source": [
    "# Seq2seq으로 한영 번역기 만들기(Kor2Eng)\n",
    "\n",
    "- 한국어 문장을 입력하면 영어로 번역된 문장을 출력하는 번역기를 만들어 봅니다.\n",
    "- Sequence-to-Sequence 구조는 두 개의 RNN 모듈을 Encoder-Decoder 구조로 결합하여 사용하는 구조로 번역기에 최적화 되어 있습니다.\n",
    "- 이번 프로젝트에서는 Seq2seq 기반 번역기를 직접 만들어보며 그 구조를 이해해보고 또한 Attention 기법을 추가하여 성능을 높여 볼 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alone-recall",
   "metadata": {},
   "source": [
    "한국어를 잘 시각화 하기 위해서 한국어 폰트를 다운로드 합니다.\n",
    "- 설치후 LMS를 재실행해야 설치된 글꼴이 제대로 보입니다\n",
    "- matplotlib 라이브러리의 기본 폰트는 한국어를 지원하지 않습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "purple-stationery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fonts-nanum is already the newest version (20170925-1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!sudo apt -qq -y install fonts-nanum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "egyptian-citizenship",
   "metadata": {},
   "source": [
    "사용할 라이브러리들을 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "geological-jewel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "%config InlineBackend.figure_format = 'retina'\n",
    " \n",
    "import matplotlib.font_manager as fm\n",
    "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
    "font = fm.FontProperties(fname=fontpath, size=9)\n",
    "plt.rc('font', family='NanumBarunGothic') \n",
    "mpl.font_manager._rebuild()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ruled-breath",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import io\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspended-bandwidth",
   "metadata": {},
   "source": [
    "## 데이터 준비\n",
    "[jungyeul/korean-parallel-corpora](https://github.com/jungyeul/korean-parallel-corpora/tree/master/korean-english-news-v1)\n",
    "\n",
    "한영 병렬 데이터 korean-english-park.train.tar.gz를 다운받습니다.\n",
    "- 94123개의 한국어-영어 paired data가 존재합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "herbal-chambers",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://raw.githubusercontent.com/jungyeul/korean-parallel-corpora/master/korean-english-news-v1/korean-english-park.train.tar.gz\n",
      "8724480/8718893 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "cache_dir = '~/aiffel/going_deeper/gd8'\n",
    "path_to_zip = tf.keras.utils.get_file(\n",
    "    'korean-english-park.train.tar.gz',\n",
    "    origin = 'https://raw.githubusercontent.com/jungyeul/korean-parallel-corpora/master/korean-english-news-v1/korean-english-park.train.tar.gz',\n",
    "    cache_dir = cache_dir,\n",
    "    extract=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "moving-exclusive",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_en = os.path.dirname(path_to_zip)+\"/korean-english-park.train.en\"\n",
    "path_to_ko = os.path.dirname(path_to_zip)+\"/korean-english-park.train.ko\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "italic-multimedia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Size: ko_94123, en_94123\n",
      "Example:\n",
      ">>\n",
      " 개인용 컴퓨터 사용의 상당 부분은 \"이것보다 뛰어날 수 있느냐?\" \n",
      " Much of personal computing is about \"can you top this?\"\n",
      ">>\n",
      " 모든 광마우스와 마찬가지 로 이 광마우스도 책상 위에 놓는 마우스 패드를 필요로 하지 않는다. \n",
      " so a mention a few weeks ago about a rechargeable wireless optical mouse brought in another rechargeable, wireless mouse.\n",
      ">>\n",
      " 그러나 이것은 또한 책상도 필요로 하지 않는다. \n",
      " Like all optical mice, But it also doesn't need a desk.\n",
      ">>\n",
      " 79.95달러하는 이 최첨단 무선 광마우스는 허공에서 팔목, 팔, 그외에 어떤 부분이든 그 움직임에따라 커서의 움직임을 조절하는 회전 운동 센서를 사용하고 있다. \n",
      " uses gyroscopic sensors to control the cursor movement as you move your wrist, arm, whatever through the air.\n",
      ">>\n",
      " 정보 관리들은 동남 아시아에서의 선박들에 대한 많은 (테러) 계획들이 실패로 돌아갔음을 밝혔으며, 세계 해상 교역량의 거의 3분의 1을 운송하는 좁은 해로인 말라카 해협이 테러 공격을 당하기 쉽다고 경고하고 있다. \n",
      " Intelligence officials have revealed a spate of foiled plots on ships in Southeast Asia and are warning that a narrow stretch of water carrying almost one third of the world's maritime trade is vulnerable to a terror attack.\n"
     ]
    }
   ],
   "source": [
    "with open(path_to_ko, \"r\") as f:\n",
    "    raw_ko=f.read().splitlines()\n",
    "with open(path_to_en, \"r\") as f:\n",
    "    raw_en=f.read().splitlines()\n",
    "    \n",
    "print(f\"Data Size: ko_{len(raw_ko)}, en_{len(raw_en)}\")\n",
    "print(\"Example:\")\n",
    "\n",
    "for sen_ko, sen_en in list(zip(raw_ko, raw_en))[:5]:\n",
    "    print(\">>\\n\",sen_ko, \"\\n\",sen_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polish-spare",
   "metadata": {},
   "source": [
    "## 데이터 정제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "light-lending",
   "metadata": {},
   "source": [
    "### 중복데이터 제거\n",
    "\n",
    "set 데이터형이 중복을 허용하지 않는다는 것을 활용해 중복된 데이터를 제거하도록 합니다. 데이터의 병렬 쌍이 흐트러지지 않도록 주의해야 합니다.중복을 제거한 데이터를 cleaned_corpus 에 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ancient-classics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78968"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_corpus = list(set(zip(raw_ko, raw_en)))\n",
    "len(cleaned_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "elementary-ending",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('미 캘리포니아 글렌데일에 거주하는 라보프는 오는 11월 28일 쿡카운티 지방 법원에 출석해야 한다.',\n",
       "  'LaBeouf, of Glendale, California, is scheduled to appear in Cook County court on November 28.'),\n",
       " ('일본에서 16일(현지시각) 기상관측 이래 최고 기온이 기록돼 폭염으로 7명이 목숨을 잃었다.',\n",
       "  'TOKYO, Japan (CNN) Temperatures hit record highs in Japan on Thursday as a heat wave swept through the country, leaving at least seven people dead over the last few days.'),\n",
       " ('미국은 2만1천5백 여명의 미군을 이라크에 더 보낼 예정이라고 발표한 바 있다.',\n",
       "  'Bush recently announced plans to send 21,500 more US troops to Iraq.')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_corpus[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "australian-banana",
   "metadata": {},
   "source": [
    "### 데이터 전처리: 정제하기\n",
    "- 불필요한 노이즈로 작용할 수 있는 특수문자는 정제과정에서 제거합니다.\n",
    "- 전처리 과정에서 문장의 시작문자 , 종료문자 를 붙여줍니다. Decoder는 첫 입력으로 사용할 시작 토큰과 문장생성 종료를 알리는 끝 토큰이 반드시 필요하기 때문에 Decoder에게 필수적인 작업입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "separated-princess",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence, s_token=False, e_token=False):\n",
    "    \n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence) #단어와 구두점 사이의 공백 추가\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 공백 여러개 하나의 공백으로 치환\n",
    "    sentence = re.sub(r\"[^ㄱ-ㅎㅏ-ㅣ가-힣a-zA-Z0-9?.!,]+\", \" \", sentence) #a-zA-Z?.!, 제외한 문자 제거\n",
    "    \n",
    "    sentence = sentence.strip() # 양 끝 공백 제거\n",
    "    \n",
    "    if s_token:\n",
    "        sentence = '<start> ' + sentence\n",
    "\n",
    "    if e_token:\n",
    "        sentence += ' <end>'\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "annoying-profile",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국어: 그들은 자신들의 요구조건이 수용되지 않을 경우 인질을 추가 살해하겠다고 경고하기도 했다 .\n",
      "영어: <start> The Taliban killed two male hostages and have long said they would kill others unless their demands were met . <end>\n"
     ]
    }
   ],
   "source": [
    "enc_corpus = []\n",
    "dec_corpus = []\n",
    "\n",
    "for pair in cleaned_corpus:\n",
    "    ko, en = pair\n",
    "    \n",
    "    enc_corpus.append(preprocess_sentence(ko))\n",
    "    dec_corpus.append(preprocess_sentence(en, s_token=True, e_token=True))\n",
    "\n",
    "print(\"한국어:\", enc_corpus[20])\n",
    "print(\"영어:\", dec_corpus[20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assisted-denver",
   "metadata": {},
   "source": [
    "### 데이터 전처리: 토큰화\n",
    "- 한글 토큰화는 KoNLPy의 mecab 클래스를 사용합니다.\n",
    "- 모든 데이터를 사용할 경우 학습에 굉장히 오랜 시간이 걸립니다. cleaned_corpus로부터 토큰의 길이가 40 이하인 데이터를 선별하여 eng_corpus와 kor_corpus를 구축합니다.\n",
    "- tokenize() 함수를 사용해 데이터를 텐서로 변환하고 각각의 tokenizer를 얻습니다. 단어의 수는 실험을 통해 적당한 값을 맞춰주도록 합니다! (최소 10,000 이상)\n",
    "- 난이도에 비해 데이터가 많지 않아 훈련 데이터와 검증 데이터를 따로 나누지는 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "polyphonic-management",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "curl is already the newest version (7.58.0-2ubuntu3.13).\n",
      "g++ is already the newest version (4:7.4.0-1ubuntu2.3).\n",
      "openjdk-8-jdk is already the newest version (8u282-b08-0ubuntu1~18.04).\n",
      "The following additional packages will be installed:\n",
      "  dh-python libexpat1-dev libpython3-dev libpython3.6-dev python-pip-whl\n",
      "  python3-asn1crypto python3-cffi-backend python3-crypto python3-cryptography\n",
      "  python3-distutils python3-keyring python3-keyrings.alt python3-lib2to3\n",
      "  python3-secretstorage python3-setuptools python3-wheel python3-xdg\n",
      "  python3.6-dev\n",
      "Suggested packages:\n",
      "  python-crypto-doc python-cryptography-doc python3-cryptography-vectors\n",
      "  gnome-keyring libkf5wallet-bin gir1.2-gnomekeyring-1.0\n",
      "  python-secretstorage-doc python-setuptools-doc\n",
      "The following NEW packages will be installed:\n",
      "  dh-python libexpat1-dev libpython3-dev libpython3.6-dev python-pip-whl\n",
      "  python3-asn1crypto python3-cffi-backend python3-crypto python3-cryptography\n",
      "  python3-dev python3-distutils python3-keyring python3-keyrings.alt\n",
      "  python3-lib2to3 python3-pip python3-secretstorage python3-setuptools\n",
      "  python3-wheel python3-xdg python3.6-dev\n",
      "0 upgraded, 20 newly installed, 0 to remove and 0 not upgraded.\n",
      "Need to get 48.6 MB of archives.\n",
      "After this operation, 89.5 MB of additional disk space will be used.\n",
      "Do you want to continue? [Y/n] ^C\n",
      "Requirement already satisfied: pip in /opt/conda/lib/python3.7/site-packages (20.3.3)\n",
      "Collecting pip\n",
      "  Downloading pip-21.3-py3-none-any.whl (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 8.0 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 20.3.3\n",
      "    Uninstalling pip-20.3.3:\n",
      "      Successfully uninstalled pip-20.3.3\n",
      "Successfully installed pip-21.3\n",
      "Requirement already satisfied: konlpy in /opt/conda/lib/python3.7/site-packages (0.5.2)\n",
      "Requirement already satisfied: tweepy>=3.7.0 in /opt/conda/lib/python3.7/site-packages (from konlpy) (3.10.0)\n",
      "Requirement already satisfied: beautifulsoup4==4.6.0 in /opt/conda/lib/python3.7/site-packages (from konlpy) (4.6.0)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.7/site-packages (from konlpy) (0.4.4)\n",
      "Requirement already satisfied: lxml>=4.1.0 in /opt/conda/lib/python3.7/site-packages (from konlpy) (4.6.2)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from konlpy) (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.6 in /opt/conda/lib/python3.7/site-packages (from konlpy) (1.19.5)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
      "Requirement already satisfied: requests[socks]>=2.11.1 in /opt/conda/lib/python3.7/site-packages (from tweepy>=3.7.0->konlpy) (2.25.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.26.2)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "curl is already the newest version (7.58.0-2ubuntu3.13).\n",
      "git is already the newest version (1:2.17.1-1ubuntu0.8).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n",
      "Installing automake (A dependency for mecab-ko)\n",
      "Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
      "Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease                        \n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
      "Get:4 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,372 kB]\n",
      "Get:5 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [614 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]   \n",
      "Get:7 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,433 kB]\n",
      "Get:8 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [26.7 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,808 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [647 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [34.4 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,211 kB]\n",
      "Fetched 10.4 MB in 2s (5,274 kB/s)                      \n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  autoconf autotools-dev libsigsegv2 m4\n",
      "Suggested packages:\n",
      "  autoconf-archive gnu-standards autoconf-doc libtool gettext m4-doc\n",
      "The following NEW packages will be installed:\n",
      "  autoconf automake autotools-dev libsigsegv2 m4\n",
      "0 upgraded, 5 newly installed, 0 to remove and 93 not upgraded.\n",
      "Need to get 1,082 kB of archives.\n",
      "After this operation, 3,994 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsigsegv2 amd64 2.12-1 [14.7 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 m4 amd64 1.4.18-1 [197 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 autoconf all 2.69-11 [322 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 autotools-dev all 20180224.1 [39.6 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 automake all 1:1.15.1-3ubuntu2 [509 kB]\n",
      "Fetched 1,082 kB in 1s (1,057 kB/s)\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 5.)\n",
      "debconf: falling back to frontend: Readline\n",
      "Selecting previously unselected package libsigsegv2:amd64.\n",
      "(Reading database ... 72960 files and directories currently installed.)\n",
      "Preparing to unpack .../libsigsegv2_2.12-1_amd64.deb ...\n",
      "Unpacking libsigsegv2:amd64 (2.12-1) ...\n",
      "Selecting previously unselected package m4.\n",
      "Preparing to unpack .../archives/m4_1.4.18-1_amd64.deb ...\n",
      "Unpacking m4 (1.4.18-1) ...\n",
      "Selecting previously unselected package autoconf.\n",
      "Preparing to unpack .../autoconf_2.69-11_all.deb ...\n",
      "Unpacking autoconf (2.69-11) ...\n",
      "Selecting previously unselected package autotools-dev.\n",
      "Preparing to unpack .../autotools-dev_20180224.1_all.deb ...\n",
      "Unpacking autotools-dev (20180224.1) ...\n",
      "Selecting previously unselected package automake.\n",
      "Preparing to unpack .../automake_1%3a1.15.1-3ubuntu2_all.deb ...\n",
      "Unpacking automake (1:1.15.1-3ubuntu2) ...\n",
      "Setting up libsigsegv2:amd64 (2.12-1) ...\n",
      "Setting up m4 (1.4.18-1) ...\n",
      "Setting up autotools-dev (20180224.1) ...\n",
      "Setting up autoconf (2.69-11) ...\n",
      "Setting up automake (1:1.15.1-3ubuntu2) ...\n",
      "update-alternatives: using /usr/bin/automake-1.15 to provide /usr/bin/automake (automake) in auto mode\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/automake.1.gz because associated file /usr/share/man/man1/automake-1.15.1.gz (of link group automake) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/aclocal.1.gz because associated file /usr/share/man/man1/aclocal-1.15.1.gz (of link group automake) doesn't exist\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1.4) ...\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
      "Install mecab-ko-dic\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 1381k  100 1381k    0     0  1771k      0 --:--:-- --:--:-- --:--:--  101M\n",
      "mecab-0.996-ko-0.9.2/\n",
      "mecab-0.996-ko-0.9.2/example/\n",
      "mecab-0.996-ko-0.9.2/example/example.cpp\n",
      "mecab-0.996-ko-0.9.2/example/example_lattice.cpp\n",
      "mecab-0.996-ko-0.9.2/example/example_lattice.c\n",
      "mecab-0.996-ko-0.9.2/example/example.c\n",
      "mecab-0.996-ko-0.9.2/example/thread_test.cpp\n",
      "mecab-0.996-ko-0.9.2/mecab-config.in\n",
      "mecab-0.996-ko-0.9.2/man/\n",
      "mecab-0.996-ko-0.9.2/man/Makefile.am\n",
      "mecab-0.996-ko-0.9.2/man/mecab.1\n",
      "mecab-0.996-ko-0.9.2/man/Makefile.in\n",
      "mecab-0.996-ko-0.9.2/mecab.iss.in\n",
      "mecab-0.996-ko-0.9.2/config.guess\n",
      "mecab-0.996-ko-0.9.2/README\n",
      "mecab-0.996-ko-0.9.2/COPYING\n",
      "mecab-0.996-ko-0.9.2/CHANGES.md\n",
      "mecab-0.996-ko-0.9.2/README.md\n",
      "mecab-0.996-ko-0.9.2/INSTALL\n",
      "mecab-0.996-ko-0.9.2/config.sub\n",
      "mecab-0.996-ko-0.9.2/configure.in\n",
      "mecab-0.996-ko-0.9.2/swig/\n",
      "mecab-0.996-ko-0.9.2/swig/Makefile\n",
      "mecab-0.996-ko-0.9.2/swig/version.h.in\n",
      "mecab-0.996-ko-0.9.2/swig/version.h\n",
      "mecab-0.996-ko-0.9.2/swig/MeCab.i\n",
      "mecab-0.996-ko-0.9.2/aclocal.m4\n",
      "mecab-0.996-ko-0.9.2/LGPL\n",
      "mecab-0.996-ko-0.9.2/Makefile.am\n",
      "mecab-0.996-ko-0.9.2/configure\n",
      "mecab-0.996-ko-0.9.2/tests/\n",
      "mecab-0.996-ko-0.9.2/tests/autolink/\n",
      "mecab-0.996-ko-0.9.2/tests/autolink/unk.def\n",
      "mecab-0.996-ko-0.9.2/tests/autolink/dicrc\n",
      "mecab-0.996-ko-0.9.2/tests/autolink/dic.csv\n",
      "mecab-0.996-ko-0.9.2/tests/autolink/test\n",
      "mecab-0.996-ko-0.9.2/tests/autolink/char.def\n",
      "mecab-0.996-ko-0.9.2/tests/autolink/matrix.def\n",
      "mecab-0.996-ko-0.9.2/tests/autolink/test.gld\n",
      "mecab-0.996-ko-0.9.2/tests/t9/\n",
      "mecab-0.996-ko-0.9.2/tests/t9/unk.def\n",
      "mecab-0.996-ko-0.9.2/tests/t9/ipadic.pl\n",
      "mecab-0.996-ko-0.9.2/tests/t9/dicrc\n",
      "mecab-0.996-ko-0.9.2/tests/t9/dic.csv\n",
      "mecab-0.996-ko-0.9.2/tests/t9/test\n",
      "mecab-0.996-ko-0.9.2/tests/t9/char.def\n",
      "mecab-0.996-ko-0.9.2/tests/t9/matrix.def\n",
      "mecab-0.996-ko-0.9.2/tests/t9/mkdic.pl\n",
      "mecab-0.996-ko-0.9.2/tests/t9/test.gld\n",
      "mecab-0.996-ko-0.9.2/tests/cost-train/\n",
      "mecab-0.996-ko-0.9.2/tests/cost-train/ipa.train\n",
      "mecab-0.996-ko-0.9.2/tests/cost-train/ipa.test\n",
      "mecab-0.996-ko-0.9.2/tests/cost-train/seed/\n",
      "mecab-0.996-ko-0.9.2/tests/cost-train/seed/rewrite.def\n",
      "mecab-0.996-ko-0.9.2/tests/cost-train/seed/feature.def\n",
      "mecab-0.996-ko-0.9.2/tests/cost-train/seed/unk.def\n",
      "mecab-0.996-ko-0.9.2/tests/cost-train/seed/dicrc\n",
      "mecab-0.996-ko-0.9.2/tests/cost-train/seed/dic.csv\n",
      "mecab-0.996-ko-0.9.2/tests/cost-train/seed/char.def\n",
      "mecab-0.996-ko-0.9.2/tests/cost-train/seed/matrix.def\n",
      "mecab-0.996-ko-0.9.2/tests/run-eval.sh\n",
      "mecab-0.996-ko-0.9.2/tests/run-cost-train.sh\n",
      "mecab-0.996-ko-0.9.2/tests/Makefile.am\n",
      "mecab-0.996-ko-0.9.2/tests/katakana/\n",
      "mecab-0.996-ko-0.9.2/tests/katakana/unk.def\n",
      "mecab-0.996-ko-0.9.2/tests/katakana/dicrc\n",
      "mecab-0.996-ko-0.9.2/tests/katakana/dic.csv\n",
      "mecab-0.996-ko-0.9.2/tests/katakana/test\n",
      "mecab-0.996-ko-0.9.2/tests/katakana/char.def\n",
      "mecab-0.996-ko-0.9.2/tests/katakana/matrix.def\n",
      "mecab-0.996-ko-0.9.2/tests/katakana/test.gld\n",
      "mecab-0.996-ko-0.9.2/tests/eval/\n",
      "mecab-0.996-ko-0.9.2/tests/eval/answer\n",
      "mecab-0.996-ko-0.9.2/tests/eval/system\n",
      "mecab-0.996-ko-0.9.2/tests/eval/test.gld\n",
      "mecab-0.996-ko-0.9.2/tests/shiin/\n",
      "mecab-0.996-ko-0.9.2/tests/shiin/unk.def\n",
      "mecab-0.996-ko-0.9.2/tests/shiin/dicrc\n",
      "mecab-0.996-ko-0.9.2/tests/shiin/dic.csv\n",
      "mecab-0.996-ko-0.9.2/tests/shiin/test\n",
      "mecab-0.996-ko-0.9.2/tests/shiin/char.def\n",
      "mecab-0.996-ko-0.9.2/tests/shiin/matrix.def\n",
      "mecab-0.996-ko-0.9.2/tests/shiin/mkdic.pl\n",
      "mecab-0.996-ko-0.9.2/tests/shiin/test.gld\n",
      "mecab-0.996-ko-0.9.2/tests/latin/\n",
      "mecab-0.996-ko-0.9.2/tests/latin/unk.def\n",
      "mecab-0.996-ko-0.9.2/tests/latin/dicrc\n",
      "mecab-0.996-ko-0.9.2/tests/latin/dic.csv\n",
      "mecab-0.996-ko-0.9.2/tests/latin/test\n",
      "mecab-0.996-ko-0.9.2/tests/latin/char.def\n",
      "mecab-0.996-ko-0.9.2/tests/latin/matrix.def\n",
      "mecab-0.996-ko-0.9.2/tests/latin/test.gld\n",
      "mecab-0.996-ko-0.9.2/tests/chartype/\n",
      "mecab-0.996-ko-0.9.2/tests/chartype/unk.def\n",
      "mecab-0.996-ko-0.9.2/tests/chartype/dicrc\n",
      "mecab-0.996-ko-0.9.2/tests/chartype/dic.csv\n",
      "mecab-0.996-ko-0.9.2/tests/chartype/test\n",
      "mecab-0.996-ko-0.9.2/tests/chartype/char.def\n",
      "mecab-0.996-ko-0.9.2/tests/chartype/matrix.def\n",
      "mecab-0.996-ko-0.9.2/tests/chartype/test.gld\n",
      "mecab-0.996-ko-0.9.2/tests/run-dics.sh\n",
      "mecab-0.996-ko-0.9.2/tests/ngram/\n",
      "mecab-0.996-ko-0.9.2/tests/ngram/unk.def\n",
      "mecab-0.996-ko-0.9.2/tests/ngram/dicrc\n",
      "mecab-0.996-ko-0.9.2/tests/ngram/dic.csv\n",
      "mecab-0.996-ko-0.9.2/tests/ngram/test\n",
      "mecab-0.996-ko-0.9.2/tests/ngram/char.def\n",
      "mecab-0.996-ko-0.9.2/tests/ngram/matrix.def\n",
      "mecab-0.996-ko-0.9.2/tests/ngram/test.gld\n",
      "mecab-0.996-ko-0.9.2/tests/Makefile.in\n",
      "mecab-0.996-ko-0.9.2/ltmain.sh\n",
      "mecab-0.996-ko-0.9.2/config.rpath\n",
      "mecab-0.996-ko-0.9.2/config.h.in\n",
      "mecab-0.996-ko-0.9.2/mecabrc.in\n",
      "mecab-0.996-ko-0.9.2/GPL\n",
      "mecab-0.996-ko-0.9.2/Makefile.train\n",
      "mecab-0.996-ko-0.9.2/ChangeLog\n",
      "mecab-0.996-ko-0.9.2/install-sh\n",
      "mecab-0.996-ko-0.9.2/AUTHORS\n",
      "mecab-0.996-ko-0.9.2/doc/\n",
      "mecab-0.996-ko-0.9.2/doc/bindings.html\n",
      "mecab-0.996-ko-0.9.2/doc/posid.html\n",
      "mecab-0.996-ko-0.9.2/doc/unk.html\n",
      "mecab-0.996-ko-0.9.2/doc/learn.html\n",
      "mecab-0.996-ko-0.9.2/doc/format.html\n",
      "mecab-0.996-ko-0.9.2/doc/libmecab.html\n",
      "mecab-0.996-ko-0.9.2/doc/mecab.css\n",
      "mecab-0.996-ko-0.9.2/doc/feature.html\n",
      "mecab-0.996-ko-0.9.2/doc/Makefile.am\n",
      "mecab-0.996-ko-0.9.2/doc/soft.html\n",
      "mecab-0.996-ko-0.9.2/doc/en/\n",
      "mecab-0.996-ko-0.9.2/doc/en/bindings.html\n",
      "mecab-0.996-ko-0.9.2/doc/dic-detail.html\n",
      "mecab-0.996-ko-0.9.2/doc/flow.png\n",
      "mecab-0.996-ko-0.9.2/doc/mecab.html\n",
      "mecab-0.996-ko-0.9.2/doc/index.html\n",
      "mecab-0.996-ko-0.9.2/doc/result.png\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/tab_a.png\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/globals_eval.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Tagger-members.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/functions_vars.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/doxygen.css\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/tab_r.gif\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Lattice.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/functions.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Tagger.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/mecab_8h_source.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/tabs.css\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/nav_f.png\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/tab_b.png\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/globals.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/nav_h.png\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/tab_h.png\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Model.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/globals_func.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/closed.png\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/tab_l.gif\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__path__t-members.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/functions_func.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/globals_type.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Lattice-members.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__node__t.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/namespacemembers_func.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/tab_s.png\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__dictionary__info__t-members.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/namespacemembers_type.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Model-members.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__dictionary__info__t.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/namespaces.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/namespacemembers.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/namespaceMeCab.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__path__t.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/files.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__node__t-members.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/index.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/annotated.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/globals_defs.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/classes.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/mecab_8h-source.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/doxygen.png\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/tab_b.gif\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/bc_s.png\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/open.png\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/mecab_8h.html\n",
      "mecab-0.996-ko-0.9.2/doc/dic.html\n",
      "mecab-0.996-ko-0.9.2/doc/partial.html\n",
      "mecab-0.996-ko-0.9.2/doc/feature.png\n",
      "mecab-0.996-ko-0.9.2/doc/Makefile.in\n",
      "mecab-0.996-ko-0.9.2/missing\n",
      "mecab-0.996-ko-0.9.2/BSD\n",
      "mecab-0.996-ko-0.9.2/NEWS\n",
      "mecab-0.996-ko-0.9.2/mkinstalldirs\n",
      "mecab-0.996-ko-0.9.2/src/\n",
      "mecab-0.996-ko-0.9.2/src/dictionary.h\n",
      "mecab-0.996-ko-0.9.2/src/writer.h\n",
      "mecab-0.996-ko-0.9.2/src/utils.h\n",
      "mecab-0.996-ko-0.9.2/src/string_buffer.cpp\n",
      "mecab-0.996-ko-0.9.2/src/tokenizer.cpp\n",
      "mecab-0.996-ko-0.9.2/src/make.bat\n",
      "mecab-0.996-ko-0.9.2/src/mecab.h\n",
      "mecab-0.996-ko-0.9.2/src/freelist.h\n",
      "mecab-0.996-ko-0.9.2/src/string_buffer.h\n",
      "mecab-0.996-ko-0.9.2/src/learner_tagger.h\n",
      "mecab-0.996-ko-0.9.2/src/dictionary_compiler.cpp\n",
      "mecab-0.996-ko-0.9.2/src/eval.cpp\n",
      "mecab-0.996-ko-0.9.2/src/mecab-system-eval.cpp\n",
      "mecab-0.996-ko-0.9.2/src/darts.h\n",
      "mecab-0.996-ko-0.9.2/src/param.h\n",
      "mecab-0.996-ko-0.9.2/src/char_property.h\n",
      "mecab-0.996-ko-0.9.2/src/learner_node.h\n",
      "mecab-0.996-ko-0.9.2/src/mecab-dict-gen.cpp\n",
      "mecab-0.996-ko-0.9.2/src/mecab-dict-index.cpp\n",
      "mecab-0.996-ko-0.9.2/src/winmain.h\n",
      "mecab-0.996-ko-0.9.2/src/thread.h\n",
      "mecab-0.996-ko-0.9.2/src/context_id.cpp\n",
      "mecab-0.996-ko-0.9.2/src/Makefile.am\n",
      "mecab-0.996-ko-0.9.2/src/connector.h\n",
      "mecab-0.996-ko-0.9.2/src/common.h\n",
      "mecab-0.996-ko-0.9.2/src/dictionary_rewriter.cpp\n",
      "mecab-0.996-ko-0.9.2/src/Makefile.msvc.in\n",
      "mecab-0.996-ko-0.9.2/src/dictionary_rewriter.h\n",
      "mecab-0.996-ko-0.9.2/src/feature_index.h\n",
      "mecab-0.996-ko-0.9.2/src/iconv_utils.cpp\n",
      "mecab-0.996-ko-0.9.2/src/char_property.cpp\n",
      "mecab-0.996-ko-0.9.2/src/mecab-test-gen.cpp\n",
      "mecab-0.996-ko-0.9.2/src/tagger.cpp\n",
      "mecab-0.996-ko-0.9.2/src/mecab-cost-train.cpp\n",
      "mecab-0.996-ko-0.9.2/src/learner.cpp\n",
      "mecab-0.996-ko-0.9.2/src/dictionary.cpp\n",
      "mecab-0.996-ko-0.9.2/src/lbfgs.cpp\n",
      "mecab-0.996-ko-0.9.2/src/ucs.h\n",
      "mecab-0.996-ko-0.9.2/src/writer.cpp\n",
      "mecab-0.996-ko-0.9.2/src/learner_tagger.cpp\n",
      "mecab-0.996-ko-0.9.2/src/lbfgs.h\n",
      "mecab-0.996-ko-0.9.2/src/libmecab.cpp\n",
      "mecab-0.996-ko-0.9.2/src/tokenizer.h\n",
      "mecab-0.996-ko-0.9.2/src/mecab.cpp\n",
      "mecab-0.996-ko-0.9.2/src/utils.cpp\n",
      "mecab-0.996-ko-0.9.2/src/dictionary_generator.cpp\n",
      "mecab-0.996-ko-0.9.2/src/param.cpp\n",
      "mecab-0.996-ko-0.9.2/src/context_id.h\n",
      "mecab-0.996-ko-0.9.2/src/mmap.h\n",
      "mecab-0.996-ko-0.9.2/src/viterbi.h\n",
      "mecab-0.996-ko-0.9.2/src/viterbi.cpp\n",
      "mecab-0.996-ko-0.9.2/src/stream_wrapper.h\n",
      "mecab-0.996-ko-0.9.2/src/feature_index.cpp\n",
      "mecab-0.996-ko-0.9.2/src/nbest_generator.h\n",
      "mecab-0.996-ko-0.9.2/src/ucstable.h\n",
      "mecab-0.996-ko-0.9.2/src/nbest_generator.cpp\n",
      "mecab-0.996-ko-0.9.2/src/iconv_utils.h\n",
      "mecab-0.996-ko-0.9.2/src/connector.cpp\n",
      "mecab-0.996-ko-0.9.2/src/Makefile.in\n",
      "mecab-0.996-ko-0.9.2/src/scoped_ptr.h\n",
      "mecab-0.996-ko-0.9.2/Makefile.in\n",
      "checking for a BSD-compatible install... /usr/bin/install -c\n",
      "checking whether build environment is sane... yes\n",
      "checking for a thread-safe mkdir -p... /bin/mkdir -p\n",
      "checking for gawk... no\n",
      "checking for mawk... mawk\n",
      "checking whether make sets $(MAKE)... yes\n",
      "checking for gcc... gcc\n",
      "checking whether the C compiler works... yes\n",
      "checking for C compiler default output file name... a.out\n",
      "checking for suffix of executables... \n",
      "checking whether we are cross compiling... no\n",
      "checking for suffix of object files... o\n",
      "checking whether we are using the GNU C compiler... yes\n",
      "checking whether gcc accepts -g... yes\n",
      "checking for gcc option to accept ISO C89... none needed\n",
      "checking for style of include used by make... GNU\n",
      "checking dependency style of gcc... none\n",
      "checking for g++... g++\n",
      "checking whether we are using the GNU C++ compiler... yes\n",
      "checking whether g++ accepts -g... yes\n",
      "checking dependency style of g++... none\n",
      "checking how to run the C preprocessor... gcc -E\n",
      "checking for grep that handles long lines and -e... /bin/grep\n",
      "checking for egrep... /bin/grep -E\n",
      "checking whether gcc needs -traditional... no\n",
      "checking whether make sets $(MAKE)... (cached) yes\n",
      "checking build system type... x86_64-unknown-linux-gnu\n",
      "checking host system type... x86_64-unknown-linux-gnu\n",
      "checking how to print strings... printf\n",
      "checking for a sed that does not truncate output... /bin/sed\n",
      "checking for fgrep... /bin/grep -F\n",
      "checking for ld used by gcc... /usr/bin/ld\n",
      "checking if the linker (/usr/bin/ld) is GNU ld... yes\n",
      "checking for BSD- or MS-compatible name lister (nm)... /usr/bin/nm -B\n",
      "checking the name lister (/usr/bin/nm -B) interface... BSD nm\n",
      "checking whether ln -s works... yes\n",
      "checking the maximum length of command line arguments... 1572864\n",
      "checking whether the shell understands some XSI constructs... yes\n",
      "checking whether the shell understands \"+=\"... yes\n",
      "checking how to convert x86_64-unknown-linux-gnu file names to x86_64-unknown-linux-gnu format... func_convert_file_noop\n",
      "checking how to convert x86_64-unknown-linux-gnu file names to toolchain format... func_convert_file_noop\n",
      "checking for /usr/bin/ld option to reload object files... -r\n",
      "checking for objdump... objdump\n",
      "checking how to recognize dependent libraries... pass_all\n",
      "checking for dlltool... dlltool\n",
      "checking how to associate runtime and link libraries... printf %s\\n\n",
      "checking for ar... ar\n",
      "checking for archiver @FILE support... @\n",
      "checking for strip... strip\n",
      "checking for ranlib... ranlib\n",
      "checking command to parse /usr/bin/nm -B output from gcc object... ok\n",
      "checking for sysroot... no\n",
      "checking for mt... no\n",
      "checking if : is a manifest tool... no\n",
      "checking for ANSI C header files... yes\n",
      "checking for sys/types.h... yes\n",
      "checking for sys/stat.h... yes\n",
      "checking for stdlib.h... yes\n",
      "checking for string.h... yes\n",
      "checking for memory.h... yes\n",
      "checking for strings.h... yes\n",
      "checking for inttypes.h... yes\n",
      "checking for stdint.h... yes\n",
      "checking for unistd.h... yes\n",
      "checking for dlfcn.h... yes\n",
      "checking for objdir... .libs\n",
      "checking if gcc supports -fno-rtti -fno-exceptions... no\n",
      "checking for gcc option to produce PIC... -fPIC -DPIC\n",
      "checking if gcc PIC flag -fPIC -DPIC works... yes\n",
      "checking if gcc static flag -static works... yes\n",
      "checking if gcc supports -c -o file.o... yes\n",
      "checking if gcc supports -c -o file.o... (cached) yes\n",
      "checking whether the gcc linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes\n",
      "checking whether -lc should be explicitly linked in... no\n",
      "checking dynamic linker characteristics... GNU/Linux ld.so\n",
      "checking how to hardcode library paths into programs... immediate\n",
      "checking whether stripping libraries is possible... yes\n",
      "checking if libtool supports shared libraries... yes\n",
      "checking whether to build shared libraries... yes\n",
      "checking whether to build static libraries... yes\n",
      "checking how to run the C++ preprocessor... g++ -E\n",
      "checking for ld used by g++... /usr/bin/ld -m elf_x86_64\n",
      "checking if the linker (/usr/bin/ld -m elf_x86_64) is GNU ld... yes\n",
      "checking whether the g++ linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes\n",
      "checking for g++ option to produce PIC... -fPIC -DPIC\n",
      "checking if g++ PIC flag -fPIC -DPIC works... yes\n",
      "checking if g++ static flag -static works... yes\n",
      "checking if g++ supports -c -o file.o... yes\n",
      "checking if g++ supports -c -o file.o... (cached) yes\n",
      "checking whether the g++ linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes\n",
      "checking dynamic linker characteristics... (cached) GNU/Linux ld.so\n",
      "checking how to hardcode library paths into programs... immediate\n",
      "checking for library containing strerror... none required\n",
      "checking whether byte ordering is bigendian... no\n",
      "checking for ld used by GCC... /usr/bin/ld -m elf_x86_64\n",
      "checking if the linker (/usr/bin/ld -m elf_x86_64) is GNU ld... yes\n",
      "checking for shared library run path origin... done\n",
      "checking for iconv... yes\n",
      "checking for working iconv... yes\n",
      "checking for iconv declaration... \n",
      "         extern size_t iconv (iconv_t cd, char * *inbuf, size_t *inbytesleft, char * *outbuf, size_t *outbytesleft);\n",
      "checking for ANSI C header files... (cached) yes\n",
      "checking for an ANSI C-conforming const... yes\n",
      "checking whether byte ordering is bigendian... (cached) no\n",
      "checking for string.h... (cached) yes\n",
      "checking for stdlib.h... (cached) yes\n",
      "checking for unistd.h... (cached) yes\n",
      "checking fcntl.h usability... yes\n",
      "checking fcntl.h presence... yes\n",
      "checking for fcntl.h... yes\n",
      "checking for stdint.h... (cached) yes\n",
      "checking for sys/stat.h... (cached) yes\n",
      "checking sys/mman.h usability... yes\n",
      "checking sys/mman.h presence... yes\n",
      "checking for sys/mman.h... yes\n",
      "checking sys/times.h usability... yes\n",
      "checking sys/times.h presence... yes\n",
      "checking for sys/times.h... yes\n",
      "checking for sys/types.h... (cached) yes\n",
      "checking dirent.h usability... yes\n",
      "checking dirent.h presence... yes\n",
      "checking for dirent.h... yes\n",
      "checking ctype.h usability... yes\n",
      "checking ctype.h presence... yes\n",
      "checking for ctype.h... yes\n",
      "checking for sys/types.h... (cached) yes\n",
      "checking io.h usability... no\n",
      "checking io.h presence... no\n",
      "checking for io.h... no\n",
      "checking windows.h usability... no\n",
      "checking windows.h presence... no\n",
      "checking for windows.h... no\n",
      "checking pthread.h usability... yes\n",
      "checking pthread.h presence... yes\n",
      "checking for pthread.h... yes\n",
      "checking for off_t... yes\n",
      "checking for size_t... yes\n",
      "checking size of char... 1\n",
      "checking size of short... 2\n",
      "checking size of int... 4\n",
      "checking size of long... 8\n",
      "checking size of long long... 8\n",
      "checking size of size_t... 8\n",
      "checking for size_t... (cached) yes\n",
      "checking for unsigned long long int... yes\n",
      "checking for stdlib.h... (cached) yes\n",
      "checking for unistd.h... (cached) yes\n",
      "checking for sys/param.h... yes\n",
      "checking for getpagesize... yes\n",
      "checking for working mmap... yes\n",
      "checking for main in -lstdc++... yes\n",
      "checking for pthread_create in -lpthread... yes\n",
      "checking for pthread_join in -lpthread... yes\n",
      "checking for getenv... yes\n",
      "checking for opendir... yes\n",
      "checking whether make is GNU Make... yes\n",
      "checking if g++ supports stl <vector> (required)... yes\n",
      "checking if g++ supports stl <list> (required)... yes\n",
      "checking if g++ supports stl <map> (required)... yes\n",
      "checking if g++ supports stl <set> (required)... yes\n",
      "checking if g++ supports stl <queue> (required)... yes\n",
      "checking if g++ supports stl <functional> (required)... yes\n",
      "checking if g++ supports stl <algorithm> (required)... yes\n",
      "checking if g++ supports stl <string> (required)... yes\n",
      "checking if g++ supports stl <iostream> (required)... yes\n",
      "checking if g++ supports stl <sstream> (required)... yes\n",
      "checking if g++ supports stl <fstream> (required)... yes\n",
      "checking if g++ supports template <class T> (required)... yes\n",
      "checking if g++ supports const_cast<> (required)... yes\n",
      "checking if g++ supports static_cast<> (required)... yes\n",
      "checking if g++ supports reinterpret_cast<> (required)... yes\n",
      "checking if g++ supports namespaces (required) ... yes\n",
      "checking if g++ supports __thread (optional)... yes\n",
      "checking if g++ supports template <class T> (required)... yes\n",
      "checking if g++ supports GCC native atomic operations (optional)... yes\n",
      "checking if g++ supports OSX native atomic operations (optional)... no\n",
      "checking if g++ environment provides all required features... yes\n",
      "configure: creating ./config.status\n",
      "config.status: creating Makefile\n",
      "config.status: creating src/Makefile\n",
      "config.status: creating src/Makefile.msvc\n",
      "config.status: creating man/Makefile\n",
      "config.status: creating doc/Makefile\n",
      "config.status: creating tests/Makefile\n",
      "config.status: creating swig/version.h\n",
      "config.status: creating mecab.iss\n",
      "config.status: creating mecab-config\n",
      "config.status: creating mecabrc\n",
      "config.status: creating config.h\n",
      "config.status: executing depfiles commands\n",
      "config.status: executing libtool commands\n",
      "config.status: executing default commands\n",
      "make  all-recursive\n",
      "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
      "Making all in src\n",
      "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
      "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o viterbi.lo viterbi.cpp\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c viterbi.cpp  -fPIC -DPIC -o .libs/viterbi.o\n",
      "In file included from \u001b[01m\u001b[Kviterbi.cpp:14:0\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[Kparam.h:30:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KTarget {anonymous}::lexical_cast(Source) [with Target = std::__cxx11::basic_string<char>; Source = std::__cxx11::basic_string<char>]\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-function\u001b[m\u001b[K]\n",
      " std::string \u001b[01;35m\u001b[Klexical_cast<std::string, std::string>\u001b[m\u001b[K(std::string arg) {\n",
      "             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c viterbi.cpp -o viterbi.o >/dev/null 2>&1\n",
      "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o tagger.lo tagger.cpp\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c tagger.cpp  -fPIC -DPIC -o .libs/tagger.o\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c tagger.cpp -o tagger.o >/dev/null 2>&1\n",
      "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o utils.lo utils.cpp\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c utils.cpp  -fPIC -DPIC -o .libs/utils.o\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c utils.cpp -o utils.o >/dev/null 2>&1\n",
      "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o eval.lo eval.cpp\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c eval.cpp  -fPIC -DPIC -o .libs/eval.o\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c eval.cpp -o eval.o >/dev/null 2>&1\n",
      "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o iconv_utils.lo iconv_utils.cpp\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c iconv_utils.cpp  -fPIC -DPIC -o .libs/iconv_utils.o\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c iconv_utils.cpp -o iconv_utils.o >/dev/null 2>&1\n",
      "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o dictionary_rewriter.lo dictionary_rewriter.cpp\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_rewriter.cpp  -fPIC -DPIC -o .libs/dictionary_rewriter.o\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_rewriter.cpp -o dictionary_rewriter.o >/dev/null 2>&1\n",
      "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o dictionary_generator.lo dictionary_generator.cpp\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_generator.cpp  -fPIC -DPIC -o .libs/dictionary_generator.o\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_generator.cpp -o dictionary_generator.o >/dev/null 2>&1\n",
      "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o dictionary_compiler.lo dictionary_compiler.cpp\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_compiler.cpp  -fPIC -DPIC -o .libs/dictionary_compiler.o\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_compiler.cpp -o dictionary_compiler.o >/dev/null 2>&1\n",
      "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o context_id.lo context_id.cpp\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c context_id.cpp  -fPIC -DPIC -o .libs/context_id.o\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c context_id.cpp -o context_id.o >/dev/null 2>&1\n",
      "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o connector.lo connector.cpp\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c connector.cpp  -fPIC -DPIC -o .libs/connector.o\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c connector.cpp -o connector.o >/dev/null 2>&1\n",
      "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o nbest_generator.lo nbest_generator.cpp\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c nbest_generator.cpp  -fPIC -DPIC -o .libs/nbest_generator.o\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c nbest_generator.cpp -o nbest_generator.o >/dev/null 2>&1\n",
      "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o writer.lo writer.cpp\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c writer.cpp  -fPIC -DPIC -o .libs/writer.o\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c writer.cpp -o writer.o >/dev/null 2>&1\n",
      "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o string_buffer.lo string_buffer.cpp\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c string_buffer.cpp  -fPIC -DPIC -o .libs/string_buffer.o\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c string_buffer.cpp -o string_buffer.o >/dev/null 2>&1\n",
      "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o param.lo param.cpp\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c param.cpp  -fPIC -DPIC -o .libs/param.o\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c param.cpp -o param.o >/dev/null 2>&1\n",
      "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o tokenizer.lo tokenizer.cpp\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c tokenizer.cpp  -fPIC -DPIC -o .libs/tokenizer.o\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c tokenizer.cpp -o tokenizer.o >/dev/null 2>&1\n",
      "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o char_property.lo char_property.cpp\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c char_property.cpp  -fPIC -DPIC -o .libs/char_property.o\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c char_property.cpp -o char_property.o >/dev/null 2>&1\n",
      "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o dictionary.lo dictionary.cpp\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary.cpp  -fPIC -DPIC -o .libs/dictionary.o\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary.cpp -o dictionary.o >/dev/null 2>&1\n",
      "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o feature_index.lo feature_index.cpp\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c feature_index.cpp  -fPIC -DPIC -o .libs/feature_index.o\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c feature_index.cpp -o feature_index.o >/dev/null 2>&1\n",
      "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o lbfgs.lo lbfgs.cpp\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c lbfgs.cpp  -fPIC -DPIC -o .libs/lbfgs.o\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c lbfgs.cpp -o lbfgs.o >/dev/null 2>&1\n",
      "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o learner_tagger.lo learner_tagger.cpp\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c learner_tagger.cpp  -fPIC -DPIC -o .libs/learner_tagger.o\n",
      "\u001b[01m\u001b[Klearner_tagger.cpp:25:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kchar* MeCab::{anonymous}::mystrdup(const string&)\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-function\u001b[m\u001b[K]\n",
      " char *\u001b[01;35m\u001b[Kmystrdup\u001b[m\u001b[K(const std::string &str) {\n",
      "       \u001b[01;35m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c learner_tagger.cpp -o learner_tagger.o >/dev/null 2>&1\n",
      "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o learner.lo learner.cpp\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c learner.cpp  -fPIC -DPIC -o .libs/learner.o\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c learner.cpp -o learner.o >/dev/null 2>&1\n",
      "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o libmecab.lo libmecab.cpp\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c libmecab.cpp  -fPIC -DPIC -o .libs/libmecab.o\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c libmecab.cpp -o libmecab.o >/dev/null 2>&1\n",
      "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall  -no-undefined -version-info 2:0:0  -o libmecab.la -rpath /usr/local/lib viterbi.lo tagger.lo utils.lo eval.lo iconv_utils.lo dictionary_rewriter.lo dictionary_generator.lo dictionary_compiler.lo context_id.lo connector.lo nbest_generator.lo writer.lo string_buffer.lo param.lo tokenizer.lo char_property.lo dictionary.lo feature_index.lo lbfgs.lo learner_tagger.lo learner.lo libmecab.lo  -lpthread -lpthread  -lstdc++ \n",
      "libtool: link: g++  -fPIC -DPIC -shared -nostdlib /usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu/crti.o /usr/lib/gcc/x86_64-linux-gnu/7/crtbeginS.o  .libs/viterbi.o .libs/tagger.o .libs/utils.o .libs/eval.o .libs/iconv_utils.o .libs/dictionary_rewriter.o .libs/dictionary_generator.o .libs/dictionary_compiler.o .libs/context_id.o .libs/connector.o .libs/nbest_generator.o .libs/writer.o .libs/string_buffer.o .libs/param.o .libs/tokenizer.o .libs/char_property.o .libs/dictionary.o .libs/feature_index.o .libs/lbfgs.o .libs/learner_tagger.o .libs/learner.o .libs/libmecab.o   -lpthread -L/usr/lib/gcc/x86_64-linux-gnu/7 -L/usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu -L/usr/lib/gcc/x86_64-linux-gnu/7/../../../../lib -L/lib/x86_64-linux-gnu -L/lib/../lib -L/usr/lib/x86_64-linux-gnu -L/usr/lib/../lib -L/usr/lib/gcc/x86_64-linux-gnu/7/../../.. -lstdc++ -lm -lc -lgcc_s /usr/lib/gcc/x86_64-linux-gnu/7/crtendS.o /usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu/crtn.o  -O3   -Wl,-soname -Wl,libmecab.so.2 -o .libs/libmecab.so.2.0.0\n",
      "libtool: link: (cd \".libs\" && rm -f \"libmecab.so.2\" && ln -s \"libmecab.so.2.0.0\" \"libmecab.so.2\")\n",
      "libtool: link: (cd \".libs\" && rm -f \"libmecab.so\" && ln -s \"libmecab.so.2.0.0\" \"libmecab.so\")\n",
      "libtool: link: ar cru .libs/libmecab.a  viterbi.o tagger.o utils.o eval.o iconv_utils.o dictionary_rewriter.o dictionary_generator.o dictionary_compiler.o context_id.o connector.o nbest_generator.o writer.o string_buffer.o param.o tokenizer.o char_property.o dictionary.o feature_index.o lbfgs.o learner_tagger.o learner.o libmecab.o\n",
      "ar: `u' modifier ignored since `D' is the default (see `U')\n",
      "libtool: link: ranlib .libs/libmecab.a\n",
      "libtool: link: ( cd \".libs\" && rm -f \"libmecab.la\" && ln -s \"../libmecab.la\" \"libmecab.la\" )\n",
      "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab.o mecab.cpp\n",
      "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab mecab.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
      "libtool: link: g++ -O3 -Wall -o .libs/mecab mecab.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
      "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-dict-index.o mecab-dict-index.cpp\n",
      "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-dict-index mecab-dict-index.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
      "libtool: link: g++ -O3 -Wall -o .libs/mecab-dict-index mecab-dict-index.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
      "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-dict-gen.o mecab-dict-gen.cpp\n",
      "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-dict-gen mecab-dict-gen.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
      "libtool: link: g++ -O3 -Wall -o .libs/mecab-dict-gen mecab-dict-gen.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
      "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-cost-train.o mecab-cost-train.cpp\n",
      "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-cost-train mecab-cost-train.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
      "libtool: link: g++ -O3 -Wall -o .libs/mecab-cost-train mecab-cost-train.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
      "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-system-eval.o mecab-system-eval.cpp\n",
      "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-system-eval mecab-system-eval.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
      "libtool: link: g++ -O3 -Wall -o .libs/mecab-system-eval mecab-system-eval.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
      "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-test-gen.o mecab-test-gen.cpp\n",
      "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-test-gen mecab-test-gen.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
      "libtool: link: g++ -O3 -Wall -o .libs/mecab-test-gen mecab-test-gen.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
      "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
      "Making all in man\n",
      "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
      "make[2]: Nothing to be done for 'all'.\n",
      "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
      "Making all in doc\n",
      "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
      "make[2]: Nothing to be done for 'all'.\n",
      "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
      "Making all in tests\n",
      "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
      "make[2]: Nothing to be done for 'all'.\n",
      "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
      "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
      "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
      "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
      "Making check in src\n",
      "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
      "make[1]: Nothing to be done for 'check'.\n",
      "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
      "Making check in man\n",
      "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
      "make[1]: Nothing to be done for 'check'.\n",
      "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
      "Making check in doc\n",
      "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
      "make[1]: Nothing to be done for 'check'.\n",
      "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
      "Making check in tests\n",
      "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
      "make  check-TESTS\n",
      "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
      "./pos-id.def is not found. minimum setting is used\n",
      "reading ./unk.def ... 2\n",
      "emitting double-array: 100% |###########################################| \n",
      "./model.def is not found. skipped.\n",
      "./pos-id.def is not found. minimum setting is used\n",
      "reading ./dic.csv ... 177\n",
      "emitting double-array: 100% |###########################################| \n",
      "reading ./matrix.def ... 178x178\n",
      "emitting matrix      : 100% |###########################################| \n",
      "\n",
      "done!\n",
      "./pos-id.def is not found. minimum setting is used\n",
      "reading ./unk.def ... 2\n",
      "emitting double-array: 100% |###########################################| \n",
      "./model.def is not found. skipped.\n",
      "./pos-id.def is not found. minimum setting is used\n",
      "reading ./dic.csv ... 83\n",
      "emitting double-array: 100% |###########################################| \n",
      "reading ./matrix.def ... 84x84\n",
      "emitting matrix      : 100% |###########################################| \n",
      "\n",
      "done!\n",
      "./pos-id.def is not found. minimum setting is used\n",
      "reading ./unk.def ... 2\n",
      "emitting double-array: 100% |###########################################| \n",
      "./model.def is not found. skipped.\n",
      "./pos-id.def is not found. minimum setting is used\n",
      "reading ./dic.csv ... 450\n",
      "emitting double-array: 100% |###########################################| \n",
      "reading ./matrix.def ... 1x1\n",
      "\n",
      "done!\n",
      "./pos-id.def is not found. minimum setting is used\n",
      "reading ./unk.def ... 2\n",
      "emitting double-array: 100% |###########################################| \n",
      "./model.def is not found. skipped.\n",
      "./pos-id.def is not found. minimum setting is used\n",
      "reading ./dic.csv ... 162\n",
      "emitting double-array: 100% |###########################################| \n",
      "reading ./matrix.def ... 3x3\n",
      "emitting matrix      : 100% |###########################################| \n",
      "\n",
      "done!\n",
      "./pos-id.def is not found. minimum setting is used\n",
      "reading ./unk.def ... 2\n",
      "emitting double-array: 100% |###########################################| \n",
      "./model.def is not found. skipped.\n",
      "./pos-id.def is not found. minimum setting is used\n",
      "reading ./dic.csv ... 4\n",
      "emitting double-array: 100% |###########################################| \n",
      "reading ./matrix.def ... 1x1\n",
      "\n",
      "done!\n",
      "./pos-id.def is not found. minimum setting is used\n",
      "reading ./unk.def ... 11\n",
      "emitting double-array: 100% |###########################################| \n",
      "./model.def is not found. skipped.\n",
      "./pos-id.def is not found. minimum setting is used\n",
      "reading ./dic.csv ... 1\n",
      "reading ./matrix.def ... 1x1\n",
      "\n",
      "done!\n",
      "./pos-id.def is not found. minimum setting is used\n",
      "reading ./unk.def ... 2\n",
      "emitting double-array: 100% |###########################################| \n",
      "./model.def is not found. skipped.\n",
      "./pos-id.def is not found. minimum setting is used\n",
      "reading ./dic.csv ... 1\n",
      "reading ./matrix.def ... 1x1\n",
      "\n",
      "done!\n",
      "PASS: run-dics.sh\n",
      "PASS: run-eval.sh\n",
      "seed/pos-id.def is not found. minimum setting is used\n",
      "reading seed/unk.def ... 40\n",
      "emitting double-array: 100% |###########################################| \n",
      "seed/model.def is not found. skipped.\n",
      "seed/pos-id.def is not found. minimum setting is used\n",
      "reading seed/dic.csv ... 4335\n",
      "emitting double-array: 100% |###########################################| \n",
      "reading seed/matrix.def ... 1x1\n",
      "\n",
      "done!\n",
      "reading corpus ...\n",
      "Number of sentences: 34\n",
      "Number of features:  64108\n",
      "eta:                 0.00005\n",
      "freq:                1\n",
      "eval-size:           6\n",
      "unk-eval-size:       4\n",
      "threads:             1\n",
      "charset:             EUC-JP\n",
      "C(sigma^2):          1.00000\n",
      "\n",
      "iter=0 err=1.00000 F=0.35771 target=2406.28355 diff=1.00000\n",
      "iter=1 err=0.97059 F=0.65652 target=1484.25231 diff=0.38318\n",
      "iter=2 err=0.91176 F=0.79331 target=863.32765 diff=0.41834\n",
      "iter=3 err=0.85294 F=0.89213 target=596.72480 diff=0.30881\n",
      "iter=4 err=0.61765 F=0.95467 target=336.30744 diff=0.43641\n",
      "iter=5 err=0.50000 F=0.96702 target=246.53039 diff=0.26695\n",
      "iter=6 err=0.35294 F=0.95472 target=188.93963 diff=0.23361\n",
      "iter=7 err=0.20588 F=0.99106 target=168.62665 diff=0.10751\n",
      "iter=8 err=0.05882 F=0.99777 target=158.64865 diff=0.05917\n",
      "iter=9 err=0.08824 F=0.99665 target=154.14530 diff=0.02839\n",
      "iter=10 err=0.08824 F=0.99665 target=151.94257 diff=0.01429\n",
      "iter=11 err=0.02941 F=0.99888 target=147.20825 diff=0.03116\n",
      "iter=12 err=0.00000 F=1.00000 target=147.34956 diff=0.00096\n",
      "iter=13 err=0.02941 F=0.99888 target=146.32592 diff=0.00695\n",
      "iter=14 err=0.00000 F=1.00000 target=145.77299 diff=0.00378\n",
      "iter=15 err=0.02941 F=0.99888 target=145.24641 diff=0.00361\n",
      "iter=16 err=0.00000 F=1.00000 target=144.96490 diff=0.00194\n",
      "iter=17 err=0.02941 F=0.99888 target=144.90246 diff=0.00043\n",
      "iter=18 err=0.00000 F=1.00000 target=144.75959 diff=0.00099\n",
      "iter=19 err=0.00000 F=1.00000 target=144.71727 diff=0.00029\n",
      "iter=20 err=0.00000 F=1.00000 target=144.66337 diff=0.00037\n",
      "iter=21 err=0.00000 F=1.00000 target=144.61349 diff=0.00034\n",
      "iter=22 err=0.00000 F=1.00000 target=144.62987 diff=0.00011\n",
      "iter=23 err=0.00000 F=1.00000 target=144.60060 diff=0.00020\n",
      "iter=24 err=0.00000 F=1.00000 target=144.59125 diff=0.00006\n",
      "iter=25 err=0.00000 F=1.00000 target=144.58619 diff=0.00004\n",
      "iter=26 err=0.00000 F=1.00000 target=144.58219 diff=0.00003\n",
      "iter=27 err=0.00000 F=1.00000 target=144.58059 diff=0.00001\n",
      "\n",
      "Done! writing model file ... \n",
      "model-ipadic.c1.0.f1.model is not a binary model. reopen it as text mode...\n",
      "reading seed/unk.def ... 40\n",
      "reading seed/dic.csv ... 4335\n",
      "emitting model-ipadic.c1.0.f1.dic/left-id.def/ model-ipadic.c1.0.f1.dic/right-id.def\n",
      "emitting model-ipadic.c1.0.f1.dic/unk.def ... 40\n",
      "emitting model-ipadic.c1.0.f1.dic/dic.csv ... 4335\n",
      "emitting matrix      : 100% |###########################################| \n",
      "copying seed/char.def to model-ipadic.c1.0.f1.dic/char.def\n",
      "copying seed/rewrite.def to model-ipadic.c1.0.f1.dic/rewrite.def\n",
      "copying seed/dicrc to model-ipadic.c1.0.f1.dic/dicrc\n",
      "copying seed/feature.def to model-ipadic.c1.0.f1.dic/feature.def\n",
      "copying model-ipadic.c1.0.f1.model to model-ipadic.c1.0.f1.dic/model.def\n",
      "\n",
      "done!\n",
      "model-ipadic.c1.0.f1.dic/pos-id.def is not found. minimum setting is used\n",
      "reading model-ipadic.c1.0.f1.dic/unk.def ... 40\n",
      "emitting double-array: 100% |###########################################| \n",
      "model-ipadic.c1.0.f1.dic/pos-id.def is not found. minimum setting is used\n",
      "reading model-ipadic.c1.0.f1.dic/dic.csv ... 4335\n",
      "emitting double-array: 100% |###########################################|                       | \n",
      "reading model-ipadic.c1.0.f1.dic/matrix.def ... 346x346\n",
      "emitting matrix      : 100% |###########################################| \n",
      "\n",
      "done!\n",
      "              precision          recall         F\n",
      "LEVEL 0:    12.8959(57/442) 11.8998(57/479) 12.3779\n",
      "LEVEL 1:    12.2172(54/442) 11.2735(54/479) 11.7264\n",
      "LEVEL 2:    11.7647(52/442) 10.8559(52/479) 11.2921\n",
      "LEVEL 4:    11.7647(52/442) 10.8559(52/479) 11.2921\n",
      "PASS: run-cost-train.sh\n",
      "==================\n",
      "All 3 tests passed\n",
      "==================\n",
      "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
      "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
      "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
      "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
      "Making install in src\n",
      "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
      "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
      "test -z \"/usr/local/lib\" || /bin/mkdir -p \"/usr/local/lib\"\n",
      " /bin/bash ../libtool   --mode=install /usr/bin/install -c   libmecab.la '/usr/local/lib'\n",
      "libtool: install: /usr/bin/install -c .libs/libmecab.so.2.0.0 /usr/local/lib/libmecab.so.2.0.0\n",
      "libtool: install: (cd /usr/local/lib && { ln -s -f libmecab.so.2.0.0 libmecab.so.2 || { rm -f libmecab.so.2 && ln -s libmecab.so.2.0.0 libmecab.so.2; }; })\n",
      "libtool: install: (cd /usr/local/lib && { ln -s -f libmecab.so.2.0.0 libmecab.so || { rm -f libmecab.so && ln -s libmecab.so.2.0.0 libmecab.so; }; })\n",
      "libtool: install: /usr/bin/install -c .libs/libmecab.lai /usr/local/lib/libmecab.la\n",
      "libtool: install: /usr/bin/install -c .libs/libmecab.a /usr/local/lib/libmecab.a\n",
      "libtool: install: chmod 644 /usr/local/lib/libmecab.a\n",
      "libtool: install: ranlib /usr/local/lib/libmecab.a\n",
      "libtool: finish: PATH=\"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin:/sbin\" ldconfig -n /usr/local/lib\n",
      "----------------------------------------------------------------------\n",
      "Libraries have been installed in:\n",
      "   /usr/local/lib\n",
      "\n",
      "If you ever happen to want to link against installed libraries\n",
      "in a given directory, LIBDIR, you must either use libtool, and\n",
      "specify the full pathname of the library, or use the `-LLIBDIR'\n",
      "flag during linking and do at least one of the following:\n",
      "   - add LIBDIR to the `LD_LIBRARY_PATH' environment variable\n",
      "     during execution\n",
      "   - add LIBDIR to the `LD_RUN_PATH' environment variable\n",
      "     during linking\n",
      "   - use the `-Wl,-rpath -Wl,LIBDIR' linker flag\n",
      "   - have your system administrator add LIBDIR to `/etc/ld.so.conf'\n",
      "\n",
      "See any operating system documentation about shared libraries for\n",
      "more information, such as the ld(1) and ld.so(8) manual pages.\n",
      "----------------------------------------------------------------------\n",
      "test -z \"/usr/local/bin\" || /bin/mkdir -p \"/usr/local/bin\"\n",
      "  /bin/bash ../libtool   --mode=install /usr/bin/install -c mecab '/usr/local/bin'\n",
      "libtool: install: /usr/bin/install -c .libs/mecab /usr/local/bin/mecab\n",
      "test -z \"/usr/local/libexec/mecab\" || /bin/mkdir -p \"/usr/local/libexec/mecab\"\n",
      "  /bin/bash ../libtool   --mode=install /usr/bin/install -c mecab-dict-index mecab-dict-gen mecab-cost-train mecab-system-eval mecab-test-gen '/usr/local/libexec/mecab'\n",
      "libtool: install: /usr/bin/install -c .libs/mecab-dict-index /usr/local/libexec/mecab/mecab-dict-index\n",
      "libtool: install: /usr/bin/install -c .libs/mecab-dict-gen /usr/local/libexec/mecab/mecab-dict-gen\n",
      "libtool: install: /usr/bin/install -c .libs/mecab-cost-train /usr/local/libexec/mecab/mecab-cost-train\n",
      "libtool: install: /usr/bin/install -c .libs/mecab-system-eval /usr/local/libexec/mecab/mecab-system-eval\n",
      "libtool: install: /usr/bin/install -c .libs/mecab-test-gen /usr/local/libexec/mecab/mecab-test-gen\n",
      "test -z \"/usr/local/include\" || /bin/mkdir -p \"/usr/local/include\"\n",
      " /usr/bin/install -c -m 644 mecab.h '/usr/local/include'\n",
      "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
      "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
      "Making install in man\n",
      "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
      "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
      "make[2]: Nothing to be done for 'install-exec-am'.\n",
      "test -z \"/usr/local/share/man/man1\" || /bin/mkdir -p \"/usr/local/share/man/man1\"\n",
      " /usr/bin/install -c -m 644 mecab.1 '/usr/local/share/man/man1'\n",
      "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
      "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
      "Making install in doc\n",
      "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
      "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
      "make[2]: Nothing to be done for 'install-exec-am'.\n",
      "make[2]: Nothing to be done for 'install-data-am'.\n",
      "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
      "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
      "Making install in tests\n",
      "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
      "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
      "make[2]: Nothing to be done for 'install-exec-am'.\n",
      "make[2]: Nothing to be done for 'install-data-am'.\n",
      "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
      "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
      "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
      "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
      "test -z \"/usr/local/bin\" || /bin/mkdir -p \"/usr/local/bin\"\n",
      " /usr/bin/install -c mecab-config '/usr/local/bin'\n",
      "test -z \"/usr/local/etc\" || /bin/mkdir -p \"/usr/local/etc\"\n",
      " /usr/bin/install -c -m 644 mecabrc '/usr/local/etc'\n",
      "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
      "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
      "Install mecab-ko-dic\n",
      "Install mecab-ko-dic\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 47.4M  100 47.4M    0     0  31.1M      0  0:00:01  0:00:01 --:--:-- 73.4M\n",
      "mecab-ko-dic-2.1.1-20180720/\n",
      "mecab-ko-dic-2.1.1-20180720/configure\n",
      "mecab-ko-dic-2.1.1-20180720/COPYING\n",
      "mecab-ko-dic-2.1.1-20180720/autogen.sh\n",
      "mecab-ko-dic-2.1.1-20180720/Place-station.csv\n",
      "mecab-ko-dic-2.1.1-20180720/NNG.csv\n",
      "mecab-ko-dic-2.1.1-20180720/README\n",
      "mecab-ko-dic-2.1.1-20180720/EF.csv\n",
      "mecab-ko-dic-2.1.1-20180720/MAG.csv\n",
      "mecab-ko-dic-2.1.1-20180720/Preanalysis.csv\n",
      "mecab-ko-dic-2.1.1-20180720/NNB.csv\n",
      "mecab-ko-dic-2.1.1-20180720/Person-actor.csv\n",
      "mecab-ko-dic-2.1.1-20180720/VV.csv\n",
      "mecab-ko-dic-2.1.1-20180720/Makefile.in\n",
      "mecab-ko-dic-2.1.1-20180720/matrix.def\n",
      "mecab-ko-dic-2.1.1-20180720/EC.csv\n",
      "mecab-ko-dic-2.1.1-20180720/NNBC.csv\n",
      "mecab-ko-dic-2.1.1-20180720/clean\n",
      "mecab-ko-dic-2.1.1-20180720/ChangeLog\n",
      "mecab-ko-dic-2.1.1-20180720/J.csv\n",
      "mecab-ko-dic-2.1.1-20180720/.keep\n",
      "mecab-ko-dic-2.1.1-20180720/feature.def\n",
      "mecab-ko-dic-2.1.1-20180720/Foreign.csv\n",
      "mecab-ko-dic-2.1.1-20180720/XPN.csv\n",
      "mecab-ko-dic-2.1.1-20180720/EP.csv\n",
      "mecab-ko-dic-2.1.1-20180720/NR.csv\n",
      "mecab-ko-dic-2.1.1-20180720/left-id.def\n",
      "mecab-ko-dic-2.1.1-20180720/Place.csv\n",
      "mecab-ko-dic-2.1.1-20180720/Symbol.csv\n",
      "mecab-ko-dic-2.1.1-20180720/dicrc\n",
      "mecab-ko-dic-2.1.1-20180720/NP.csv\n",
      "mecab-ko-dic-2.1.1-20180720/ETM.csv\n",
      "mecab-ko-dic-2.1.1-20180720/IC.csv\n",
      "mecab-ko-dic-2.1.1-20180720/Place-address.csv\n",
      "mecab-ko-dic-2.1.1-20180720/Group.csv\n",
      "mecab-ko-dic-2.1.1-20180720/model.def\n",
      "mecab-ko-dic-2.1.1-20180720/XSN.csv\n",
      "mecab-ko-dic-2.1.1-20180720/INSTALL\n",
      "mecab-ko-dic-2.1.1-20180720/rewrite.def\n",
      "mecab-ko-dic-2.1.1-20180720/Inflect.csv\n",
      "mecab-ko-dic-2.1.1-20180720/configure.ac\n",
      "mecab-ko-dic-2.1.1-20180720/NNP.csv\n",
      "mecab-ko-dic-2.1.1-20180720/CoinedWord.csv\n",
      "mecab-ko-dic-2.1.1-20180720/XSV.csv\n",
      "mecab-ko-dic-2.1.1-20180720/pos-id.def\n",
      "mecab-ko-dic-2.1.1-20180720/Makefile.am\n",
      "mecab-ko-dic-2.1.1-20180720/unk.def\n",
      "mecab-ko-dic-2.1.1-20180720/missing\n",
      "mecab-ko-dic-2.1.1-20180720/VCP.csv\n",
      "mecab-ko-dic-2.1.1-20180720/install-sh\n",
      "mecab-ko-dic-2.1.1-20180720/Hanja.csv\n",
      "mecab-ko-dic-2.1.1-20180720/MAJ.csv\n",
      "mecab-ko-dic-2.1.1-20180720/XSA.csv\n",
      "mecab-ko-dic-2.1.1-20180720/Wikipedia.csv\n",
      "mecab-ko-dic-2.1.1-20180720/tools/\n",
      "mecab-ko-dic-2.1.1-20180720/tools/add-userdic.sh\n",
      "mecab-ko-dic-2.1.1-20180720/tools/mecab-bestn.sh\n",
      "mecab-ko-dic-2.1.1-20180720/tools/convert_for_using_store.sh\n",
      "mecab-ko-dic-2.1.1-20180720/user-dic/\n",
      "mecab-ko-dic-2.1.1-20180720/user-dic/nnp.csv\n",
      "mecab-ko-dic-2.1.1-20180720/user-dic/place.csv\n",
      "mecab-ko-dic-2.1.1-20180720/user-dic/person.csv\n",
      "mecab-ko-dic-2.1.1-20180720/user-dic/README.md\n",
      "mecab-ko-dic-2.1.1-20180720/NorthKorea.csv\n",
      "mecab-ko-dic-2.1.1-20180720/VX.csv\n",
      "mecab-ko-dic-2.1.1-20180720/right-id.def\n",
      "mecab-ko-dic-2.1.1-20180720/VA.csv\n",
      "mecab-ko-dic-2.1.1-20180720/char.def\n",
      "mecab-ko-dic-2.1.1-20180720/NEWS\n",
      "mecab-ko-dic-2.1.1-20180720/MM.csv\n",
      "mecab-ko-dic-2.1.1-20180720/ETN.csv\n",
      "mecab-ko-dic-2.1.1-20180720/AUTHORS\n",
      "mecab-ko-dic-2.1.1-20180720/Person.csv\n",
      "mecab-ko-dic-2.1.1-20180720/XR.csv\n",
      "mecab-ko-dic-2.1.1-20180720/VCN.csv\n",
      "Looking in current directory for macros.\n",
      "configure.ac:2: warning: AM_INIT_AUTOMAKE: two- and three-arguments forms are deprecated.  For more info, see:\n",
      "configure.ac:2: http://www.gnu.org/software/automake/manual/automake.html#Modernize-AM_005fINIT_005fAUTOMAKE-invocation\n",
      "checking for a BSD-compatible install... /usr/bin/install -c\n",
      "checking whether build environment is sane... yes\n",
      "/tmp/mecab-ko-dic-2.1.1-20180720/missing: Unknown `--is-lightweight' option\n",
      "Try `/tmp/mecab-ko-dic-2.1.1-20180720/missing --help' for more information\n",
      "configure: WARNING: 'missing' script is too old or missing\n",
      "checking for a thread-safe mkdir -p... /bin/mkdir -p\n",
      "checking for gawk... no\n",
      "checking for mawk... mawk\n",
      "checking whether make sets $(MAKE)... yes\n",
      "checking whether make supports nested variables... yes\n",
      "checking for mecab-config... /usr/local/bin/mecab-config\n",
      "checking that generated files are newer than configure... done\n",
      "configure: creating ./config.status\n",
      "config.status: creating Makefile\n",
      "/usr/local/lib\n",
      "/usr/local/libexec/mecab/mecab-dict-index -d . -o . -f UTF-8 -t UTF-8\n",
      "reading ./unk.def ... 13\n",
      "emitting double-array: 100% |###########################################| \n",
      "reading ./Symbol.csv ... 16\n",
      "reading ./Hanja.csv ... 125750\n",
      "reading ./VCP.csv ... 9\n",
      "reading ./IC.csv ... 1305\n",
      "reading ./ETM.csv ... 133\n",
      "reading ./J.csv ... 416\n",
      "reading ./Place-address.csv ... 19301\n",
      "reading ./XR.csv ... 3637\n",
      "reading ./EC.csv ... 2547\n",
      "reading ./NR.csv ... 482\n",
      "reading ./MAJ.csv ... 240\n",
      "reading ./NNG.csv ... 208524\n",
      "reading ./NorthKorea.csv ... 3\n",
      "reading ./NNP.csv ... 2371\n",
      "reading ./VA.csv ... 2360\n",
      "reading ./XPN.csv ... 83\n",
      "reading ./Foreign.csv ... 11690\n",
      "reading ./Preanalysis.csv ... 5\n",
      "reading ./Person.csv ... 196459\n",
      "reading ./EF.csv ... 1820\n",
      "reading ./CoinedWord.csv ... 148\n",
      "reading ./ETN.csv ... 14\n",
      "reading ./XSV.csv ... 23\n",
      "reading ./Person-actor.csv ... 99230\n",
      "reading ./MAG.csv ... 14242\n",
      "reading ./Inflect.csv ... 44820\n",
      "reading ./NNBC.csv ... 677\n",
      "reading ./MM.csv ... 453\n",
      "reading ./Wikipedia.csv ... 36762\n",
      "reading ./EP.csv ... 51\n",
      "reading ./NNB.csv ... 140\n",
      "reading ./Place-station.csv ... 1145\n",
      "reading ./VCN.csv ... 7\n",
      "reading ./Place.csv ... 30303\n",
      "reading ./Group.csv ... 3176\n",
      "reading ./VX.csv ... 125\n",
      "reading ./NP.csv ... 342\n",
      "reading ./XSN.csv ... 124\n",
      "reading ./VV.csv ... 7331\n",
      "reading ./XSA.csv ... 19\n",
      "emitting double-array: 100% |###########################################| \n",
      "reading ./matrix.def ... 3822x2693\n",
      "emitting matrix      : 100% |###########################################| \n",
      "\n",
      "done!\n",
      "echo To enable dictionary, rewrite /usr/local/etc/mecabrc as \\\"dicdir = /usr/local/lib/mecab/dic/mecab-ko-dic\\\"\n",
      "To enable dictionary, rewrite /usr/local/etc/mecabrc as \"dicdir = /usr/local/lib/mecab/dic/mecab-ko-dic\"\n",
      "make[1]: Entering directory '/tmp/mecab-ko-dic-2.1.1-20180720'\n",
      "make[1]: Nothing to be done for 'install-exec-am'.\n",
      " /bin/mkdir -p '/usr/local/lib/mecab/dic/mecab-ko-dic'\n",
      " /usr/bin/install -c -m 644 model.bin matrix.bin char.bin sys.dic unk.dic left-id.def right-id.def rewrite.def pos-id.def dicrc '/usr/local/lib/mecab/dic/mecab-ko-dic'\n",
      "make[1]: Leaving directory '/tmp/mecab-ko-dic-2.1.1-20180720'\n",
      "Install mecab-python\n",
      "/tmp /tmp/mecab-ko-dic-2.1.1-20180720\n",
      "Cloning into 'mecab-python-0.996'...\n",
      "Unpacking objects: 100% (17/17), done.\n",
      "/tmp/mecab-ko-dic-2.1.1-20180720\n",
      "Processing /tmp/mecab-python-0.996\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: mecab-python\n",
      "  Building wheel for mecab-python (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for mecab-python: filename=mecab_python-0.996_ko_0.9.2-cp37-cp37m-linux_x86_64.whl size=155548 sha256=5277795a69214a464d168858f9f0d0b259fb09bf8f7df49fb8b37ccf94717b96\n",
      "  Stored in directory: /aiffel/.cache/pip/wheels/40/7b/9f/2922869bef86c3354ae7034f7a3647c573ee1997c2dad0290a\n",
      "\u001b[33m  WARNING: Built wheel for mecab-python is invalid: Metadata 1.2 mandates PEP 440 version, but '0.996-ko-0.9.2' is not\u001b[0m\n",
      "Failed to build mecab-python\n",
      "Installing collected packages: mecab-python\n",
      "    Running setup.py install for mecab-python ... \u001b[?25ldone\n",
      "\u001b[33m  DEPRECATION: mecab-python was installed using the legacy 'setup.py install' method, because a wheel could not be built for it. A possible replacement is to fix the wheel build issue reported above. Discussion can be found at https://github.com/pypa/pip/issues/8368\u001b[0m\n",
      "\u001b[?25hSuccessfully installed mecab-python-0.996-ko-0.9.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#- Konlpy Mecab 설치 \n",
    "# Install dependencies\n",
    "! sudo apt-get install g++ openjdk-8-jdk python3-dev python3-pip curl\n",
    "# Install KoNLPy\n",
    "! python3 -m pip install --upgrade pip\n",
    "! python3 -m pip install konlpy  # Python 3.x\n",
    "# Install MeCab (Optional)\n",
    "! sudo apt-get install curl git \n",
    "! bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "stuck-librarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "from collections import Counter\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "challenging-novelty",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(corpus, vocab_size=30000, max_len=40, padding='post'):\n",
    "    tokenizer=Mecab()\n",
    "    \n",
    "    X_train = []\n",
    "    for sentence in corpus:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        X_train.append(temp_X)\n",
    "        \n",
    "        \n",
    "    # 단어사전 만들기\n",
    "    words = np.concatenate(X_train).tolist()\n",
    "    counter = Counter(words)\n",
    "    counter = counter.most_common(vocab_size-4)  # 단어 빈도순으로 vocab_size 만큼 가져오기\n",
    "    vocab = ['<PAD>','<UNK>','<start>','<end>'] + [key for key, _ in counter]  # 앞부분 4개 추가\n",
    "    word_to_index = {word:index for index, word in enumerate(vocab)}  # {단어:인덱스} 단어사전 생성\n",
    "    \n",
    "    # 텍스트를 단어사전 인덱스로 변환\n",
    "    def wordlist_to_indexlist(wordlist):\n",
    "        return [word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in wordlist]\n",
    "    \n",
    "    X_train = list(map(wordlist_to_indexlist, X_train))\n",
    "    \n",
    "    # index to word\n",
    "    index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "    \n",
    "    # padding으로 문장 길이 맞추기\n",
    "    X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train,\n",
    "                                       value=word_to_index[\"<PAD>\"],\n",
    "                                       padding=padding,\n",
    "                                       maxlen=max_len)\n",
    "    \n",
    "    return X_train, word_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geological-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화\n",
    "enc_tensor, enc_tokenizer = tokenize(enc_corpus, vocab_size = 30000, max_len=40, padding='post')\n",
    "dec_tensor, dec_tokenizer = tokenize(dec_corpus, vocab_size = 30000+2, max_len=40, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-silver",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Korean Vocab Size:\", len(enc_tokenizer))\n",
    "print(\"English Vocab Size:\", len(dec_tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blessed-namibia",
   "metadata": {},
   "source": [
    "## 모델 설계\n",
    "- Attention 기반 Seq2seq 모델을 설계합니다.\n",
    "    - 인코더-디코더에 GRU 1개씩 갖는 구조\n",
    "    - 인코더는 모든 Time-Step의 Hidden State를 출력으로 갖고, 디코더는 인코더의 출력과 t-1의 Step의 Hidden State로 Attention을 취하여 t Step의 Hidden State를 생성\n",
    "    - 디코더에서 t Step의 단어로 예측된 것을 실제 정답과 대조해 Loss를 구하고, 생성된 t Step의 Hidden State는 t+1 Step의 Hidden State를 만들기 위해 다시 Decoder에 전달\n",
    "    - t=1 일 때의 Hidden State는 일반적으로 Encoder의 Final State를 Hidden State로 사용\n",
    "    - Attention은 Bahdanau을 사용\n",
    "- Dropout 모듈을 추가하여 성능을 향상시켜 봅니다.\n",
    "- Embedding Size와 Hidden Size는 실험을 통해 적당한 값을 맞춰줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "appropriate-internet",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.w_dec = tf.keras.layers.Dense(units)\n",
    "        self.w_enc = tf.keras.layers.Dense(units)\n",
    "        self.w_com = tf.keras.layers.Dense(1)\n",
    "    \n",
    "    def call(self, h_enc, h_dec):\n",
    "        # h_enc shape: [batch x length x units]\n",
    "        # h_dec shape: [batch x units]\n",
    "\n",
    "        h_enc = self.w_enc(h_enc)\n",
    "        h_dec = tf.expand_dims(h_dec, 1)\n",
    "        h_dec = self.w_dec(h_dec)\n",
    "        \n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        score = self.w_com(tf.nn.tanh(h_dec + h_enc))\n",
    "        \n",
    "        # attention weights shape == (batch_size, max_length, 1)\n",
    "        attn = tf.nn.softmax(score, axis=1)\n",
    "        \n",
    "        # context vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vec = attn * h_enc\n",
    "        context_vec = tf.reduce_sum(context_vec, axis=1)\n",
    "\n",
    "        return context_vec, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "still-equity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(enc_units, dropout = 0.3, return_sequences=True)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.gru(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Decoder\n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(dec_units,\n",
    "                                       dropout = 0.3,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "        self.attention = BahdanauAttention(self.dec_units)   # Attention 필수 사용!\n",
    "\n",
    "    def call(self, x, h_dec, enc_out):\n",
    "        context_vec, attn = self.attention(enc_out, h_dec)\n",
    "        \n",
    "        out = self.embedding(x)\n",
    "        out = tf.concat([tf.expand_dims(context_vec, 1), out], axis=-1)\n",
    "        \n",
    "        out, h_dec = self.gru(out)\n",
    "        out = tf.reshape(out, (-1, out.shape[2]))\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out, h_dec, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "comprehensive-dimension",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE     = 64\n",
    "SRC_VOCAB_SIZE = len(enc_tokenizer) + 1\n",
    "TGT_VOCAB_SIZE = len(dec_tokenizer) + 1\n",
    "\n",
    "units         = 1024\n",
    "embedding_dim = 512\n",
    "\n",
    "encoder = Encoder(SRC_VOCAB_SIZE, embedding_dim, units)\n",
    "decoder = Decoder(TGT_VOCAB_SIZE, embedding_dim, units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "considerable-factor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Output: (64, 30, 1024)\n",
      "Decoder Output: (64, 30003)\n",
      "Decoder Hidden State: (64, 1024)\n",
      "Attention: (64, 30, 1)\n"
     ]
    }
   ],
   "source": [
    "# sample input\n",
    "sequence_len = 30\n",
    "\n",
    "sample_enc = tf.random.uniform((BATCH_SIZE, sequence_len))\n",
    "sample_output = encoder(sample_enc)\n",
    "\n",
    "print ('Encoder Output:', sample_output.shape)\n",
    "\n",
    "sample_state = tf.random.uniform((BATCH_SIZE, units))\n",
    "\n",
    "sample_logits, h_dec, attn = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                     sample_state, sample_output)\n",
    "\n",
    "print ('Decoder Output:', sample_logits.shape)\n",
    "print ('Decoder Hidden State:', h_dec.shape)\n",
    "print ('Attention:', attn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nuclear-territory",
   "metadata": {},
   "source": [
    "## 훈련하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excited-instrument",
   "metadata": {},
   "source": [
    "### Optimizer & Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ahead-buddy",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=tf.keras.optimizers.Adam()\n",
    "loss_object=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask=tf.math.logical_not(tf.math.equal(real,0))\n",
    "    loss=loss_object(real,pred)\n",
    "    \n",
    "    mask=tf.cast(mask, dtype=loss.dtype)\n",
    "    loss*=mask\n",
    "    \n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-booth",
   "metadata": {},
   "source": [
    "### Train step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "informative-hearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(src, tgt, encoder, decoder, optimizer, dec_tok):\n",
    "    bsz = src.shape[0]\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_out = encoder(src)\n",
    "        h_dec = enc_out[:, -1]\n",
    "        \n",
    "        dec_src = tf.expand_dims([dec_tok['<start>']] * bsz, 1)\n",
    "\n",
    "        for t in range(1, tgt.shape[1]):\n",
    "            pred, h_dec, _ = decoder(dec_src, h_dec, enc_out)\n",
    "\n",
    "            loss += loss_function(tgt[:, t], pred)\n",
    "            dec_src = tf.expand_dims(tgt[:, t], 1)\n",
    "        \n",
    "    batch_loss = (loss / int(tgt.shape[1]))\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    \n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "rural-indonesia",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  1:  22%|██▏       | 271/1234 [07:55<28:10,  1.76s/it, Loss 5.0393] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-408da77b2215>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m                                 \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                                 \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                                 dec_tokenizer)\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    \n",
    "    idx_list = list(range(0, enc_tensor.shape[0], BATCH_SIZE))\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm(idx_list)    # tqdm\n",
    "\n",
    "    for (batch, idx) in enumerate(t):\n",
    "        batch_loss = train_step(enc_tensor[idx:idx+BATCH_SIZE],\n",
    "                                dec_tensor[idx:idx+BATCH_SIZE],\n",
    "                                encoder,\n",
    "                                decoder,\n",
    "                                optimizer,\n",
    "                                dec_tokenizer)\n",
    "    \n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        t.set_description_str('Epoch %2d' % (epoch + 1))    # tqdm\n",
    "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))    # tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contrary-canadian",
   "metadata": {},
   "source": [
    "## 평가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peaceful-console",
   "metadata": {},
   "source": [
    "- 아래 예문을 번역해봅니다.\n",
    "\n",
    "  -  K1) 오바마는 대통령이다. <br>\n",
    "  -  K2) 시민들은 도시 속에 산다.<br>\n",
    "  -  K3) 커피는 필요 없다.<br>\n",
    "  -  K4) 일곱 명의 사망자가 발생했다.<br>\n",
    "    \n",
    "- Attention Map을 시각화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organizational-trick",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence, encoder, decoder):\n",
    "    attention = np.zeros((dec_train.shape[-1], enc_train.shape[-1]))\n",
    "    \n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    inputs = enc_tokenizer.texts_to_sequences([sentence.split()])\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,\n",
    "                                                           maxlen=enc_train.shape[-1],\n",
    "                                                           padding='post')\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    enc_out = encoder(inputs)\n",
    "\n",
    "    dec_hidden = enc_out[:, -1]\n",
    "    dec_input = tf.expand_dims([dec_tokenizer.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(dec_train.shape[-1]):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = \\\n",
    "        tf.argmax(tf.math.softmax(predictions, axis=-1)[0]).numpy()\n",
    "\n",
    "        result += dec_tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "        if dec_tokenizer.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention\n",
    "\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention\n",
    "\n",
    "\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def translate(sentence, encoder, decoder):\n",
    "    result, sentence, attention = evaluate(sentence, encoder, decoder)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "    \n",
    "    attention = attention[:len(result.split()), :len(sentence.split())]\n",
    "    plot_attention(attention, sentence.split(), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excess-focus",
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(\"Can I have some coffee?\", encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-representative",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-gossip",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-drilling",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "latter-bumper",
   "metadata": {},
   "source": [
    "## 루브릭\n",
    "|평가문항|상세기준|\n",
    "|:---|:---|\n",
    "|1. 번역기 모델 학습에 필요한 텍스트 데이터 전처리가 한국어 포함하여 잘 이루어졌다.|구두점, 대소문자, 띄어쓰기, 한글 형태소분석 등 번역기 모델에 요구되는 전처리가 정상적으로 진행되었다.|\n",
    "|2. Attentional Seq2seq 모델이 정상적으로 구동된다.|seq2seq 모델 훈련 과정에서 training loss가 안정적으로 떨어지면서 학습이 진행됨이 확인되었다.|\n",
    "|3. 테스트 결과 의미가 통하는 수준의 번역문이 생성되었다.|테스트용 디코더 모델이 정상적으로 만들어져서, 정답과 어느 정도 유사한 영어 번역이 진행됨을 확인하였다.|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
